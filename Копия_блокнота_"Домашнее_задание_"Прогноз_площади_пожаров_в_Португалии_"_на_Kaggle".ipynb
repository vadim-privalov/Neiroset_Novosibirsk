{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"Домашнее задание  \"Прогноз площади пожаров в Португалии.\" - на Kaggle\"",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vadim-privalov/Neiroset_Novosibirsk/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22%D0%94%D0%BE%D0%BC%D0%B0%D1%88%D0%BD%D0%B5%D0%B5_%D0%B7%D0%B0%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5_%22%D0%9F%D1%80%D0%BE%D0%B3%D0%BD%D0%BE%D0%B7_%D0%BF%D0%BB%D0%BE%D1%89%D0%B0%D0%B4%D0%B8_%D0%BF%D0%BE%D0%B6%D0%B0%D1%80%D0%BE%D0%B2_%D0%B2_%D0%9F%D0%BE%D1%80%D1%82%D1%83%D0%B3%D0%B0%D0%BB%D0%B8%D0%B8_%22_%D0%BD%D0%B0_Kaggle%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We9z4ERyi95C"
      },
      "source": [
        "# ООО \"Университет Цифровых Технологий платформа 3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6vuXjYmw4Dn"
      },
      "source": [
        "###Подключаем необходимые модули."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvKZgeLhzBnJ"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, load_model # Подлючаем класс создания модели Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization # Подключаем класс Dense - полносвязный слой, и Flatten - данные выстраиваем в линию, одномерные\n",
        "from tensorflow.keras.optimizers import Adam # Подключаем оптимизатор Adam\n",
        "from tensorflow.keras import utils #Утилиты для to_categorical\n",
        "\n",
        "import tensorflow as tf # импортируем tensorflow\n",
        "\n",
        "# sklearn - популярная библиотека для машинного обучения\n",
        "# train_test_split - функция разделения на обучающую и проверочную/тестовую выборку\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix # для построения матрицы ошибок\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler  # для нормализации данных\n",
        "\n",
        "import numpy as np # Подключаем библиотеку numpy\n",
        "import pandas as pd # Библиотека pandas\n",
        "\n",
        "import matplotlib.pyplot as plt #Отрисовка изображений\n",
        "from PIL import Image #Отрисовка изображений\n",
        "\n",
        "#Отрисовывать изображения в ноутбуке, а не в консоль или файл\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQxs3E-E9A_4",
        "outputId": "31b6ed4e-7877-4bc1-a3af-a5e4d3ea5222"
      },
      "source": [
        "#запускаем - подключаем Google Drive - будем скачивать с него, т.к. намного быстрее\n",
        "#после запуска переходим по ссылке, которая появится, для идентификации\n",
        "#копируем оттуда код authorization code и вставляем здесь в окошко\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-npmaayqnsMc"
      },
      "source": [
        "## Задача регрессии, цель которой состоит в том, чтобы спрогнозировать площадь выгоревших лесных пожаров в северо-восточном регионе Португалии с использованием метеорологических и других данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkCU7hzJHmk4"
      },
      "source": [
        "Загрузите из дата сета базы метеорологических и других данных - тренировочную и валидационную, а также базу для тестирования. Подайте дата сет в нейронную сеть, постаравшись добиться максимальной точности распознавания. Для улучшения обучения можно использовать также дополнительные методы, не рассмотренные в занятиях, слои, функции активации, менять параметры оптимизатора Adam и прочие гипер параметры. Результаты рекомендуется заносить в таблицу для себя, чтобы можно было потом воспроизвести лучший вариант. Предсказание Вашей сети необходимо отправить в виде специального файла с расширением csv, чтобы войти в рейтинговую таблицу соревнования. Ответ можно улучшить и подавать результат несколько раз."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYGF17p_JIUi"
      },
      "source": [
        "Содержание датасета: Набор данных содержится в 3 массивах (train, test, val) и содержит метки размера площади пожара. Меток нет только в тестовом наборе, их нужно спрогнозировать нейронной сетью и отослать на соревнование в виде файла csv. Существует 517 наборов данных, из них 439 обучающая выборка и 78 тестовая.\n",
        "\n",
        "Наборы данных уже нормализованы и готовы к подачи, для обучения в нейронной сети."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud3M8jH7xKyD"
      },
      "source": [
        "### Наборы данных до нормализации выглядел следующим образом:\n",
        "\n",
        "1. Пространственная координата оси X - x на карте парка Монтесиньо: от 1 до 9\n",
        "2. Пространственная координата оси Y - y на карте парка Монтесиньо: от 2 до 9\n",
        "3. месяц - месяц года: с января по декабрь\n",
        "4. день - день недели: от \"пн\" до \"вс\"\n",
        "5. Индекс FFMC - FFMC из системы FWI: от 18,7 до 96,20\n",
        "6. Индекс DMC - DMC из системы FWI: от 1,1 до 291,3\n",
        "7. Индекс DC - DC от системы FWI: от 7,9 до 860,6\n",
        "8. Индекс ISI - ISI от системы FWI: от 0.0 до 56.10\n",
        "9. temp - температура в градусах Цельсия: от 2,2 до 33,30\n",
        "10. RH - относительная влажность воздуха в %: от 15,0 до 100\n",
        "11. ветер - скорость ветра в км/ч: от 0,40 до 9,40\n",
        "12. дождь - наружный дождь в мм/м2 : от 0,0 до 6,4\n",
        "13. площадь - сожженная площадь леса (в га): от 0,00 до 1090,84\n",
        "(эта выходная переменная очень смещена в сторону 0.0, поэтому имеет смысл моделировать с помощью логарифмического преобразования).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lETgAzkJnyR"
      },
      "source": [
        "Ссылка на задание: https://www.kaggle.com/t/e594f270a7554fe5b3ce37e557d9d883\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi6PBbPFGGQ6"
      },
      "source": [
        "### Анализ и обработка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1d4beD-2bfD",
        "outputId": "c420f853-70e4-43c0-9e5a-315fc6f9c750"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVgbIXSTLRvc",
        "outputId": "2289f2f6-bd1b-4a5a-fea3-4a2648d25189"
      },
      "source": [
        "pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCi9U2FoM4Lo",
        "outputId": "fc9dd7df-9bd8-4a35-b3f1-c2723d09eafb"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHTOfSzcX9V6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1215ab1-2c90-434d-cf43-e2fd90f5eb39"
      },
      "source": [
        "%cd /content/drive/MyDrive/datasets/kaggle/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/datasets/kaggle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6eSnS0QUFXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ee7fd0-6ec5-4780-943c-aff61cd2f80a"
      },
      "source": [
        "#!cp './kaggle.json' '/root/.kaggle/kaggle.json' # установка ключей"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSXS4J5XIuuv"
      },
      "source": [
        "!cp '/content/drive/MyDrive/datasets/kaggle/kaggle.json' '/root/.kaggle/kaggle.json' # альтернативный вариант"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLpyQD79Iowj",
        "outputId": "dfbf5175-5b6a-46ff-ec29-d7d19024226f"
      },
      "source": [
        "!kaggle competitions download -c udt-3-regression"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "sampleSubmissionForest.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "x_train.npy: Skipping, found more recently modified local copy (use --force to force download)\n",
            "x_test.npy: Skipping, found more recently modified local copy (use --force to force download)\n",
            "y_train.npy: Skipping, found more recently modified local copy (use --force to force download)\n",
            "yTrainScaled.bin: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umnMjvl4PRVi"
      },
      "source": [
        "x_train = np.load('x_train.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "x_test = np.load('x_test.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9cZhTI4upvb",
        "outputId": "80cce307-90ce-4b08-ab98-60f8419c5219"
      },
      "source": [
        "x_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.625     , 0.42857143, 0.27272727, 0.66666667, 0.9316129 ,\n",
              "        0.43211578, 0.79582503, 0.12477718, 0.61414791, 0.31764706,\n",
              "        0.2       , 0.        ],\n",
              "       [0.375     , 0.14285714, 0.27272727, 0.33333333, 0.9483871 ,\n",
              "        0.34872502, 0.87205348, 0.14973262, 0.68488746, 0.14117647,\n",
              "        0.4       , 0.        ],\n",
              "       [0.75      , 0.28571429, 0.27272727, 0.83333333, 0.92129032,\n",
              "        0.28187457, 0.8535241 , 0.11051693, 0.4244373 , 0.49411765,\n",
              "        0.45555556, 0.        ],\n",
              "       [0.375     , 0.42857143, 0.        , 0.        , 0.94193548,\n",
              "        0.11095796, 0.08162308, 0.16042781, 0.48231511, 0.12941176,\n",
              "        0.45555556, 0.        ],\n",
              "       [0.125     , 0.28571429, 0.18181818, 0.83333333, 0.94709677,\n",
              "        0.37939352, 0.75782808, 0.17112299, 0.58842444, 0.23529412,\n",
              "        0.4       , 0.        ],\n",
              "       [0.875     , 0.42857143, 0.18181818, 0.83333333, 0.96      ,\n",
              "        0.53824948, 0.77260467, 0.24064171, 0.79099678, 0.11764706,\n",
              "        0.3       , 0.        ],\n",
              "       [0.875     , 0.57142857, 0.18181818, 0.83333333, 0.98709677,\n",
              "        0.74638181, 0.79992964, 0.32085561, 0.83601286, 0.16470588,\n",
              "        0.15555556, 0.        ],\n",
              "       [0.25      , 0.28571429, 0.18181818, 0.66666667, 0.93935484,\n",
              "        0.49724328, 0.70399906, 0.19073084, 0.26045016, 0.69411765,\n",
              "        0.2       , 0.        ],\n",
              "       [0.375     , 0.28571429, 0.81818182, 0.66666667, 0.86064516,\n",
              "        0.08373535, 0.40084438, 0.04634581, 0.07717042, 0.07058824,\n",
              "        0.9       , 0.        ],\n",
              "       [0.625     , 0.42857143, 0.27272727, 1.        , 0.95612903,\n",
              "        0.40627154, 0.90958133, 0.13368984, 0.46945338, 0.15294118,\n",
              "        0.4       , 0.        ],\n",
              "       [0.375     , 0.42857143, 0.27272727, 0.16666667, 0.93419355,\n",
              "        0.452102  , 0.94312185, 0.2228164 , 0.44051447, 0.27058824,\n",
              "        0.55555556, 0.        ],\n",
              "       [0.125     , 0.28571429, 0.18181818, 1.        , 0.94064516,\n",
              "        0.85217092, 0.87475079, 0.11229947, 0.46302251, 0.51764706,\n",
              "        0.25555556, 0.        ],\n",
              "       [0.75      , 0.28571429, 0.54545455, 0.5       , 0.96774194,\n",
              "        0.34527912, 0.48727571, 0.26203209, 0.51446945, 0.78823529,\n",
              "        0.45555556, 0.        ],\n",
              "       [0.75      , 0.28571429, 0.27272727, 0.        , 0.94709677,\n",
              "        0.33735355, 0.86478246, 0.17112299, 0.5659164 , 0.37647059,\n",
              "        0.25555556, 0.        ],\n",
              "       [0.625     , 0.42857143, 0.27272727, 0.83333333, 0.95741935,\n",
              "        0.4555479 , 0.81118799, 0.16399287, 0.77813505, 0.07058824,\n",
              "        0.45555556, 0.        ],\n",
              "       [0.375     , 0.28571429, 0.27272727, 0.5       , 0.96516129,\n",
              "        0.51068229, 0.84519761, 0.14438503, 0.66559486, 0.28235294,\n",
              "        0.5       , 0.        ],\n",
              "       [0.75      , 0.28571429, 0.18181818, 0.33333333, 0.96516129,\n",
              "        0.47656788, 0.68758063, 0.36185383, 0.09324759, 0.95294118,\n",
              "        0.6       , 0.        ],\n",
              "       [0.        , 0.28571429, 0.27272727, 1.        , 0.95612903,\n",
              "        0.40627154, 0.90958133, 0.13368984, 0.46945338, 0.15294118,\n",
              "        0.4       , 0.        ],\n",
              "       [0.875     , 0.14285714, 0.45454545, 0.66666667, 0.89677419,\n",
              "        0.32770503, 0.25929401, 0.08377897, 0.38906752, 0.75294118,\n",
              "        0.4       , 0.        ],\n",
              "       [0.25      , 0.28571429, 0.18181818, 0.16666667, 0.94709677,\n",
              "        0.52205376, 0.76263633, 0.25490196, 0.60450161, 0.2       ,\n",
              "        0.3       , 0.        ],\n",
              "       [0.375     , 0.28571429, 0.27272727, 0.83333333, 0.92129032,\n",
              "        0.28187457, 0.8535241 , 0.11051693, 0.34405145, 0.69411765,\n",
              "        0.5       , 0.        ],\n",
              "       [0.875     , 0.57142857, 0.        , 0.        , 0.94193548,\n",
              "        0.11095796, 0.08162308, 0.16042781, 0.19614148, 0.96470588,\n",
              "        0.4       , 0.03125   ],\n",
              "       [0.75      , 0.28571429, 0.09090909, 0.33333333, 0.92774194,\n",
              "        0.14679531, 0.79629412, 0.11942959, 0.39871383, 0.21176471,\n",
              "        0.1       , 0.        ],\n",
              "       [0.375     , 0.14285714, 0.27272727, 0.5       , 0.92645161,\n",
              "        0.32942798, 0.87088073, 0.20320856, 0.585209  , 0.47058824,\n",
              "        0.5       , 0.        ],\n",
              "       [0.125     , 0.42857143, 0.18181818, 0.33333333, 0.96774194,\n",
              "        0.79255686, 0.82936554, 0.14973262, 0.68810289, 0.44705882,\n",
              "        0.4       , 0.        ],\n",
              "       [0.5       , 0.28571429, 0.        , 0.        , 0.94193548,\n",
              "        0.11095796, 0.08162308, 0.16042781, 0.43086817, 0.11764706,\n",
              "        0.65555556, 0.        ],\n",
              "       [0.75      , 0.28571429, 0.27272727, 0.83333333, 0.91612903,\n",
              "        0.97794624, 0.98053243, 0.18003565, 0.26688103, 0.72941176,\n",
              "        0.4       , 0.        ],\n",
              "       [0.375     , 0.14285714, 0.45454545, 1.        , 0.95870968,\n",
              "        0.35389387, 0.36214378, 0.19251337, 0.77813505, 0.23529412,\n",
              "        0.25555556, 0.        ],\n",
              "       [0.375     , 0.28571429, 0.27272727, 0.66666667, 0.9316129 ,\n",
              "        0.43211578, 0.79582503, 0.12477718, 0.49839228, 0.28235294,\n",
              "        0.2       , 0.        ],\n",
              "       [0.125     , 0.        , 0.27272727, 0.        , 0.95096774,\n",
              "        0.40248105, 0.77412924, 0.21746881, 0.55948553, 0.21176471,\n",
              "        0.65555556, 0.        ],\n",
              "       [0.875     , 0.57142857, 0.18181818, 0.83333333, 0.86322581,\n",
              "        0.30771881, 0.70564091, 0.11764706, 0.48874598, 0.41176471,\n",
              "        0.4       , 0.        ],\n",
              "       [0.        , 0.        , 0.54545455, 0.33333333, 0.92      ,\n",
              "        0.17298415, 0.33821977, 0.15508021, 0.46302251, 0.44705882,\n",
              "        0.55555556, 0.        ],\n",
              "       [0.125     , 0.        , 0.18181818, 0.16666667, 0.97935484,\n",
              "        0.72708477, 0.78925765, 0.16934046, 0.82636656, 0.14117647,\n",
              "        0.2       , 0.        ],\n",
              "       [0.25      , 0.57142857, 0.27272727, 0.66666667, 0.9316129 ,\n",
              "        0.43211578, 0.79582503, 0.12477718, 0.43086817, 0.6       ,\n",
              "        0.3       , 0.        ],\n",
              "       [0.        , 0.28571429, 0.18181818, 0.33333333, 0.92258065,\n",
              "        0.33011716, 0.72276299, 0.15864528, 0.58199357, 0.28235294,\n",
              "        0.5       , 0.        ],\n",
              "       [0.125     , 0.42857143, 0.18181818, 1.        , 0.98709677,\n",
              "        0.45003446, 0.66952035, 0.18538324, 0.7073955 , 0.15294118,\n",
              "        0.25555556, 0.        ],\n",
              "       [0.25      , 0.28571429, 0.18181818, 1.        , 0.94064516,\n",
              "        0.85217092, 0.87475079, 0.11229947, 0.46945338, 0.48235294,\n",
              "        0.3       , 0.        ],\n",
              "       [0.625     , 0.14285714, 0.27272727, 0.66666667, 0.90193548,\n",
              "        0.31254307, 0.82326727, 0.12655971, 0.28938907, 0.74117647,\n",
              "        0.8       , 0.        ],\n",
              "       [0.375     , 0.42857143, 0.27272727, 1.        , 0.95741935,\n",
              "        0.46829773, 0.81916266, 0.16399287, 0.63987138, 0.22352941,\n",
              "        0.15555556, 0.        ],\n",
              "       [0.375     , 0.28571429, 0.27272727, 0.83333333, 0.95741935,\n",
              "        0.4555479 , 0.81118799, 0.16399287, 0.77813505, 0.07058824,\n",
              "        0.45555556, 0.        ],\n",
              "       [0.5       , 0.28571429, 0.27272727, 0.        , 0.92387097,\n",
              "        0.99552033, 0.99378445, 0.13190731, 0.45016077, 0.50588235,\n",
              "        0.35555556, 0.        ],\n",
              "       [0.125     , 0.        , 0.18181818, 1.        , 0.95870968,\n",
              "        0.25568573, 0.53793831, 0.1372549 , 0.53376206, 0.23529412,\n",
              "        0.5       , 0.        ],\n",
              "       [0.        , 0.28571429, 0.18181818, 0.83333333, 0.94193548,\n",
              "        0.65575465, 0.73648411, 0.13903743, 0.56913183, 0.41176471,\n",
              "        0.4       , 0.        ],\n",
              "       [0.125     , 0.        , 0.18181818, 1.        , 0.94193548,\n",
              "        0.39007581, 0.76627184, 0.11229947, 0.52733119, 0.34117647,\n",
              "        0.45555556, 0.        ],\n",
              "       [0.25      , 0.57142857, 0.45454545, 0.        , 0.93419355,\n",
              "        0.32046864, 0.26292952, 0.12655971, 0.54662379, 0.27058824,\n",
              "        0.45555556, 0.        ],\n",
              "       [0.375     , 0.57142857, 0.        , 0.66666667, 0.88387097,\n",
              "        0.07856651, 0.06661194, 0.07308378, 0.37942122, 0.28235294,\n",
              "        0.3       , 0.        ],\n",
              "       [0.5       , 0.28571429, 0.36363636, 0.5       , 0.93290323,\n",
              "        0.04651964, 0.02075759, 0.21925134, 0.49517685, 0.14117647,\n",
              "        0.6       , 0.        ],\n",
              "       [0.375     , 0.42857143, 0.        , 0.        , 0.93548387,\n",
              "        0.16264645, 0.10542981, 0.2228164 , 0.43729904, 0.14117647,\n",
              "        0.8       , 0.        ],\n",
              "       [0.375     , 0.42857143, 0.27272727, 1.        , 0.95096774,\n",
              "        0.32770503, 0.85786326, 0.15329768, 0.52733119, 0.10588235,\n",
              "        0.6       , 0.        ],\n",
              "       [0.625     , 0.42857143, 0.36363636, 1.        , 0.81032258,\n",
              "        0.0275672 , 0.05547086, 0.04812834, 0.11575563, 0.45882353,\n",
              "        0.6       , 0.        ],\n",
              "       [0.25      , 0.28571429, 0.09090909, 0.5       , 0.95354839,\n",
              "        0.15644383, 0.80204058, 0.15686275, 0.59163987, 0.10588235,\n",
              "        0.55555556, 0.        ],\n",
              "       [0.875     , 0.57142857, 0.        , 0.        , 0.94193548,\n",
              "        0.11957271, 0.08549314, 0.13903743, 0.48874598, 0.10588235,\n",
              "        0.55555556, 0.        ],\n",
              "       [0.375     , 0.28571429, 0.18181818, 1.        , 0.99483871,\n",
              "        0.51998622, 0.72264571, 0.2459893 , 0.97106109, 0.07058824,\n",
              "        0.45555556, 0.        ],\n",
              "       [0.25      , 0.28571429, 0.27272727, 1.        , 0.93419355,\n",
              "        0.30013784, 0.84883312, 0.14795009, 0.66237942, 0.36470588,\n",
              "        0.4       , 0.        ],\n",
              "       [0.625     , 0.14285714, 0.54545455, 0.16666667, 0.95483871,\n",
              "        0.5616816 , 0.66600211, 0.15864528, 0.77491961, 0.28235294,\n",
              "        0.3       , 0.        ],\n",
              "       [0.625     , 0.42857143, 0.18181818, 0.5       , 0.94580645,\n",
              "        0.69641626, 0.77002463, 0.14438503, 0.54340836, 0.64705882,\n",
              "        0.2       , 0.        ],\n",
              "       [0.625     , 0.42857143, 0.63636364, 0.16666667, 0.72774194,\n",
              "        0.01137147, 0.00973379, 0.03386809, 0.07717042, 0.78823529,\n",
              "        0.65555556, 0.        ],\n",
              "       [0.125     , 0.        , 0.18181818, 0.16666667, 0.94709677,\n",
              "        0.52205376, 0.76263633, 0.25490196, 0.63022508, 0.48235294,\n",
              "        0.3       , 0.        ],\n",
              "       [0.        , 0.14285714, 0.27272727, 0.33333333, 0.93548387,\n",
              "        0.32115782, 0.86372698, 0.14973262, 0.64630225, 0.38823529,\n",
              "        0.4       , 0.        ],\n",
              "       [0.125     , 0.        , 0.        , 0.5       , 0.91096774,\n",
              "        0.17298415, 0.11058989, 0.17112299, 0.10610932, 0.51764706,\n",
              "        0.65555556, 0.        ],\n",
              "       [0.125     , 0.28571429, 0.18181818, 0.5       , 0.8116129 ,\n",
              "        0.19159201, 0.77131465, 0.03386809, 0.63344051, 0.65882353,\n",
              "        0.6       , 0.        ],\n",
              "       [0.375     , 0.42857143, 0.27272727, 0.33333333, 0.95225806,\n",
              "        0.29944866, 0.81001525, 0.12655971, 0.58199357, 0.35294118,\n",
              "        0.3       , 0.        ],\n",
              "       [0.625     , 0.28571429, 0.        , 0.33333333, 0.93032258,\n",
              "        0.14059269, 0.09557875, 0.14081996, 0.35691318, 0.31764706,\n",
              "        0.05555556, 0.        ],\n",
              "       [0.125     , 0.        , 0.54545455, 0.        , 0.89806452,\n",
              "        0.51412819, 0.35416911, 0.12121212, 0.36012862, 0.75294118,\n",
              "        0.35555556, 0.        ],\n",
              "       [0.375     , 0.14285714, 0.54545455, 0.5       , 0.96774194,\n",
              "        0.34527912, 0.48727571, 0.26203209, 0.76848875, 0.35294118,\n",
              "        0.4       , 0.        ],\n",
              "       [0.625     , 0.28571429, 0.36363636, 0.33333333, 0.87225806,\n",
              "        0.09062715, 0.10460889, 0.09090909, 0.22829582, 0.34117647,\n",
              "        0.45555556, 0.        ],\n",
              "       [0.25      , 0.28571429, 0.        , 0.16666667, 0.89548387,\n",
              "        0.08476912, 0.0700129 , 0.06773619, 0.43729904, 0.14117647,\n",
              "        0.8       , 0.        ],\n",
              "       [0.375     , 0.28571429, 0.09090909, 0.33333333, 0.92774194,\n",
              "        0.14679531, 0.79629412, 0.11942959, 0.52090032, 0.11764706,\n",
              "        0.3       , 0.        ],\n",
              "       [0.375     , 0.57142857, 0.63636364, 0.33333333, 0.63870968,\n",
              "        0.07029635, 0.09299871, 0.01426025, 0.4244373 , 0.29411765,\n",
              "        0.25555556, 0.        ],\n",
              "       [0.625     , 0.42857143, 0.27272727, 0.33333333, 0.9483871 ,\n",
              "        0.34872502, 0.87205348, 0.14973262, 0.56270096, 0.23529412,\n",
              "        0.15555556, 0.        ],\n",
              "       [0.        , 0.        , 0.18181818, 0.16666667, 0.98193548,\n",
              "        0.36940041, 0.74961886, 0.3030303 , 0.52733119, 0.42352941,\n",
              "        0.45555556, 0.        ],\n",
              "       [0.75      , 0.42857143, 0.27272727, 0.33333333, 0.95225806,\n",
              "        0.29944866, 0.81001525, 0.12655971, 0.66237942, 0.29411765,\n",
              "        0.4       , 0.        ],\n",
              "       [0.875     , 0.57142857, 0.18181818, 0.33333333, 0.9483871 ,\n",
              "        0.27808408, 0.5545913 , 0.21212121, 0.5755627 , 0.22352941,\n",
              "        0.45555556, 0.        ],\n",
              "       [0.        , 0.        , 0.18181818, 0.        , 0.93290323,\n",
              "        0.57133012, 0.8733435 , 0.12655971, 0.76205788, 0.30588235,\n",
              "        0.35555556, 0.        ],\n",
              "       [0.125     , 0.        , 0.27272727, 0.        , 0.95096774,\n",
              "        0.40248105, 0.77412924, 0.21746881, 0.66881029, 0.25882353,\n",
              "        0.45555556, 0.        ],\n",
              "       [0.125     , 0.14285714, 0.27272727, 0.66666667, 0.94064516,\n",
              "        0.369745  , 0.88671279, 0.11051693, 0.50803859, 0.42352941,\n",
              "        0.55555556, 0.        ],\n",
              "       [0.625     , 0.14285714, 0.27272727, 0.66666667, 0.94322581,\n",
              "        0.26671261, 0.8401548 , 0.16399287, 0.61093248, 0.2       ,\n",
              "        0.25555556, 0.        ],\n",
              "       [0.5       , 0.28571429, 0.63636364, 0.        , 0.85806452,\n",
              "        0.01309442, 0.00926469, 0.11229947, 0.17041801, 0.36470588,\n",
              "        0.84444444, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BxJf4JMHJHf"
      },
      "source": [
        "### Создаем нейронную сеть с полученными данными."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p8U47eS8Cfc"
      },
      "source": [
        "# Обучаем модель полученными данными\n",
        "def createModel(inputmy):\n",
        "    model = Sequential()\n",
        "    model.add(BatchNormalization(input_shape=(inputmy,)))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1000, activation='tanh'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(500, activation='relu'))\n",
        "    model.add(Dense(400, activation='tanh'))\n",
        "    model.add(Dense(300, activation='relu'))\n",
        "    model.add(Dense(200, activation='tanh'))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_absolute_error', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIM7FaDdKfky",
        "outputId": "fe27d354-bb99-4ea3-d982-fdcc1fab8a3c"
      },
      "source": [
        "# Создаём пустую сеть при помощи функции createModel() с заданным аргументом\n",
        "model = createModel(x_train.shape[1])\n",
        "# Обучаем сеть\n",
        "history = model.fit(x_train, \n",
        "                    y_train, \n",
        "                    epochs=500, # Количество эпох\n",
        "                    batch_size=50, # Размер батча\n",
        "                    validation_split=0.2, \n",
        "                    verbose=1) # Выводить процесс обучения на каждой эпохе\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 1s 43ms/step - loss: 0.6325 - accuracy: 0.3134 - val_loss: 0.2192 - val_accuracy: 0.4432\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.2363 - accuracy: 0.4644 - val_loss: 0.2049 - val_accuracy: 0.4432\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.2209 - accuracy: 0.4644 - val_loss: 0.1752 - val_accuracy: 0.4432\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.1565 - accuracy: 0.4786 - val_loss: 0.1709 - val_accuracy: 0.4432\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.1500 - accuracy: 0.4786 - val_loss: 0.1734 - val_accuracy: 0.4432\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1416 - accuracy: 0.4786 - val_loss: 0.1703 - val_accuracy: 0.4432\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1410 - accuracy: 0.4786 - val_loss: 0.1665 - val_accuracy: 0.4432\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.1493 - accuracy: 0.4786 - val_loss: 0.1699 - val_accuracy: 0.4432\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.1342 - accuracy: 0.4786 - val_loss: 0.1671 - val_accuracy: 0.4432\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.1310 - accuracy: 0.4786 - val_loss: 0.1669 - val_accuracy: 0.4432\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.1289 - accuracy: 0.4786 - val_loss: 0.1705 - val_accuracy: 0.4432\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.1288 - accuracy: 0.4786 - val_loss: 0.1791 - val_accuracy: 0.4432\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1173 - accuracy: 0.4815 - val_loss: 0.1674 - val_accuracy: 0.4432\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1220 - accuracy: 0.4786 - val_loss: 0.1679 - val_accuracy: 0.4432\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.1185 - accuracy: 0.4758 - val_loss: 0.1680 - val_accuracy: 0.4432\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.1150 - accuracy: 0.4786 - val_loss: 0.1782 - val_accuracy: 0.4432\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.1174 - accuracy: 0.4786 - val_loss: 0.1681 - val_accuracy: 0.4432\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.1136 - accuracy: 0.4758 - val_loss: 0.1737 - val_accuracy: 0.4432\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.1139 - accuracy: 0.4786 - val_loss: 0.1723 - val_accuracy: 0.4432\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.1123 - accuracy: 0.4786 - val_loss: 0.1817 - val_accuracy: 0.4432\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.1143 - accuracy: 0.4786 - val_loss: 0.1787 - val_accuracy: 0.4432\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.1008 - accuracy: 0.4786 - val_loss: 0.1716 - val_accuracy: 0.4432\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.1068 - accuracy: 0.4758 - val_loss: 0.1734 - val_accuracy: 0.4432\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.1040 - accuracy: 0.4786 - val_loss: 0.1727 - val_accuracy: 0.4432\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.1079 - accuracy: 0.4786 - val_loss: 0.1728 - val_accuracy: 0.4432\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0952 - accuracy: 0.4786 - val_loss: 0.1824 - val_accuracy: 0.4432\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.1147 - accuracy: 0.4786 - val_loss: 0.1871 - val_accuracy: 0.4432\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.1076 - accuracy: 0.4786 - val_loss: 0.1787 - val_accuracy: 0.4432\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0976 - accuracy: 0.4786 - val_loss: 0.1842 - val_accuracy: 0.4432\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.1005 - accuracy: 0.4815 - val_loss: 0.1804 - val_accuracy: 0.4432\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0941 - accuracy: 0.4786 - val_loss: 0.2001 - val_accuracy: 0.4205\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0972 - accuracy: 0.4815 - val_loss: 0.1848 - val_accuracy: 0.4432\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0966 - accuracy: 0.4786 - val_loss: 0.1871 - val_accuracy: 0.4432\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0922 - accuracy: 0.4786 - val_loss: 0.1868 - val_accuracy: 0.4432\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0933 - accuracy: 0.4786 - val_loss: 0.1773 - val_accuracy: 0.4432\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0810 - accuracy: 0.4786 - val_loss: 0.1923 - val_accuracy: 0.4318\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0893 - accuracy: 0.4786 - val_loss: 0.1895 - val_accuracy: 0.4318\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0890 - accuracy: 0.4815 - val_loss: 0.1934 - val_accuracy: 0.4318\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0868 - accuracy: 0.4786 - val_loss: 0.2085 - val_accuracy: 0.3977\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0874 - accuracy: 0.4786 - val_loss: 0.1889 - val_accuracy: 0.4205\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0918 - accuracy: 0.4786 - val_loss: 0.1916 - val_accuracy: 0.4432\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0832 - accuracy: 0.4786 - val_loss: 0.1996 - val_accuracy: 0.4432\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0871 - accuracy: 0.4815 - val_loss: 0.2102 - val_accuracy: 0.3977\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0844 - accuracy: 0.4786 - val_loss: 0.1984 - val_accuracy: 0.4091\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0825 - accuracy: 0.4786 - val_loss: 0.1802 - val_accuracy: 0.4318\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0863 - accuracy: 0.4815 - val_loss: 0.1958 - val_accuracy: 0.4205\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0867 - accuracy: 0.4786 - val_loss: 0.2118 - val_accuracy: 0.4091\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0837 - accuracy: 0.4815 - val_loss: 0.1987 - val_accuracy: 0.4318\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0788 - accuracy: 0.4786 - val_loss: 0.2051 - val_accuracy: 0.4205\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0814 - accuracy: 0.4786 - val_loss: 0.1902 - val_accuracy: 0.4432\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0901 - accuracy: 0.4815 - val_loss: 0.1730 - val_accuracy: 0.4432\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0885 - accuracy: 0.4815 - val_loss: 0.1920 - val_accuracy: 0.4318\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0861 - accuracy: 0.4815 - val_loss: 0.2029 - val_accuracy: 0.4432\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0691 - accuracy: 0.4815 - val_loss: 0.2130 - val_accuracy: 0.3977\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0733 - accuracy: 0.4786 - val_loss: 0.1964 - val_accuracy: 0.4205\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0749 - accuracy: 0.4815 - val_loss: 0.2051 - val_accuracy: 0.3977\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0759 - accuracy: 0.4815 - val_loss: 0.2018 - val_accuracy: 0.4091\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0780 - accuracy: 0.4786 - val_loss: 0.1960 - val_accuracy: 0.4432\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0700 - accuracy: 0.4815 - val_loss: 0.1937 - val_accuracy: 0.4091\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0669 - accuracy: 0.4786 - val_loss: 0.2002 - val_accuracy: 0.4205\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0707 - accuracy: 0.4815 - val_loss: 0.1949 - val_accuracy: 0.4318\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0722 - accuracy: 0.4758 - val_loss: 0.1953 - val_accuracy: 0.4318\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0682 - accuracy: 0.4815 - val_loss: 0.1965 - val_accuracy: 0.4318\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0748 - accuracy: 0.4815 - val_loss: 0.2006 - val_accuracy: 0.4091\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0676 - accuracy: 0.4815 - val_loss: 0.2173 - val_accuracy: 0.4091\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0812 - accuracy: 0.4815 - val_loss: 0.2119 - val_accuracy: 0.4091\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0875 - accuracy: 0.4786 - val_loss: 0.2102 - val_accuracy: 0.4205\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0812 - accuracy: 0.4815 - val_loss: 0.2055 - val_accuracy: 0.4205\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0660 - accuracy: 0.4815 - val_loss: 0.2091 - val_accuracy: 0.4318\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0820 - accuracy: 0.4815 - val_loss: 0.1992 - val_accuracy: 0.4091\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0802 - accuracy: 0.4815 - val_loss: 0.1971 - val_accuracy: 0.4318\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0777 - accuracy: 0.4786 - val_loss: 0.1997 - val_accuracy: 0.4318\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0758 - accuracy: 0.4815 - val_loss: 0.2000 - val_accuracy: 0.4205\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0700 - accuracy: 0.4786 - val_loss: 0.2072 - val_accuracy: 0.4205\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0705 - accuracy: 0.4815 - val_loss: 0.2154 - val_accuracy: 0.3977\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0696 - accuracy: 0.4815 - val_loss: 0.2033 - val_accuracy: 0.4432\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0639 - accuracy: 0.4815 - val_loss: 0.1874 - val_accuracy: 0.4318\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0660 - accuracy: 0.4815 - val_loss: 0.2041 - val_accuracy: 0.4318\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0702 - accuracy: 0.4815 - val_loss: 0.1889 - val_accuracy: 0.4318\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0618 - accuracy: 0.4815 - val_loss: 0.1847 - val_accuracy: 0.4205\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0643 - accuracy: 0.4815 - val_loss: 0.1979 - val_accuracy: 0.4318\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0683 - accuracy: 0.4815 - val_loss: 0.2066 - val_accuracy: 0.4205\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0653 - accuracy: 0.4815 - val_loss: 0.1912 - val_accuracy: 0.4091\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0598 - accuracy: 0.4815 - val_loss: 0.1957 - val_accuracy: 0.4205\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0613 - accuracy: 0.4815 - val_loss: 0.2048 - val_accuracy: 0.4205\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0550 - accuracy: 0.4815 - val_loss: 0.1843 - val_accuracy: 0.4318\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0564 - accuracy: 0.4815 - val_loss: 0.1993 - val_accuracy: 0.4318\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0580 - accuracy: 0.4815 - val_loss: 0.2114 - val_accuracy: 0.3977\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0624 - accuracy: 0.4815 - val_loss: 0.1987 - val_accuracy: 0.4091\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0562 - accuracy: 0.4815 - val_loss: 0.1831 - val_accuracy: 0.4432\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0550 - accuracy: 0.4815 - val_loss: 0.1935 - val_accuracy: 0.4318\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0542 - accuracy: 0.4815 - val_loss: 0.1925 - val_accuracy: 0.4091\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0565 - accuracy: 0.4815 - val_loss: 0.2066 - val_accuracy: 0.4205\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0549 - accuracy: 0.4815 - val_loss: 0.1990 - val_accuracy: 0.4318\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0600 - accuracy: 0.4815 - val_loss: 0.1875 - val_accuracy: 0.4205\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0632 - accuracy: 0.4815 - val_loss: 0.1959 - val_accuracy: 0.4205\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0558 - accuracy: 0.4815 - val_loss: 0.1916 - val_accuracy: 0.4432\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0579 - accuracy: 0.4786 - val_loss: 0.1993 - val_accuracy: 0.4318\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0551 - accuracy: 0.4815 - val_loss: 0.2029 - val_accuracy: 0.4318\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0542 - accuracy: 0.4815 - val_loss: 0.1971 - val_accuracy: 0.4205\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0549 - accuracy: 0.4815 - val_loss: 0.1932 - val_accuracy: 0.4432\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0535 - accuracy: 0.4815 - val_loss: 0.2054 - val_accuracy: 0.4205\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0596 - accuracy: 0.4815 - val_loss: 0.2003 - val_accuracy: 0.4205\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0555 - accuracy: 0.4815 - val_loss: 0.2028 - val_accuracy: 0.4205\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0587 - accuracy: 0.4815 - val_loss: 0.1963 - val_accuracy: 0.4091\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0567 - accuracy: 0.4786 - val_loss: 0.1950 - val_accuracy: 0.4318\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0555 - accuracy: 0.4815 - val_loss: 0.2088 - val_accuracy: 0.4318\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0550 - accuracy: 0.4815 - val_loss: 0.1941 - val_accuracy: 0.4432\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0449 - accuracy: 0.4815 - val_loss: 0.2043 - val_accuracy: 0.4318\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0489 - accuracy: 0.4815 - val_loss: 0.1902 - val_accuracy: 0.4432\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0553 - accuracy: 0.4815 - val_loss: 0.2037 - val_accuracy: 0.4205\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0505 - accuracy: 0.4815 - val_loss: 0.2056 - val_accuracy: 0.4091\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0517 - accuracy: 0.4815 - val_loss: 0.1815 - val_accuracy: 0.4432\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0510 - accuracy: 0.4786 - val_loss: 0.1881 - val_accuracy: 0.4432\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0516 - accuracy: 0.4815 - val_loss: 0.1906 - val_accuracy: 0.4432\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0516 - accuracy: 0.4815 - val_loss: 0.2001 - val_accuracy: 0.4205\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0467 - accuracy: 0.4815 - val_loss: 0.2046 - val_accuracy: 0.4205\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0461 - accuracy: 0.4815 - val_loss: 0.1911 - val_accuracy: 0.4205\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0522 - accuracy: 0.4786 - val_loss: 0.1889 - val_accuracy: 0.4318\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0464 - accuracy: 0.4815 - val_loss: 0.1974 - val_accuracy: 0.4091\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0490 - accuracy: 0.4815 - val_loss: 0.1984 - val_accuracy: 0.4205\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0469 - accuracy: 0.4786 - val_loss: 0.1908 - val_accuracy: 0.4318\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0489 - accuracy: 0.4815 - val_loss: 0.1984 - val_accuracy: 0.4205\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0525 - accuracy: 0.4815 - val_loss: 0.1900 - val_accuracy: 0.4318\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0494 - accuracy: 0.4815 - val_loss: 0.1902 - val_accuracy: 0.4432\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0507 - accuracy: 0.4815 - val_loss: 0.1975 - val_accuracy: 0.4318\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0550 - accuracy: 0.4815 - val_loss: 0.1997 - val_accuracy: 0.4205\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0558 - accuracy: 0.4815 - val_loss: 0.2097 - val_accuracy: 0.4205\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0508 - accuracy: 0.4815 - val_loss: 0.1940 - val_accuracy: 0.4318\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0501 - accuracy: 0.4786 - val_loss: 0.1985 - val_accuracy: 0.4205\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0521 - accuracy: 0.4815 - val_loss: 0.1937 - val_accuracy: 0.4318\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0502 - accuracy: 0.4815 - val_loss: 0.2054 - val_accuracy: 0.4205\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0484 - accuracy: 0.4815 - val_loss: 0.1977 - val_accuracy: 0.4205\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0523 - accuracy: 0.4786 - val_loss: 0.1891 - val_accuracy: 0.4205\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0467 - accuracy: 0.4815 - val_loss: 0.2010 - val_accuracy: 0.4091\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0451 - accuracy: 0.4815 - val_loss: 0.1909 - val_accuracy: 0.4318\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0513 - accuracy: 0.4786 - val_loss: 0.2090 - val_accuracy: 0.4091\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0508 - accuracy: 0.4815 - val_loss: 0.1982 - val_accuracy: 0.4205\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0482 - accuracy: 0.4786 - val_loss: 0.1870 - val_accuracy: 0.4205\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0474 - accuracy: 0.4815 - val_loss: 0.1920 - val_accuracy: 0.4318\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0457 - accuracy: 0.4815 - val_loss: 0.2023 - val_accuracy: 0.4205\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0427 - accuracy: 0.4815 - val_loss: 0.2049 - val_accuracy: 0.4205\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0451 - accuracy: 0.4815 - val_loss: 0.1919 - val_accuracy: 0.4318\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0433 - accuracy: 0.4815 - val_loss: 0.1869 - val_accuracy: 0.4432\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0468 - accuracy: 0.4815 - val_loss: 0.1936 - val_accuracy: 0.4318\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0482 - accuracy: 0.4815 - val_loss: 0.1977 - val_accuracy: 0.4091\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0464 - accuracy: 0.4815 - val_loss: 0.1965 - val_accuracy: 0.4205\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0434 - accuracy: 0.4815 - val_loss: 0.1849 - val_accuracy: 0.4318\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0498 - accuracy: 0.4815 - val_loss: 0.1890 - val_accuracy: 0.4205\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0421 - accuracy: 0.4786 - val_loss: 0.1778 - val_accuracy: 0.4432\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0442 - accuracy: 0.4815 - val_loss: 0.1955 - val_accuracy: 0.4091\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0529 - accuracy: 0.4815 - val_loss: 0.2010 - val_accuracy: 0.4318\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0485 - accuracy: 0.4815 - val_loss: 0.2028 - val_accuracy: 0.4091\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0537 - accuracy: 0.4815 - val_loss: 0.1897 - val_accuracy: 0.4318\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0458 - accuracy: 0.4815 - val_loss: 0.2010 - val_accuracy: 0.4091\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0417 - accuracy: 0.4815 - val_loss: 0.1926 - val_accuracy: 0.4432\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0456 - accuracy: 0.4815 - val_loss: 0.1980 - val_accuracy: 0.4432\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0505 - accuracy: 0.4815 - val_loss: 0.2046 - val_accuracy: 0.4205\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0461 - accuracy: 0.4815 - val_loss: 0.2016 - val_accuracy: 0.4091\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0448 - accuracy: 0.4815 - val_loss: 0.2010 - val_accuracy: 0.4091\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0487 - accuracy: 0.4815 - val_loss: 0.2004 - val_accuracy: 0.4091\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0416 - accuracy: 0.4815 - val_loss: 0.2062 - val_accuracy: 0.4091\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0423 - accuracy: 0.4815 - val_loss: 0.1963 - val_accuracy: 0.4205\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0505 - accuracy: 0.4815 - val_loss: 0.1948 - val_accuracy: 0.4205\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0441 - accuracy: 0.4815 - val_loss: 0.2003 - val_accuracy: 0.4091\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0447 - accuracy: 0.4815 - val_loss: 0.2210 - val_accuracy: 0.3864\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0449 - accuracy: 0.4815 - val_loss: 0.2085 - val_accuracy: 0.3864\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0456 - accuracy: 0.4786 - val_loss: 0.2017 - val_accuracy: 0.3977\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0430 - accuracy: 0.4815 - val_loss: 0.1949 - val_accuracy: 0.4318\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0426 - accuracy: 0.4815 - val_loss: 0.1910 - val_accuracy: 0.4432\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0424 - accuracy: 0.4815 - val_loss: 0.1962 - val_accuracy: 0.4318\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0414 - accuracy: 0.4815 - val_loss: 0.2025 - val_accuracy: 0.4091\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0378 - accuracy: 0.4815 - val_loss: 0.1989 - val_accuracy: 0.3977\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0462 - accuracy: 0.4815 - val_loss: 0.1856 - val_accuracy: 0.4432\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0405 - accuracy: 0.4815 - val_loss: 0.2031 - val_accuracy: 0.4091\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0408 - accuracy: 0.4815 - val_loss: 0.1818 - val_accuracy: 0.4432\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0416 - accuracy: 0.4815 - val_loss: 0.1864 - val_accuracy: 0.4205\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0382 - accuracy: 0.4815 - val_loss: 0.1852 - val_accuracy: 0.4318\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0398 - accuracy: 0.4815 - val_loss: 0.2040 - val_accuracy: 0.4091\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0411 - accuracy: 0.4815 - val_loss: 0.1922 - val_accuracy: 0.4318\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0477 - accuracy: 0.4815 - val_loss: 0.1970 - val_accuracy: 0.4318\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0407 - accuracy: 0.4815 - val_loss: 0.1907 - val_accuracy: 0.4205\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0438 - accuracy: 0.4815 - val_loss: 0.1992 - val_accuracy: 0.3977\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0385 - accuracy: 0.4815 - val_loss: 0.2018 - val_accuracy: 0.4091\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0385 - accuracy: 0.4815 - val_loss: 0.1990 - val_accuracy: 0.4318\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0453 - accuracy: 0.4758 - val_loss: 0.1822 - val_accuracy: 0.4432\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0389 - accuracy: 0.4815 - val_loss: 0.1980 - val_accuracy: 0.4091\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0407 - accuracy: 0.4815 - val_loss: 0.1952 - val_accuracy: 0.4205\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0454 - accuracy: 0.4815 - val_loss: 0.1993 - val_accuracy: 0.4091\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0325 - accuracy: 0.4815 - val_loss: 0.1935 - val_accuracy: 0.4432\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0426 - accuracy: 0.4815 - val_loss: 0.1918 - val_accuracy: 0.4318\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0361 - accuracy: 0.4815 - val_loss: 0.2021 - val_accuracy: 0.4205\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0434 - accuracy: 0.4786 - val_loss: 0.1954 - val_accuracy: 0.4432\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0475 - accuracy: 0.4815 - val_loss: 0.2127 - val_accuracy: 0.4091\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0396 - accuracy: 0.4786 - val_loss: 0.2022 - val_accuracy: 0.4318\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0429 - accuracy: 0.4815 - val_loss: 0.2048 - val_accuracy: 0.4318\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0459 - accuracy: 0.4786 - val_loss: 0.1924 - val_accuracy: 0.4318\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0439 - accuracy: 0.4815 - val_loss: 0.1999 - val_accuracy: 0.4091\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0414 - accuracy: 0.4815 - val_loss: 0.1801 - val_accuracy: 0.4432\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0442 - accuracy: 0.4786 - val_loss: 0.2019 - val_accuracy: 0.4318\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0424 - accuracy: 0.4786 - val_loss: 0.1788 - val_accuracy: 0.4432\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0397 - accuracy: 0.4815 - val_loss: 0.1999 - val_accuracy: 0.4091\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0434 - accuracy: 0.4815 - val_loss: 0.1832 - val_accuracy: 0.4205\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0334 - accuracy: 0.4815 - val_loss: 0.1979 - val_accuracy: 0.4205\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0358 - accuracy: 0.4815 - val_loss: 0.1981 - val_accuracy: 0.4318\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0377 - accuracy: 0.4815 - val_loss: 0.1927 - val_accuracy: 0.4318\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0404 - accuracy: 0.4815 - val_loss: 0.2033 - val_accuracy: 0.4091\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0412 - accuracy: 0.4815 - val_loss: 0.1976 - val_accuracy: 0.4205\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0373 - accuracy: 0.4815 - val_loss: 0.2062 - val_accuracy: 0.4091\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0374 - accuracy: 0.4815 - val_loss: 0.1950 - val_accuracy: 0.4205\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0396 - accuracy: 0.4815 - val_loss: 0.2131 - val_accuracy: 0.3977\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0357 - accuracy: 0.4815 - val_loss: 0.2060 - val_accuracy: 0.4205\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0328 - accuracy: 0.4815 - val_loss: 0.2100 - val_accuracy: 0.4205\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0366 - accuracy: 0.4815 - val_loss: 0.1943 - val_accuracy: 0.4318\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0341 - accuracy: 0.4815 - val_loss: 0.1953 - val_accuracy: 0.4318\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0388 - accuracy: 0.4815 - val_loss: 0.1876 - val_accuracy: 0.4432\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0380 - accuracy: 0.4786 - val_loss: 0.1963 - val_accuracy: 0.4205\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0371 - accuracy: 0.4815 - val_loss: 0.1855 - val_accuracy: 0.4318\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0365 - accuracy: 0.4815 - val_loss: 0.1951 - val_accuracy: 0.4205\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0382 - accuracy: 0.4815 - val_loss: 0.1931 - val_accuracy: 0.4205\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0378 - accuracy: 0.4815 - val_loss: 0.2026 - val_accuracy: 0.4205\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0374 - accuracy: 0.4786 - val_loss: 0.1943 - val_accuracy: 0.4318\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0424 - accuracy: 0.4786 - val_loss: 0.1913 - val_accuracy: 0.4205\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0332 - accuracy: 0.4815 - val_loss: 0.1893 - val_accuracy: 0.4205\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0351 - accuracy: 0.4815 - val_loss: 0.1818 - val_accuracy: 0.4205\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0339 - accuracy: 0.4815 - val_loss: 0.2020 - val_accuracy: 0.4205\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0387 - accuracy: 0.4815 - val_loss: 0.1960 - val_accuracy: 0.4318\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0385 - accuracy: 0.4815 - val_loss: 0.2038 - val_accuracy: 0.4205\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0376 - accuracy: 0.4815 - val_loss: 0.1984 - val_accuracy: 0.4318\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0381 - accuracy: 0.4786 - val_loss: 0.2068 - val_accuracy: 0.4318\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0338 - accuracy: 0.4815 - val_loss: 0.2030 - val_accuracy: 0.4205\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0350 - accuracy: 0.4815 - val_loss: 0.1955 - val_accuracy: 0.4205\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0349 - accuracy: 0.4815 - val_loss: 0.1891 - val_accuracy: 0.4318\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0347 - accuracy: 0.4815 - val_loss: 0.1915 - val_accuracy: 0.4091\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0347 - accuracy: 0.4815 - val_loss: 0.1866 - val_accuracy: 0.4318\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0394 - accuracy: 0.4815 - val_loss: 0.1966 - val_accuracy: 0.4318\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0330 - accuracy: 0.4815 - val_loss: 0.1935 - val_accuracy: 0.4091\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0390 - accuracy: 0.4815 - val_loss: 0.1917 - val_accuracy: 0.4205\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0415 - accuracy: 0.4786 - val_loss: 0.1898 - val_accuracy: 0.4318\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0379 - accuracy: 0.4786 - val_loss: 0.1937 - val_accuracy: 0.4205\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0323 - accuracy: 0.4815 - val_loss: 0.1931 - val_accuracy: 0.4205\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0349 - accuracy: 0.4815 - val_loss: 0.1827 - val_accuracy: 0.4318\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0390 - accuracy: 0.4815 - val_loss: 0.1814 - val_accuracy: 0.4205\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0341 - accuracy: 0.4815 - val_loss: 0.1750 - val_accuracy: 0.4318\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0350 - accuracy: 0.4815 - val_loss: 0.1902 - val_accuracy: 0.4205\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0342 - accuracy: 0.4815 - val_loss: 0.1857 - val_accuracy: 0.4205\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0376 - accuracy: 0.4786 - val_loss: 0.1838 - val_accuracy: 0.4432\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0386 - accuracy: 0.4815 - val_loss: 0.1908 - val_accuracy: 0.4205\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0379 - accuracy: 0.4815 - val_loss: 0.1936 - val_accuracy: 0.4318\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0328 - accuracy: 0.4815 - val_loss: 0.2004 - val_accuracy: 0.4091\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0411 - accuracy: 0.4815 - val_loss: 0.1979 - val_accuracy: 0.4205\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0314 - accuracy: 0.4815 - val_loss: 0.2056 - val_accuracy: 0.4091\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0318 - accuracy: 0.4786 - val_loss: 0.1991 - val_accuracy: 0.4091\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0349 - accuracy: 0.4786 - val_loss: 0.2021 - val_accuracy: 0.4091\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0308 - accuracy: 0.4815 - val_loss: 0.1936 - val_accuracy: 0.4318\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0314 - accuracy: 0.4815 - val_loss: 0.1942 - val_accuracy: 0.4432\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0338 - accuracy: 0.4815 - val_loss: 0.1876 - val_accuracy: 0.4432\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0306 - accuracy: 0.4815 - val_loss: 0.1813 - val_accuracy: 0.4205\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0347 - accuracy: 0.4815 - val_loss: 0.1903 - val_accuracy: 0.4205\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0368 - accuracy: 0.4815 - val_loss: 0.1874 - val_accuracy: 0.4318\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0406 - accuracy: 0.4815 - val_loss: 0.2027 - val_accuracy: 0.4091\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0395 - accuracy: 0.4815 - val_loss: 0.1921 - val_accuracy: 0.4318\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0358 - accuracy: 0.4815 - val_loss: 0.2017 - val_accuracy: 0.4205\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0375 - accuracy: 0.4786 - val_loss: 0.1999 - val_accuracy: 0.4205\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0358 - accuracy: 0.4786 - val_loss: 0.1924 - val_accuracy: 0.4318\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0383 - accuracy: 0.4815 - val_loss: 0.1911 - val_accuracy: 0.4432\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0366 - accuracy: 0.4815 - val_loss: 0.2137 - val_accuracy: 0.4091\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0300 - accuracy: 0.4815 - val_loss: 0.2056 - val_accuracy: 0.4205\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0357 - accuracy: 0.4815 - val_loss: 0.2062 - val_accuracy: 0.4205\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0406 - accuracy: 0.4815 - val_loss: 0.1882 - val_accuracy: 0.4432\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0345 - accuracy: 0.4815 - val_loss: 0.1844 - val_accuracy: 0.4318\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0364 - accuracy: 0.4815 - val_loss: 0.1771 - val_accuracy: 0.4318\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0362 - accuracy: 0.4815 - val_loss: 0.1983 - val_accuracy: 0.4205\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0399 - accuracy: 0.4815 - val_loss: 0.1791 - val_accuracy: 0.4432\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0408 - accuracy: 0.4815 - val_loss: 0.1883 - val_accuracy: 0.4318\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0382 - accuracy: 0.4815 - val_loss: 0.1911 - val_accuracy: 0.4205\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0328 - accuracy: 0.4815 - val_loss: 0.1918 - val_accuracy: 0.4205\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0324 - accuracy: 0.4786 - val_loss: 0.1851 - val_accuracy: 0.4205\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0327 - accuracy: 0.4815 - val_loss: 0.1855 - val_accuracy: 0.4205\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0386 - accuracy: 0.4815 - val_loss: 0.1947 - val_accuracy: 0.4205\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0291 - accuracy: 0.4815 - val_loss: 0.2026 - val_accuracy: 0.4205\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0297 - accuracy: 0.4815 - val_loss: 0.2048 - val_accuracy: 0.4318\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0281 - accuracy: 0.4815 - val_loss: 0.2013 - val_accuracy: 0.4318\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0338 - accuracy: 0.4815 - val_loss: 0.1984 - val_accuracy: 0.4318\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0286 - accuracy: 0.4815 - val_loss: 0.1998 - val_accuracy: 0.4205\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0274 - accuracy: 0.4815 - val_loss: 0.1842 - val_accuracy: 0.4318\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0329 - accuracy: 0.4815 - val_loss: 0.1973 - val_accuracy: 0.4318\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0279 - accuracy: 0.4815 - val_loss: 0.1981 - val_accuracy: 0.4318\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0297 - accuracy: 0.4815 - val_loss: 0.2039 - val_accuracy: 0.4205\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0262 - accuracy: 0.4815 - val_loss: 0.2051 - val_accuracy: 0.4205\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0289 - accuracy: 0.4815 - val_loss: 0.1990 - val_accuracy: 0.4205\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0292 - accuracy: 0.4815 - val_loss: 0.1984 - val_accuracy: 0.4205\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0301 - accuracy: 0.4815 - val_loss: 0.1929 - val_accuracy: 0.4318\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0315 - accuracy: 0.4815 - val_loss: 0.2119 - val_accuracy: 0.3977\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0327 - accuracy: 0.4786 - val_loss: 0.1926 - val_accuracy: 0.4318\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0312 - accuracy: 0.4815 - val_loss: 0.2085 - val_accuracy: 0.4205\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0312 - accuracy: 0.4815 - val_loss: 0.1874 - val_accuracy: 0.4205\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0317 - accuracy: 0.4815 - val_loss: 0.2108 - val_accuracy: 0.3977\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0435 - accuracy: 0.4786 - val_loss: 0.1921 - val_accuracy: 0.4432\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0456 - accuracy: 0.4815 - val_loss: 0.2165 - val_accuracy: 0.4205\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0472 - accuracy: 0.4815 - val_loss: 0.1949 - val_accuracy: 0.4432\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0440 - accuracy: 0.4815 - val_loss: 0.1949 - val_accuracy: 0.4205\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0329 - accuracy: 0.4815 - val_loss: 0.1907 - val_accuracy: 0.4205\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0344 - accuracy: 0.4815 - val_loss: 0.1928 - val_accuracy: 0.4205\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0350 - accuracy: 0.4815 - val_loss: 0.1906 - val_accuracy: 0.4432\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0334 - accuracy: 0.4815 - val_loss: 0.1945 - val_accuracy: 0.4205\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0348 - accuracy: 0.4815 - val_loss: 0.1874 - val_accuracy: 0.4432\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0397 - accuracy: 0.4815 - val_loss: 0.1936 - val_accuracy: 0.4432\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0370 - accuracy: 0.4815 - val_loss: 0.2021 - val_accuracy: 0.4205\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0322 - accuracy: 0.4815 - val_loss: 0.1992 - val_accuracy: 0.4205\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0307 - accuracy: 0.4815 - val_loss: 0.2051 - val_accuracy: 0.4205\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0329 - accuracy: 0.4815 - val_loss: 0.2094 - val_accuracy: 0.4205\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0286 - accuracy: 0.4815 - val_loss: 0.2048 - val_accuracy: 0.4318\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0366 - accuracy: 0.4758 - val_loss: 0.2015 - val_accuracy: 0.4091\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0357 - accuracy: 0.4815 - val_loss: 0.1892 - val_accuracy: 0.4205\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0313 - accuracy: 0.4815 - val_loss: 0.2012 - val_accuracy: 0.4091\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0291 - accuracy: 0.4815 - val_loss: 0.1909 - val_accuracy: 0.4205\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0309 - accuracy: 0.4815 - val_loss: 0.1898 - val_accuracy: 0.4432\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0372 - accuracy: 0.4786 - val_loss: 0.1822 - val_accuracy: 0.4432\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0310 - accuracy: 0.4786 - val_loss: 0.1893 - val_accuracy: 0.4091\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0369 - accuracy: 0.4786 - val_loss: 0.1946 - val_accuracy: 0.4318\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0346 - accuracy: 0.4815 - val_loss: 0.2171 - val_accuracy: 0.3977\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0289 - accuracy: 0.4815 - val_loss: 0.2016 - val_accuracy: 0.4205\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0306 - accuracy: 0.4815 - val_loss: 0.2123 - val_accuracy: 0.4205\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0278 - accuracy: 0.4815 - val_loss: 0.2079 - val_accuracy: 0.4432\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0388 - accuracy: 0.4786 - val_loss: 0.2214 - val_accuracy: 0.4205\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0310 - accuracy: 0.4815 - val_loss: 0.2206 - val_accuracy: 0.3977\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0308 - accuracy: 0.4786 - val_loss: 0.2058 - val_accuracy: 0.3977\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0298 - accuracy: 0.4786 - val_loss: 0.1942 - val_accuracy: 0.3977\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0317 - accuracy: 0.4786 - val_loss: 0.1910 - val_accuracy: 0.4432\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0285 - accuracy: 0.4815 - val_loss: 0.1939 - val_accuracy: 0.4205\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0316 - accuracy: 0.4786 - val_loss: 0.1889 - val_accuracy: 0.4318\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0304 - accuracy: 0.4786 - val_loss: 0.2012 - val_accuracy: 0.4091\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0292 - accuracy: 0.4815 - val_loss: 0.2052 - val_accuracy: 0.4091\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0359 - accuracy: 0.4786 - val_loss: 0.1937 - val_accuracy: 0.4205\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0269 - accuracy: 0.4815 - val_loss: 0.1959 - val_accuracy: 0.4205\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0334 - accuracy: 0.4815 - val_loss: 0.2004 - val_accuracy: 0.4318\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0262 - accuracy: 0.4815 - val_loss: 0.1914 - val_accuracy: 0.4318\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0325 - accuracy: 0.4815 - val_loss: 0.2079 - val_accuracy: 0.4091\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0333 - accuracy: 0.4815 - val_loss: 0.1992 - val_accuracy: 0.4318\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0347 - accuracy: 0.4815 - val_loss: 0.2095 - val_accuracy: 0.4091\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0252 - accuracy: 0.4815 - val_loss: 0.2050 - val_accuracy: 0.4091\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0284 - accuracy: 0.4815 - val_loss: 0.2011 - val_accuracy: 0.4091\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0322 - accuracy: 0.4815 - val_loss: 0.1848 - val_accuracy: 0.4318\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0319 - accuracy: 0.4815 - val_loss: 0.1896 - val_accuracy: 0.4205\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0330 - accuracy: 0.4815 - val_loss: 0.1970 - val_accuracy: 0.4205\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0300 - accuracy: 0.4786 - val_loss: 0.1950 - val_accuracy: 0.4091\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0291 - accuracy: 0.4786 - val_loss: 0.1838 - val_accuracy: 0.4318\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0306 - accuracy: 0.4815 - val_loss: 0.1978 - val_accuracy: 0.4091\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0286 - accuracy: 0.4815 - val_loss: 0.1824 - val_accuracy: 0.4318\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0277 - accuracy: 0.4815 - val_loss: 0.1990 - val_accuracy: 0.4205\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0324 - accuracy: 0.4786 - val_loss: 0.1939 - val_accuracy: 0.4318\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0315 - accuracy: 0.4815 - val_loss: 0.2014 - val_accuracy: 0.4205\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0278 - accuracy: 0.4815 - val_loss: 0.1919 - val_accuracy: 0.4318\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0296 - accuracy: 0.4815 - val_loss: 0.1916 - val_accuracy: 0.4205\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0279 - accuracy: 0.4815 - val_loss: 0.1947 - val_accuracy: 0.4318\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0289 - accuracy: 0.4815 - val_loss: 0.2050 - val_accuracy: 0.4205\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0273 - accuracy: 0.4815 - val_loss: 0.1916 - val_accuracy: 0.4205\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0236 - accuracy: 0.4815 - val_loss: 0.1966 - val_accuracy: 0.4205\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0283 - accuracy: 0.4815 - val_loss: 0.2019 - val_accuracy: 0.4318\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0312 - accuracy: 0.4815 - val_loss: 0.1868 - val_accuracy: 0.4318\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0286 - accuracy: 0.4815 - val_loss: 0.1965 - val_accuracy: 0.4205\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0262 - accuracy: 0.4815 - val_loss: 0.1951 - val_accuracy: 0.4205\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0295 - accuracy: 0.4815 - val_loss: 0.1841 - val_accuracy: 0.4318\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0298 - accuracy: 0.4815 - val_loss: 0.1897 - val_accuracy: 0.4318\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0286 - accuracy: 0.4786 - val_loss: 0.1894 - val_accuracy: 0.4318\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0260 - accuracy: 0.4815 - val_loss: 0.1953 - val_accuracy: 0.4091\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0266 - accuracy: 0.4815 - val_loss: 0.2052 - val_accuracy: 0.3977\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0313 - accuracy: 0.4758 - val_loss: 0.1945 - val_accuracy: 0.4318\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0331 - accuracy: 0.4815 - val_loss: 0.2004 - val_accuracy: 0.4205\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0340 - accuracy: 0.4815 - val_loss: 0.1881 - val_accuracy: 0.4432\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0359 - accuracy: 0.4815 - val_loss: 0.2060 - val_accuracy: 0.4205\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0283 - accuracy: 0.4815 - val_loss: 0.1996 - val_accuracy: 0.4318\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0347 - accuracy: 0.4815 - val_loss: 0.2119 - val_accuracy: 0.4205\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0352 - accuracy: 0.4815 - val_loss: 0.1957 - val_accuracy: 0.4318\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0270 - accuracy: 0.4815 - val_loss: 0.1941 - val_accuracy: 0.4091\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0331 - accuracy: 0.4786 - val_loss: 0.1900 - val_accuracy: 0.4318\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0229 - accuracy: 0.4815 - val_loss: 0.1982 - val_accuracy: 0.4205\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0287 - accuracy: 0.4815 - val_loss: 0.1919 - val_accuracy: 0.4205\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0312 - accuracy: 0.4815 - val_loss: 0.1942 - val_accuracy: 0.4432\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0304 - accuracy: 0.4815 - val_loss: 0.1987 - val_accuracy: 0.4205\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0278 - accuracy: 0.4815 - val_loss: 0.1892 - val_accuracy: 0.4318\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0297 - accuracy: 0.4815 - val_loss: 0.1919 - val_accuracy: 0.4432\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0294 - accuracy: 0.4815 - val_loss: 0.1871 - val_accuracy: 0.4318\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0273 - accuracy: 0.4786 - val_loss: 0.1877 - val_accuracy: 0.4205\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0297 - accuracy: 0.4815 - val_loss: 0.1883 - val_accuracy: 0.4205\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0264 - accuracy: 0.4815 - val_loss: 0.1805 - val_accuracy: 0.4318\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0293 - accuracy: 0.4815 - val_loss: 0.1783 - val_accuracy: 0.4318\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0314 - accuracy: 0.4815 - val_loss: 0.1786 - val_accuracy: 0.4318\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0266 - accuracy: 0.4815 - val_loss: 0.1800 - val_accuracy: 0.4205\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0244 - accuracy: 0.4815 - val_loss: 0.1845 - val_accuracy: 0.4205\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0297 - accuracy: 0.4815 - val_loss: 0.1919 - val_accuracy: 0.4091\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0265 - accuracy: 0.4815 - val_loss: 0.1970 - val_accuracy: 0.4091\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0290 - accuracy: 0.4786 - val_loss: 0.1921 - val_accuracy: 0.4091\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0221 - accuracy: 0.4815 - val_loss: 0.1879 - val_accuracy: 0.4205\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0284 - accuracy: 0.4786 - val_loss: 0.1839 - val_accuracy: 0.4091\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0285 - accuracy: 0.4786 - val_loss: 0.1885 - val_accuracy: 0.4091\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0360 - accuracy: 0.4786 - val_loss: 0.1921 - val_accuracy: 0.4091\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0229 - accuracy: 0.4815 - val_loss: 0.1902 - val_accuracy: 0.4205\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0316 - accuracy: 0.4786 - val_loss: 0.1969 - val_accuracy: 0.4205\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0284 - accuracy: 0.4786 - val_loss: 0.1868 - val_accuracy: 0.4205\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0320 - accuracy: 0.4815 - val_loss: 0.1937 - val_accuracy: 0.4091\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0332 - accuracy: 0.4815 - val_loss: 0.1864 - val_accuracy: 0.4205\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0259 - accuracy: 0.4815 - val_loss: 0.1901 - val_accuracy: 0.4205\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0293 - accuracy: 0.4786 - val_loss: 0.1988 - val_accuracy: 0.4091\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0333 - accuracy: 0.4786 - val_loss: 0.2011 - val_accuracy: 0.4205\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0279 - accuracy: 0.4815 - val_loss: 0.2010 - val_accuracy: 0.4318\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0359 - accuracy: 0.4786 - val_loss: 0.1988 - val_accuracy: 0.4318\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0299 - accuracy: 0.4786 - val_loss: 0.1946 - val_accuracy: 0.4205\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0315 - accuracy: 0.4815 - val_loss: 0.1968 - val_accuracy: 0.4091\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0301 - accuracy: 0.4815 - val_loss: 0.1873 - val_accuracy: 0.4205\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0306 - accuracy: 0.4786 - val_loss: 0.1861 - val_accuracy: 0.4091\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0287 - accuracy: 0.4815 - val_loss: 0.1942 - val_accuracy: 0.4091\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0292 - accuracy: 0.4815 - val_loss: 0.1999 - val_accuracy: 0.4091\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0319 - accuracy: 0.4815 - val_loss: 0.1960 - val_accuracy: 0.4091\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0295 - accuracy: 0.4815 - val_loss: 0.1961 - val_accuracy: 0.4091\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0253 - accuracy: 0.4815 - val_loss: 0.1992 - val_accuracy: 0.4205\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0269 - accuracy: 0.4815 - val_loss: 0.1955 - val_accuracy: 0.4205\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0268 - accuracy: 0.4815 - val_loss: 0.2026 - val_accuracy: 0.4091\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0276 - accuracy: 0.4815 - val_loss: 0.1938 - val_accuracy: 0.4205\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0286 - accuracy: 0.4815 - val_loss: 0.2044 - val_accuracy: 0.3864\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0330 - accuracy: 0.4815 - val_loss: 0.1810 - val_accuracy: 0.4205\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0291 - accuracy: 0.4815 - val_loss: 0.1848 - val_accuracy: 0.3977\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0289 - accuracy: 0.4815 - val_loss: 0.1849 - val_accuracy: 0.4318\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0298 - accuracy: 0.4815 - val_loss: 0.1944 - val_accuracy: 0.4091\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0300 - accuracy: 0.4815 - val_loss: 0.1801 - val_accuracy: 0.4318\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0330 - accuracy: 0.4815 - val_loss: 0.1907 - val_accuracy: 0.4205\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0335 - accuracy: 0.4815 - val_loss: 0.1895 - val_accuracy: 0.4318\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0352 - accuracy: 0.4815 - val_loss: 0.1993 - val_accuracy: 0.4091\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0303 - accuracy: 0.4815 - val_loss: 0.1872 - val_accuracy: 0.4318\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0290 - accuracy: 0.4786 - val_loss: 0.1881 - val_accuracy: 0.4091\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0297 - accuracy: 0.4815 - val_loss: 0.1926 - val_accuracy: 0.4205\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0329 - accuracy: 0.4815 - val_loss: 0.1930 - val_accuracy: 0.4318\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0278 - accuracy: 0.4815 - val_loss: 0.1808 - val_accuracy: 0.4205\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0238 - accuracy: 0.4815 - val_loss: 0.1787 - val_accuracy: 0.4318\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0263 - accuracy: 0.4815 - val_loss: 0.1909 - val_accuracy: 0.4318\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0268 - accuracy: 0.4815 - val_loss: 0.1964 - val_accuracy: 0.4205\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0244 - accuracy: 0.4815 - val_loss: 0.2026 - val_accuracy: 0.4205\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0290 - accuracy: 0.4815 - val_loss: 0.1987 - val_accuracy: 0.4318\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0267 - accuracy: 0.4815 - val_loss: 0.2010 - val_accuracy: 0.4318\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0251 - accuracy: 0.4815 - val_loss: 0.1993 - val_accuracy: 0.4432\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0255 - accuracy: 0.4815 - val_loss: 0.2062 - val_accuracy: 0.4205\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0269 - accuracy: 0.4815 - val_loss: 0.1984 - val_accuracy: 0.4205\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0257 - accuracy: 0.4786 - val_loss: 0.1976 - val_accuracy: 0.4205\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0253 - accuracy: 0.4815 - val_loss: 0.1971 - val_accuracy: 0.4205\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0231 - accuracy: 0.4815 - val_loss: 0.2025 - val_accuracy: 0.4205\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0265 - accuracy: 0.4815 - val_loss: 0.2063 - val_accuracy: 0.4205\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0267 - accuracy: 0.4758 - val_loss: 0.2023 - val_accuracy: 0.4205\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0283 - accuracy: 0.4815 - val_loss: 0.1973 - val_accuracy: 0.4205\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0244 - accuracy: 0.4815 - val_loss: 0.1997 - val_accuracy: 0.4091\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0267 - accuracy: 0.4815 - val_loss: 0.2102 - val_accuracy: 0.4205\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0279 - accuracy: 0.4815 - val_loss: 0.2054 - val_accuracy: 0.4091\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0329 - accuracy: 0.4786 - val_loss: 0.1930 - val_accuracy: 0.4205\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0274 - accuracy: 0.4815 - val_loss: 0.1820 - val_accuracy: 0.4318\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0315 - accuracy: 0.4786 - val_loss: 0.1886 - val_accuracy: 0.4318\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0301 - accuracy: 0.4786 - val_loss: 0.1975 - val_accuracy: 0.4318\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0278 - accuracy: 0.4815 - val_loss: 0.1982 - val_accuracy: 0.4205\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0255 - accuracy: 0.4815 - val_loss: 0.1970 - val_accuracy: 0.4205\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0249 - accuracy: 0.4815 - val_loss: 0.2010 - val_accuracy: 0.4318\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0234 - accuracy: 0.4815 - val_loss: 0.1974 - val_accuracy: 0.4091\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0249 - accuracy: 0.4786 - val_loss: 0.1939 - val_accuracy: 0.4091\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0250 - accuracy: 0.4815 - val_loss: 0.2078 - val_accuracy: 0.3977\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0236 - accuracy: 0.4786 - val_loss: 0.1995 - val_accuracy: 0.4205\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0256 - accuracy: 0.4815 - val_loss: 0.2040 - val_accuracy: 0.4091\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0272 - accuracy: 0.4815 - val_loss: 0.2076 - val_accuracy: 0.4091\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0304 - accuracy: 0.4786 - val_loss: 0.2109 - val_accuracy: 0.3864\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0263 - accuracy: 0.4815 - val_loss: 0.1931 - val_accuracy: 0.4318\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0257 - accuracy: 0.4815 - val_loss: 0.1995 - val_accuracy: 0.4318\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0213 - accuracy: 0.4815 - val_loss: 0.1953 - val_accuracy: 0.4318\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0264 - accuracy: 0.4815 - val_loss: 0.1869 - val_accuracy: 0.4205\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0307 - accuracy: 0.4815 - val_loss: 0.1844 - val_accuracy: 0.4318\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0242 - accuracy: 0.4815 - val_loss: 0.1863 - val_accuracy: 0.4205\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0296 - accuracy: 0.4815 - val_loss: 0.1818 - val_accuracy: 0.4205\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0307 - accuracy: 0.4815 - val_loss: 0.1861 - val_accuracy: 0.4091\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0245 - accuracy: 0.4815 - val_loss: 0.1958 - val_accuracy: 0.4205\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0235 - accuracy: 0.4815 - val_loss: 0.1900 - val_accuracy: 0.4205\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0265 - accuracy: 0.4815 - val_loss: 0.1873 - val_accuracy: 0.4205\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0258 - accuracy: 0.4786 - val_loss: 0.1972 - val_accuracy: 0.3977\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0233 - accuracy: 0.4815 - val_loss: 0.2066 - val_accuracy: 0.4205\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0234 - accuracy: 0.4815 - val_loss: 0.2069 - val_accuracy: 0.3864\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0277 - accuracy: 0.4786 - val_loss: 0.2008 - val_accuracy: 0.4091\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0291 - accuracy: 0.4815 - val_loss: 0.2036 - val_accuracy: 0.4205\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0240 - accuracy: 0.4815 - val_loss: 0.2091 - val_accuracy: 0.4205\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0257 - accuracy: 0.4815 - val_loss: 0.2063 - val_accuracy: 0.4205\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0272 - accuracy: 0.4815 - val_loss: 0.1951 - val_accuracy: 0.4432\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0338 - accuracy: 0.4786 - val_loss: 0.2087 - val_accuracy: 0.3977\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0288 - accuracy: 0.4815 - val_loss: 0.1898 - val_accuracy: 0.4432\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0271 - accuracy: 0.4815 - val_loss: 0.2060 - val_accuracy: 0.4091\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0297 - accuracy: 0.4815 - val_loss: 0.2053 - val_accuracy: 0.4205\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0297 - accuracy: 0.4786 - val_loss: 0.2076 - val_accuracy: 0.4205\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0224 - accuracy: 0.4815 - val_loss: 0.2001 - val_accuracy: 0.4091\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0261 - accuracy: 0.4786 - val_loss: 0.1970 - val_accuracy: 0.4091\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0318 - accuracy: 0.4758 - val_loss: 0.2045 - val_accuracy: 0.4205\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0253 - accuracy: 0.4786 - val_loss: 0.2029 - val_accuracy: 0.4205\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0262 - accuracy: 0.4815 - val_loss: 0.1987 - val_accuracy: 0.4205\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0300 - accuracy: 0.4786 - val_loss: 0.2048 - val_accuracy: 0.4205\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0241 - accuracy: 0.4786 - val_loss: 0.1968 - val_accuracy: 0.4205\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0250 - accuracy: 0.4815 - val_loss: 0.1911 - val_accuracy: 0.4205\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0201 - accuracy: 0.4815 - val_loss: 0.1880 - val_accuracy: 0.4205\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0198 - accuracy: 0.4815 - val_loss: 0.2001 - val_accuracy: 0.4205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "DfLsoFt18VsM",
        "outputId": "9945939f-ebbe-4af3-99b7-45fc19b8609c"
      },
      "source": [
        "# графическое отображение работы сети\n",
        "plt.plot(history.history['loss'], \n",
        "         label='Средняя абсолютная ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], \n",
        "         label='Средняя абсолютная ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('Средняя абсолютная ошибка')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gDo9uaU-x5G",
        "outputId": "514f8984-c095-44b6-edf7-b4faae292649"
      },
      "source": [
        "model.save('/content/drive/MyDrive/datasets/kaggle/my_model') # сохраним обученную модель"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/datasets/kaggle/my_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nktR-EzWHZwx"
      },
      "source": [
        "### Проверим результат работы на тестовых данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vMl8R9hqJFk"
      },
      "source": [
        "prediction = model.predict(x_test).flatten() # сделаем предсказание нашей моделью тестовой выборки\n",
        "# зададим ответ в нужном формате для соревнования в kaggle\n",
        "submission = pd.DataFrame({\"Id\":range(1,len(prediction)+1),\"Label\":prediction})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "TZ4MYEK0VUEp",
        "outputId": "89669d9d-1650-47fd-85cb-af93247abcb7"
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.098012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.288823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.089241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.033490</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id     Label\n",
              "0   1  0.098012\n",
              "1   2  0.288823\n",
              "2   3  0.089241\n",
              "3   4  0.000320\n",
              "4   5  0.033490"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OGNVpoMV2cc"
      },
      "source": [
        "# запишем ответ в файл\n",
        "submission = submission.to_csv('./submission01_forest_file.csv',index=False,header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZozVjgyMq5gy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe24c44f-2534-4a91-b6fc-6a506f0d55f1"
      },
      "source": [
        "# передадим файл для участия в соревновании на kaggle\n",
        "!kaggle competitions submit -c udt-3-regression -f submission01_forest_file.csv -m \"Message\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "100% 1.17k/1.17k [00:01<00:00, 763B/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/cli.py\", line 64, in main\n",
            "    print(out, end='')\n",
            "UnicodeEncodeError: 'latin-1' codec can't encode characters in position 26-36: ordinal not in range(256)\n"
          ]
        }
      ]
    }
  ]
}