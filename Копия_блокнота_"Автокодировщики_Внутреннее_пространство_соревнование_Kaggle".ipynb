{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"Автокодировщики. Внутреннее пространство. - соревнование Kaggle\"",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vadim-privalov/Neiroset_Novosibirsk/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22%D0%90%D0%B2%D1%82%D0%BE%D0%BA%D0%BE%D0%B4%D0%B8%D1%80%D0%BE%D0%B2%D1%89%D0%B8%D0%BA%D0%B8_%D0%92%D0%BD%D1%83%D1%82%D1%80%D0%B5%D0%BD%D0%BD%D0%B5%D0%B5_%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D1%81%D1%82%D0%B2%D0%BE_%D1%81%D0%BE%D1%80%D0%B5%D0%B2%D0%BD%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_Kaggle%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVQjRFc6abYJ"
      },
      "source": [
        "## ООО \"Университет Цифровых Технологий платформа 3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqxNE_33bjuB"
      },
      "source": [
        "# Автокодировщики. Внутреннее пространство. - соревнование Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIHVMw0XnXBp"
      },
      "source": [
        "! Не забудьте создать копию ноутбука и в ней работать, чтобы она у Вас сохранилась с Вашими данными работы и обучения в ячейках: Файл - сохранить копию на Диске.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M77ZiM9UFnGz"
      },
      "source": [
        "### Установка и загрузка необходимых модулей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKPmn-wwtSTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f928bec1-8574-412c-f34d-c3d20c0685f6"
      },
      "source": [
        "# устанавливаем свежий Kaggle API\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaggle\n",
            "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 3.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=08adb4e964695fafb3559f8b82399b596de6f89df34f3501bc8f7202c4ae6e80\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i70Nwdf30uqS"
      },
      "source": [
        "! После установки рекомендуется перезапустить среду выполнения во избежание ошибок запуска ячеек."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCnTHeB-Ysfj"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape, Input, Conv2DTranspose, MaxPooling2D, Conv2D, BatchNormalization\n",
        "#from tensorflow.keras import backend as K \n",
        "from tensorflow.keras.optimizers import Adam \n",
        "#from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import utils \n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "from tensorflow.keras.preprocessing import image \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import random\n",
        "from PIL import Image \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample #для перемешивания выборок \n",
        "from skimage import color\n",
        "import cv2\n",
        "\n",
        "import os \n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DWgrLxLLzXd"
      },
      "source": [
        "# Определение мошеннических транзакций"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8USkuMZaxQP0"
      },
      "source": [
        "#Домашнее задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2Q6N3YvxZHZ"
      },
      "source": [
        "##**Задание 1.** \n",
        "Загрузите из датасета по ссылке ниже базы транзакций - тренировочную и базу для тестирования. С помощью методов, изученных в занятиях по работе с таблицами Pandas, Анализ и обработка данных, и данном занятии, обработайте датасет и подайте в нейронную сеть, постаравшись добиться максимальной точности распознавания. Для улучшения обучения можно использовать также дополнительные методы, не рассмотренные в занятиях, слои, функции активации, менять параметры оптимизатора Adam и прочие гиперпараметры. Результаты рекомендуется заносить в таблицу для себя, чтобы можно было потом воспроизвести лучший вариант. Предсказание Вашей сети необходимо отправить в виде специального файла с расширением csv, чтобы войти в рейтинговую таблицу соревнования. Ответ можно улучшить и подавать результат несколько раз.\n",
        "\n",
        "Ссылка на соревнование:\n",
        "\n",
        "https://www.kaggle.com/t/15b5dc2793de454cb5499a2cdfe17311\n",
        "\n",
        "Ссылка на общемировое соревнование: \n",
        "\n",
        "https://www.kaggle.com/mlg-ulb/creditcardfraud\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvoazCaTMb1m"
      },
      "source": [
        "Будем использовать датасет нормальных и мошеннических операций, ссылка на источники представлена ниже.\n",
        "\n",
        "Важно, чтобы компании, выпускающие кредитные карты, могли распознавать мошеннические транзакции по кредитным картам, чтобы с клиентов не взималась плата за товары, которые они не купили.\n",
        "\n",
        "**Содержание**\n",
        "\n",
        "Набор данных содержит транзакции, совершенные европейскими держателями кредитных карт в сентябре 2013 года.\n",
        "В этом наборе данных представлены транзакции, которые произошли за два дня, из которых у нас 492 мошенничества из 284 807 транзакций. Набор данных сильно несбалансирован, на положительный класс (мошенничество) приходится 0,172% всех транзакций.\n",
        "\n",
        "Он содержит только числовые входные переменные, которые являются результатом преобразования PCA. К сожалению, из-за проблем с конфиденциальностью мы не можем предоставить исходные функции и дополнительную справочную информацию о данных. Характеристики V1, V2,… V28 - это основные компоненты, полученные с помощью PCA, единственными функциями, которые не были преобразованы с помощью PCA, являются «Время» и «Сумма». Функция «Время» содержит секунды, прошедшие между каждой транзакцией и первой транзакцией в наборе данных. Функция «Сумма» - это сумма транзакции, эту функцию можно использовать для обучения, зависящего от стоимости, в зависимости от примера. Функция «Класс» - это переменная ответа, которая принимает значение 1 в случае мошенничества и 0 в противном случае.\n",
        "\n",
        "Учитывая коэффициент дисбаланса класса, мы рекомендуем измерять точность, используя площадь под кривой точности-отзыва (AUPRC). Точность матрицы неточностей не имеет значения для несбалансированной классификации.\n",
        "\n",
        "Представленный на соревнование датасет уже не имеет столбцов «Время» и «Сумма», а мошеннические операции смешаны с аналогичным числом нормальных и помещены в тестовую выборку для формирования ответов. Задача - обработать и подать данные так, чтобы получить наибольшее совпадение предсказанных меток с верными.\n",
        "\n",
        "Ссылка на источник:\n",
        "\n",
        "Сollaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be)\n",
        "\n",
        "https://www.researchgate.net/project/Fraud-detection-5\n",
        "\n",
        "Публикации по работе над датасетом:\n",
        "\n",
        "Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015\n",
        "\n",
        "Dal Pozzolo, Andrea; Caelen, Olivier; Le Borgne, Yann-Ael; Waterschoot, Serge; Bontempi, Gianluca. Learned lessons in credit card fraud detection from a practitioner perspective, Expert systems with applications,41,10,4915-4928,2014, Pergamon\n",
        "\n",
        "Dal Pozzolo, Andrea; Boracchi, Giacomo; Caelen, Olivier; Alippi, Cesare; Bontempi, Gianluca. Credit card fraud detection: a realistic modeling and a novel learning strategy, IEEE transactions on neural networks and learning systems,29,8,3784-3797,2018,IEEE\n",
        "\n",
        "Dal Pozzolo, Andrea Adaptive Machine learning for credit card fraud detection ULB MLG PhD thesis (supervised by G. Bontempi)\n",
        "\n",
        "Carcillo, Fabrizio; Dal Pozzolo, Andrea; Le Borgne, Yann-Aël; Caelen, Olivier; Mazzer, Yannis; Bontempi, Gianluca. Scarff: a scalable framework for streaming credit card fraud detection with Spark, Information fusion,41, 182-194,2018,Elsevier\n",
        "\n",
        "Carcillo, Fabrizio; Le Borgne, Yann-Aël; Caelen, Olivier; Bontempi, Gianluca. Streaming active learning strategies for real-life credit card fraud detection: assessment and visualization, International Journal of Data Science and Analytics, 5,4,285-300,2018,Springer International Publishing\n",
        "\n",
        "Bertrand Lebichot, Yann-Aël Le Borgne, Liyun He, Frederic Oblé, Gianluca Bontempi Deep-Learning Domain Adaptation Techniques for Credit Cards Fraud Detection, INNSBDDL 2019: Recent Advances in Big Data and Deep Learning, pp 78-88, 2019\n",
        "\n",
        "Fabrizio Carcillo, Yann-Aël Le Borgne, Olivier Caelen, Frederic Oblé, Gianluca Bontempi Combining Unsupervised and Supervised Learning in Credit Card Fraud Detection Information Sciences, 2019\n",
        "\n",
        "Yann-Aël Le Borgne, Gianluca Bontempi Machine Learning for Credit Card Fraud Detection - Practical Handbook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSVxut7ZBnPS"
      },
      "source": [
        "##Решение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWrlu3Vl2E3c"
      },
      "source": [
        "#### Создаём правильную папку для ключа Каггл"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUpEMyAVEv3z"
      },
      "source": [
        "!mkdir ~/.kaggle # создаём папку для ключа kaggle в Колабе, она должна быть такой по требованию Каггл"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll5gq1rhE1ay",
        "outputId": "191603b2-4cd0-4779-9b81-3d7a18d5a34b"
      },
      "source": [
        "# переходим в папку, теперь это путь по умолчанию\n",
        "%cd ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.kaggle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1SgDLkZES1J",
        "outputId": "3d607440-20ea-444c-824f-a238bfdbd692"
      },
      "source": [
        "#запускаем - подключаем Google Drive - будем скачивать с него, т.к. намного быстрее\n",
        "#после запуска переходим по ссылке, которая появится, для идентификации\n",
        "#копируем оттуда код authorization code и вставляем здесь в окошко\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLdGz2mH1hTr"
      },
      "source": [
        "#### Устанавливаем ключ Каггл, чтобы участвовать в соревнованиях\n",
        "\n",
        "Нужно зарегистрироваться на Каггл (https://www.kaggle.com/) и скачать ключ для взаимодействия с API соревновательной системы Каггла. После регистрации, справа появятся Ваши имя и фамилия - ссылка на персональную страницу. Нажмите на них. Когда страница загрузится, справа увидите Account. Нажимаете на надпись, затем прокручиваете страницу вниз, до вкладки API, там нажимаете Create New API Token. \n",
        "Ключ - это файл kaggle.json, который скачается после нажатия. Нужно скопировать его в папку Google Drive, предварительно её создав: My Drive/datasets/kaggle/ (из Колаба её адрес, который будем указывать для загрузки, такой: /content/drive/My Drive/datasets/kaggle/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvC38DWIKTk9"
      },
      "source": [
        "# нужно зарегистрироваться на Каггл и скачать ключ для взаимодействия с API\n",
        "# соревновательной системы Каггла kaggle.json. Нужно скопировать его в папку\n",
        "# Google Drive, предварительно её создав: /content/drive/My Drive/datasets/kaggle/\n",
        "!cp '/content/drive/My Drive/datasets/kaggle/kaggle.json' '/root/.kaggle/kaggle.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM42Vv3Dn-zR",
        "outputId": "ae54e6b6-5546-4b9c-dbd2-b511c31c6b0b"
      },
      "source": [
        "!kaggle --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API 1.5.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfTt9PCBOHnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af82145-1b36-465d-9746-ed423ea45025"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgbMKza8fqYv"
      },
      "source": [
        "###Подключаемся к системе соревнований, скачиваем датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LTsZrt7OMch",
        "outputId": "b13a5301-62f7-4d64-9dc0-a1762b922162"
      },
      "source": [
        "!kaggle competitions download -c udt-3-autoencod # скачиваем датасет и тестовые данные"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading udt-3-autoencod.zip to /root/.kaggle\n",
            " 92% 55.0M/59.6M [00:00<00:00, 129MB/s]\n",
            "100% 59.6M/59.6M [00:00<00:00, 117MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5w7lkJ39tGk"
      },
      "source": [
        "###Разархивируем датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ryi1oXpzffef",
        "outputId": "172e5454-aea1-46a0-d961-dd3585e25a1f"
      },
      "source": [
        "# разархивируем данные\n",
        "import zipfile \n",
        "import io\n",
        "z = zipfile.ZipFile('udt-3-autoencod.zip', 'r') #загрузили из архива, распаковали\n",
        "z.extractall()\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json  sampleSubmission.csv  train_test_fd.npz  udt-3-autoencod.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwT1sV8WTo7F"
      },
      "source": [
        "datasets = np.load('/content/drive/MyDrive/datasets/kaggle/train_test_fd.npz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlBEUnx4ajCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc54e88-63f2-4c4a-fc20-485f62301f7a"
      },
      "source": [
        "datasets.files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['x_train', 'x_test']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kjZVFvNb7qf"
      },
      "source": [
        "x_train = datasets['x_train']\n",
        "x_test = datasets['x_test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9HzdYB_XHXH",
        "outputId": "66bd1a91-9366-4250-b644-e895b900904e"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284315, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBsOYpr_umBB"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFp0sunYunVQ"
      },
      "source": [
        "#x_train = sc.fit_transform(x_train)\n",
        "#x_test = sc.fit_transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3GroYv0bQd5"
      },
      "source": [
        "Создадим энкодер в виде 2-х полносвязных слоев.\n",
        " \n",
        "Мы выбрали размерность скрытого пространства равной 2. Это сделано исключительно для возможности наглядного представления распределения точек. Однако для более точной работы автоэнкодера следует использовать скрытые пространства с большей размерностью, например 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqkphoJC5zTE"
      },
      "source": [
        "latent_dim = 10\n",
        "inp = Input(shape=(29,))\n",
        "h1 = Dense(128, activation='relu')(inp)\n",
        "\n",
        "#h12 = Dense(64, activation='relu')(h1)\n",
        "z = Dense(latent_dim)(h1)\n",
        "encoder = Model(inp, z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJoxBTHB-VmW",
        "outputId": "6c424a7b-c962-49f1-8b89-e92a6e32776c"
      },
      "source": [
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_19 (InputLayer)       [(None, 29)]              0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 128)               3840      \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,130\n",
            "Trainable params: 5,130\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS0DZbqxLiSy"
      },
      "source": [
        "Аналогично создаем декодер"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2EUinD5-V4L"
      },
      "source": [
        "inp_z = Input(shape=(latent_dim,))\n",
        "h2 = Dense(128, activation='relu')(inp_z)\n",
        "\n",
        "#h21 = Dense(128, activation='relu')(h2)\n",
        "out = Dense(29)(h2) \n",
        "decoder = Model(inp_z, out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWoseXfq-V-v",
        "outputId": "bb5611cf-dffb-4fc9-e037-e9835c7c6f2c"
      },
      "source": [
        "decoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_21 (InputLayer)       [(None, 10)]              0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,149\n",
            "Trainable params: 5,149\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nV9KlE1_nH_"
      },
      "source": [
        "Определим автоэнкодер как композицию энкодера и декодера:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrl1RFBL-WHq"
      },
      "source": [
        "ae = Model(inp, decoder(encoder(inp)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gYBvQYfLolu"
      },
      "source": [
        "Компилируем автоэнкодер:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vr9OCcgr-mr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c4e14aa-5417-4720-86b8-9fef4d353c1d"
      },
      "source": [
        "ae.compile(optimizer=Adam(lr=0.0005), loss='mse', metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqmUyJPTLskX"
      },
      "source": [
        "И запускаем обучение."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYAmPCVMAMC8",
        "outputId": "3c2ff470-d6f5-43b0-e69d-b764afbf9d7d"
      },
      "source": [
        "history = ae.fit(x_train, x_train, epochs=1000, batch_size=1024, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0550 - mae: 0.1454 - val_loss: 0.0556 - val_mae: 0.1459\n",
            "Epoch 2/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0546 - mae: 0.1447 - val_loss: 0.0553 - val_mae: 0.1457\n",
            "Epoch 3/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0542 - mae: 0.1442 - val_loss: 0.0558 - val_mae: 0.1461\n",
            "Epoch 4/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0539 - mae: 0.1436 - val_loss: 0.0543 - val_mae: 0.1439\n",
            "Epoch 5/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0536 - mae: 0.1431 - val_loss: 0.0544 - val_mae: 0.1438\n",
            "Epoch 6/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0531 - mae: 0.1423 - val_loss: 0.0537 - val_mae: 0.1429\n",
            "Epoch 7/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0527 - mae: 0.1418 - val_loss: 0.0542 - val_mae: 0.1433\n",
            "Epoch 8/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0524 - mae: 0.1412 - val_loss: 0.0534 - val_mae: 0.1422\n",
            "Epoch 9/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0520 - mae: 0.1406 - val_loss: 0.0534 - val_mae: 0.1421\n",
            "Epoch 10/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0517 - mae: 0.1402 - val_loss: 0.0524 - val_mae: 0.1413\n",
            "Epoch 11/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0513 - mae: 0.1396 - val_loss: 0.0521 - val_mae: 0.1404\n",
            "Epoch 12/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0510 - mae: 0.1391 - val_loss: 0.0515 - val_mae: 0.1395\n",
            "Epoch 13/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0505 - mae: 0.1384 - val_loss: 0.0512 - val_mae: 0.1388\n",
            "Epoch 14/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0501 - mae: 0.1377 - val_loss: 0.0508 - val_mae: 0.1384\n",
            "Epoch 15/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0496 - mae: 0.1371 - val_loss: 0.0505 - val_mae: 0.1377\n",
            "Epoch 16/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0493 - mae: 0.1363 - val_loss: 0.0500 - val_mae: 0.1371\n",
            "Epoch 17/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0488 - mae: 0.1356 - val_loss: 0.0495 - val_mae: 0.1361\n",
            "Epoch 18/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0486 - mae: 0.1350 - val_loss: 0.0491 - val_mae: 0.1355\n",
            "Epoch 19/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0479 - mae: 0.1339 - val_loss: 0.0484 - val_mae: 0.1345\n",
            "Epoch 20/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0475 - mae: 0.1332 - val_loss: 0.0480 - val_mae: 0.1336\n",
            "Epoch 21/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0471 - mae: 0.1323 - val_loss: 0.0478 - val_mae: 0.1330\n",
            "Epoch 22/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0466 - mae: 0.1313 - val_loss: 0.0471 - val_mae: 0.1316\n",
            "Epoch 23/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0462 - mae: 0.1305 - val_loss: 0.0466 - val_mae: 0.1310\n",
            "Epoch 24/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0457 - mae: 0.1296 - val_loss: 0.0462 - val_mae: 0.1303\n",
            "Epoch 25/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0454 - mae: 0.1287 - val_loss: 0.0462 - val_mae: 0.1297\n",
            "Epoch 26/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0450 - mae: 0.1279 - val_loss: 0.0457 - val_mae: 0.1284\n",
            "Epoch 27/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0446 - mae: 0.1270 - val_loss: 0.0453 - val_mae: 0.1273\n",
            "Epoch 28/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0442 - mae: 0.1262 - val_loss: 0.0449 - val_mae: 0.1269\n",
            "Epoch 29/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0438 - mae: 0.1253 - val_loss: 0.0455 - val_mae: 0.1271\n",
            "Epoch 30/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0438 - mae: 0.1249 - val_loss: 0.0443 - val_mae: 0.1252\n",
            "Epoch 31/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0432 - mae: 0.1239 - val_loss: 0.0439 - val_mae: 0.1247\n",
            "Epoch 32/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0428 - mae: 0.1231 - val_loss: 0.0433 - val_mae: 0.1234\n",
            "Epoch 33/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0425 - mae: 0.1223 - val_loss: 0.0431 - val_mae: 0.1228\n",
            "Epoch 34/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0422 - mae: 0.1217 - val_loss: 0.0428 - val_mae: 0.1224\n",
            "Epoch 35/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0418 - mae: 0.1208 - val_loss: 0.0425 - val_mae: 0.1218\n",
            "Epoch 36/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0415 - mae: 0.1202 - val_loss: 0.0422 - val_mae: 0.1208\n",
            "Epoch 37/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0412 - mae: 0.1196 - val_loss: 0.0420 - val_mae: 0.1207\n",
            "Epoch 38/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0410 - mae: 0.1190 - val_loss: 0.0417 - val_mae: 0.1196\n",
            "Epoch 39/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0407 - mae: 0.1183 - val_loss: 0.0412 - val_mae: 0.1191\n",
            "Epoch 40/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0404 - mae: 0.1178 - val_loss: 0.0408 - val_mae: 0.1184\n",
            "Epoch 41/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0401 - mae: 0.1171 - val_loss: 0.0413 - val_mae: 0.1194\n",
            "Epoch 42/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0399 - mae: 0.1167 - val_loss: 0.0422 - val_mae: 0.1195\n",
            "Epoch 43/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0398 - mae: 0.1162 - val_loss: 0.0403 - val_mae: 0.1168\n",
            "Epoch 44/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0394 - mae: 0.1155 - val_loss: 0.0398 - val_mae: 0.1156\n",
            "Epoch 45/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0395 - mae: 0.1152 - val_loss: 0.0395 - val_mae: 0.1153\n",
            "Epoch 46/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0391 - mae: 0.1146 - val_loss: 0.0397 - val_mae: 0.1153\n",
            "Epoch 47/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0389 - mae: 0.1140 - val_loss: 0.0395 - val_mae: 0.1148\n",
            "Epoch 48/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0387 - mae: 0.1135 - val_loss: 0.0391 - val_mae: 0.1138\n",
            "Epoch 49/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0386 - mae: 0.1131 - val_loss: 0.0395 - val_mae: 0.1143\n",
            "Epoch 50/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0383 - mae: 0.1127 - val_loss: 0.0391 - val_mae: 0.1134\n",
            "Epoch 51/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0382 - mae: 0.1122 - val_loss: 0.0388 - val_mae: 0.1126\n",
            "Epoch 52/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0380 - mae: 0.1118 - val_loss: 0.0385 - val_mae: 0.1124\n",
            "Epoch 53/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0378 - mae: 0.1114 - val_loss: 0.0384 - val_mae: 0.1122\n",
            "Epoch 54/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0378 - mae: 0.1112 - val_loss: 0.0382 - val_mae: 0.1114\n",
            "Epoch 55/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0375 - mae: 0.1107 - val_loss: 0.0380 - val_mae: 0.1110\n",
            "Epoch 56/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0373 - mae: 0.1102 - val_loss: 0.0379 - val_mae: 0.1110\n",
            "Epoch 57/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0371 - mae: 0.1098 - val_loss: 0.0376 - val_mae: 0.1106\n",
            "Epoch 58/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0371 - mae: 0.1097 - val_loss: 0.0376 - val_mae: 0.1099\n",
            "Epoch 59/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0370 - mae: 0.1094 - val_loss: 0.0375 - val_mae: 0.1102\n",
            "Epoch 60/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0370 - mae: 0.1091 - val_loss: 0.0376 - val_mae: 0.1097\n",
            "Epoch 61/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0367 - mae: 0.1086 - val_loss: 0.0372 - val_mae: 0.1090\n",
            "Epoch 62/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0366 - mae: 0.1084 - val_loss: 0.0373 - val_mae: 0.1097\n",
            "Epoch 63/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0365 - mae: 0.1082 - val_loss: 0.0369 - val_mae: 0.1083\n",
            "Epoch 64/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0363 - mae: 0.1077 - val_loss: 0.0375 - val_mae: 0.1092\n",
            "Epoch 65/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0364 - mae: 0.1077 - val_loss: 0.0367 - val_mae: 0.1077\n",
            "Epoch 66/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0361 - mae: 0.1072 - val_loss: 0.0367 - val_mae: 0.1077\n",
            "Epoch 67/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0362 - mae: 0.1072 - val_loss: 0.0367 - val_mae: 0.1083\n",
            "Epoch 68/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0360 - mae: 0.1070 - val_loss: 0.0365 - val_mae: 0.1075\n",
            "Epoch 69/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0360 - mae: 0.1068 - val_loss: 0.0362 - val_mae: 0.1070\n",
            "Epoch 70/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0358 - mae: 0.1064 - val_loss: 0.0363 - val_mae: 0.1068\n",
            "Epoch 71/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0356 - mae: 0.1061 - val_loss: 0.0363 - val_mae: 0.1069\n",
            "Epoch 72/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0357 - mae: 0.1060 - val_loss: 0.0359 - val_mae: 0.1064\n",
            "Epoch 73/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0355 - mae: 0.1058 - val_loss: 0.0361 - val_mae: 0.1063\n",
            "Epoch 74/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0354 - mae: 0.1055 - val_loss: 0.0362 - val_mae: 0.1063\n",
            "Epoch 75/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0354 - mae: 0.1054 - val_loss: 0.0358 - val_mae: 0.1064\n",
            "Epoch 76/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0353 - mae: 0.1052 - val_loss: 0.0360 - val_mae: 0.1065\n",
            "Epoch 77/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0352 - mae: 0.1051 - val_loss: 0.0358 - val_mae: 0.1059\n",
            "Epoch 78/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0352 - mae: 0.1050 - val_loss: 0.0356 - val_mae: 0.1054\n",
            "Epoch 79/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0351 - mae: 0.1047 - val_loss: 0.0357 - val_mae: 0.1053\n",
            "Epoch 80/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0350 - mae: 0.1045 - val_loss: 0.0360 - val_mae: 0.1058\n",
            "Epoch 81/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0350 - mae: 0.1046 - val_loss: 0.0354 - val_mae: 0.1047\n",
            "Epoch 82/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0348 - mae: 0.1042 - val_loss: 0.0353 - val_mae: 0.1052\n",
            "Epoch 83/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0347 - mae: 0.1040 - val_loss: 0.0352 - val_mae: 0.1046\n",
            "Epoch 84/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0347 - mae: 0.1039 - val_loss: 0.0355 - val_mae: 0.1049\n",
            "Epoch 85/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0347 - mae: 0.1039 - val_loss: 0.0354 - val_mae: 0.1053\n",
            "Epoch 86/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0346 - mae: 0.1038 - val_loss: 0.0352 - val_mae: 0.1037\n",
            "Epoch 87/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0345 - mae: 0.1035 - val_loss: 0.0350 - val_mae: 0.1044\n",
            "Epoch 88/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0345 - mae: 0.1034 - val_loss: 0.0349 - val_mae: 0.1034\n",
            "Epoch 89/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0344 - mae: 0.1033 - val_loss: 0.0350 - val_mae: 0.1042\n",
            "Epoch 90/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0343 - mae: 0.1031 - val_loss: 0.0350 - val_mae: 0.1043\n",
            "Epoch 91/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0347 - mae: 0.1035 - val_loss: 0.0347 - val_mae: 0.1029\n",
            "Epoch 92/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0343 - mae: 0.1029 - val_loss: 0.0349 - val_mae: 0.1037\n",
            "Epoch 93/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0342 - mae: 0.1027 - val_loss: 0.0352 - val_mae: 0.1042\n",
            "Epoch 94/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0341 - mae: 0.1025 - val_loss: 0.0349 - val_mae: 0.1039\n",
            "Epoch 95/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0341 - mae: 0.1025 - val_loss: 0.0345 - val_mae: 0.1029\n",
            "Epoch 96/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0340 - mae: 0.1024 - val_loss: 0.0348 - val_mae: 0.1036\n",
            "Epoch 97/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0339 - mae: 0.1021 - val_loss: 0.0352 - val_mae: 0.1048\n",
            "Epoch 98/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0340 - mae: 0.1023 - val_loss: 0.0344 - val_mae: 0.1029\n",
            "Epoch 99/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0338 - mae: 0.1020 - val_loss: 0.0343 - val_mae: 0.1033\n",
            "Epoch 100/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0339 - mae: 0.1020 - val_loss: 0.0343 - val_mae: 0.1024\n",
            "Epoch 101/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0338 - mae: 0.1019 - val_loss: 0.0343 - val_mae: 0.1024\n",
            "Epoch 102/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0338 - mae: 0.1018 - val_loss: 0.0341 - val_mae: 0.1025\n",
            "Epoch 103/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0337 - mae: 0.1016 - val_loss: 0.0341 - val_mae: 0.1022\n",
            "Epoch 104/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0336 - mae: 0.1015 - val_loss: 0.0339 - val_mae: 0.1016\n",
            "Epoch 105/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0335 - mae: 0.1014 - val_loss: 0.0339 - val_mae: 0.1015\n",
            "Epoch 106/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0335 - mae: 0.1013 - val_loss: 0.0343 - val_mae: 0.1023\n",
            "Epoch 107/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0335 - mae: 0.1012 - val_loss: 0.0337 - val_mae: 0.1008\n",
            "Epoch 108/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0334 - mae: 0.1012 - val_loss: 0.0338 - val_mae: 0.1012\n",
            "Epoch 109/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0333 - mae: 0.1008 - val_loss: 0.0338 - val_mae: 0.1016\n",
            "Epoch 110/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0334 - mae: 0.1012 - val_loss: 0.0340 - val_mae: 0.1023\n",
            "Epoch 111/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0332 - mae: 0.1007 - val_loss: 0.0336 - val_mae: 0.1009\n",
            "Epoch 112/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0331 - mae: 0.1006 - val_loss: 0.0338 - val_mae: 0.1019\n",
            "Epoch 113/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0332 - mae: 0.1006 - val_loss: 0.0338 - val_mae: 0.1019\n",
            "Epoch 114/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0333 - mae: 0.1006 - val_loss: 0.0335 - val_mae: 0.1007\n",
            "Epoch 115/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0330 - mae: 0.1002 - val_loss: 0.0342 - val_mae: 0.1016\n",
            "Epoch 116/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0330 - mae: 0.1003 - val_loss: 0.0336 - val_mae: 0.1013\n",
            "Epoch 117/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0331 - mae: 0.1003 - val_loss: 0.0336 - val_mae: 0.1008\n",
            "Epoch 118/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0328 - mae: 0.0999 - val_loss: 0.0335 - val_mae: 0.1007\n",
            "Epoch 119/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0329 - mae: 0.1000 - val_loss: 0.0337 - val_mae: 0.1011\n",
            "Epoch 120/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0328 - mae: 0.0998 - val_loss: 0.0333 - val_mae: 0.1007\n",
            "Epoch 121/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0327 - mae: 0.0997 - val_loss: 0.0332 - val_mae: 0.1003\n",
            "Epoch 122/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0328 - mae: 0.0998 - val_loss: 0.0336 - val_mae: 0.1002\n",
            "Epoch 123/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0336 - mae: 0.1008 - val_loss: 0.0333 - val_mae: 0.1001\n",
            "Epoch 124/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0326 - mae: 0.0995 - val_loss: 0.0332 - val_mae: 0.1004\n",
            "Epoch 125/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0327 - mae: 0.0995 - val_loss: 0.0331 - val_mae: 0.1000\n",
            "Epoch 126/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0324 - mae: 0.0991 - val_loss: 0.0331 - val_mae: 0.1000\n",
            "Epoch 127/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0325 - mae: 0.0993 - val_loss: 0.0331 - val_mae: 0.1000\n",
            "Epoch 128/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0324 - mae: 0.0991 - val_loss: 0.0329 - val_mae: 0.0998\n",
            "Epoch 129/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0324 - mae: 0.0989 - val_loss: 0.0331 - val_mae: 0.0995\n",
            "Epoch 130/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0324 - mae: 0.0990 - val_loss: 0.0330 - val_mae: 0.0999\n",
            "Epoch 131/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0325 - mae: 0.0991 - val_loss: 0.0328 - val_mae: 0.0991\n",
            "Epoch 132/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0324 - mae: 0.0989 - val_loss: 0.0330 - val_mae: 0.0992\n",
            "Epoch 133/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0324 - mae: 0.0988 - val_loss: 0.0328 - val_mae: 0.0993\n",
            "Epoch 134/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0322 - mae: 0.0987 - val_loss: 0.0330 - val_mae: 0.0996\n",
            "Epoch 135/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0323 - mae: 0.0988 - val_loss: 0.0326 - val_mae: 0.0990\n",
            "Epoch 136/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0322 - mae: 0.0985 - val_loss: 0.0330 - val_mae: 0.0990\n",
            "Epoch 137/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0322 - mae: 0.0985 - val_loss: 0.0329 - val_mae: 0.0995\n",
            "Epoch 138/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0321 - mae: 0.0984 - val_loss: 0.0332 - val_mae: 0.0997\n",
            "Epoch 139/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0321 - mae: 0.0983 - val_loss: 0.0329 - val_mae: 0.1005\n",
            "Epoch 140/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0321 - mae: 0.0983 - val_loss: 0.0325 - val_mae: 0.0984\n",
            "Epoch 141/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0320 - mae: 0.0981 - val_loss: 0.0326 - val_mae: 0.0985\n",
            "Epoch 142/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0320 - mae: 0.0980 - val_loss: 0.0324 - val_mae: 0.0991\n",
            "Epoch 143/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0319 - mae: 0.0980 - val_loss: 0.0324 - val_mae: 0.0983\n",
            "Epoch 144/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0319 - mae: 0.0979 - val_loss: 0.0323 - val_mae: 0.0982\n",
            "Epoch 145/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0320 - mae: 0.0983 - val_loss: 0.0324 - val_mae: 0.0980\n",
            "Epoch 146/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0318 - mae: 0.0979 - val_loss: 0.0323 - val_mae: 0.0978\n",
            "Epoch 147/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0317 - mae: 0.0976 - val_loss: 0.0322 - val_mae: 0.0982\n",
            "Epoch 148/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0318 - mae: 0.0977 - val_loss: 0.0329 - val_mae: 0.0991\n",
            "Epoch 149/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0317 - mae: 0.0976 - val_loss: 0.0325 - val_mae: 0.0988\n",
            "Epoch 150/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0319 - mae: 0.0979 - val_loss: 0.0331 - val_mae: 0.0997\n",
            "Epoch 151/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0317 - mae: 0.0974 - val_loss: 0.0322 - val_mae: 0.0980\n",
            "Epoch 152/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0316 - mae: 0.0973 - val_loss: 0.0322 - val_mae: 0.0977\n",
            "Epoch 153/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0317 - mae: 0.0976 - val_loss: 0.0322 - val_mae: 0.0982\n",
            "Epoch 154/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0315 - mae: 0.0973 - val_loss: 0.0320 - val_mae: 0.0976\n",
            "Epoch 155/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0315 - mae: 0.0972 - val_loss: 0.0323 - val_mae: 0.0988\n",
            "Epoch 156/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0315 - mae: 0.0972 - val_loss: 0.0321 - val_mae: 0.0978\n",
            "Epoch 157/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0315 - mae: 0.0972 - val_loss: 0.0321 - val_mae: 0.0976\n",
            "Epoch 158/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0315 - mae: 0.0971 - val_loss: 0.0318 - val_mae: 0.0974\n",
            "Epoch 159/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0313 - mae: 0.0969 - val_loss: 0.0325 - val_mae: 0.0989\n",
            "Epoch 160/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0314 - mae: 0.0971 - val_loss: 0.0319 - val_mae: 0.0969\n",
            "Epoch 161/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0314 - mae: 0.0971 - val_loss: 0.0319 - val_mae: 0.0969\n",
            "Epoch 162/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0313 - mae: 0.0968 - val_loss: 0.0318 - val_mae: 0.0972\n",
            "Epoch 163/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0313 - mae: 0.0969 - val_loss: 0.0323 - val_mae: 0.0988\n",
            "Epoch 164/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0313 - mae: 0.0969 - val_loss: 0.0317 - val_mae: 0.0969\n",
            "Epoch 165/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0311 - mae: 0.0966 - val_loss: 0.0321 - val_mae: 0.0973\n",
            "Epoch 166/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0311 - mae: 0.0966 - val_loss: 0.0321 - val_mae: 0.0975\n",
            "Epoch 167/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0312 - mae: 0.0967 - val_loss: 0.0317 - val_mae: 0.0970\n",
            "Epoch 168/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0312 - mae: 0.0966 - val_loss: 0.0316 - val_mae: 0.0974\n",
            "Epoch 169/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0311 - mae: 0.0964 - val_loss: 0.0321 - val_mae: 0.0973\n",
            "Epoch 170/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0311 - mae: 0.0964 - val_loss: 0.0319 - val_mae: 0.0982\n",
            "Epoch 171/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0311 - mae: 0.0964 - val_loss: 0.0318 - val_mae: 0.0967\n",
            "Epoch 172/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0312 - mae: 0.0966 - val_loss: 0.0314 - val_mae: 0.0963\n",
            "Epoch 173/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0309 - mae: 0.0961 - val_loss: 0.0313 - val_mae: 0.0961\n",
            "Epoch 174/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0309 - mae: 0.0961 - val_loss: 0.0315 - val_mae: 0.0962\n",
            "Epoch 175/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0309 - mae: 0.0961 - val_loss: 0.0317 - val_mae: 0.0972\n",
            "Epoch 176/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0309 - mae: 0.0961 - val_loss: 0.0316 - val_mae: 0.0967\n",
            "Epoch 177/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0309 - mae: 0.0962 - val_loss: 0.0314 - val_mae: 0.0962\n",
            "Epoch 178/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0309 - mae: 0.0960 - val_loss: 0.0314 - val_mae: 0.0962\n",
            "Epoch 179/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0309 - mae: 0.0961 - val_loss: 0.0316 - val_mae: 0.0970\n",
            "Epoch 180/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0307 - mae: 0.0957 - val_loss: 0.0313 - val_mae: 0.0960\n",
            "Epoch 181/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0308 - mae: 0.0959 - val_loss: 0.0314 - val_mae: 0.0963\n",
            "Epoch 182/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0309 - mae: 0.0959 - val_loss: 0.0315 - val_mae: 0.0966\n",
            "Epoch 183/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0308 - mae: 0.0958 - val_loss: 0.0312 - val_mae: 0.0960\n",
            "Epoch 184/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0307 - mae: 0.0958 - val_loss: 0.0314 - val_mae: 0.0966\n",
            "Epoch 185/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0307 - mae: 0.0956 - val_loss: 0.0315 - val_mae: 0.0968\n",
            "Epoch 186/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0306 - mae: 0.0955 - val_loss: 0.0310 - val_mae: 0.0954\n",
            "Epoch 187/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0306 - mae: 0.0954 - val_loss: 0.0312 - val_mae: 0.0961\n",
            "Epoch 188/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0305 - mae: 0.0954 - val_loss: 0.0311 - val_mae: 0.0960\n",
            "Epoch 189/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0308 - mae: 0.0958 - val_loss: 0.0312 - val_mae: 0.0962\n",
            "Epoch 190/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0305 - mae: 0.0954 - val_loss: 0.0313 - val_mae: 0.0963\n",
            "Epoch 191/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0305 - mae: 0.0952 - val_loss: 0.0312 - val_mae: 0.0961\n",
            "Epoch 192/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0305 - mae: 0.0953 - val_loss: 0.0311 - val_mae: 0.0969\n",
            "Epoch 193/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0305 - mae: 0.0953 - val_loss: 0.0309 - val_mae: 0.0957\n",
            "Epoch 194/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0304 - mae: 0.0950 - val_loss: 0.0313 - val_mae: 0.0954\n",
            "Epoch 195/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0304 - mae: 0.0950 - val_loss: 0.0312 - val_mae: 0.0967\n",
            "Epoch 196/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0304 - mae: 0.0951 - val_loss: 0.0311 - val_mae: 0.0955\n",
            "Epoch 197/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0304 - mae: 0.0951 - val_loss: 0.0310 - val_mae: 0.0952\n",
            "Epoch 198/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0303 - mae: 0.0949 - val_loss: 0.0311 - val_mae: 0.0955\n",
            "Epoch 199/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0304 - mae: 0.0950 - val_loss: 0.0313 - val_mae: 0.0959\n",
            "Epoch 200/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0303 - mae: 0.0949 - val_loss: 0.0309 - val_mae: 0.0954\n",
            "Epoch 201/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0303 - mae: 0.0950 - val_loss: 0.0312 - val_mae: 0.0955\n",
            "Epoch 202/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0303 - mae: 0.0949 - val_loss: 0.0310 - val_mae: 0.0957\n",
            "Epoch 203/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0304 - mae: 0.0949 - val_loss: 0.0309 - val_mae: 0.0958\n",
            "Epoch 204/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0302 - mae: 0.0948 - val_loss: 0.0308 - val_mae: 0.0954\n",
            "Epoch 205/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0302 - mae: 0.0948 - val_loss: 0.0310 - val_mae: 0.0955\n",
            "Epoch 206/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0301 - mae: 0.0946 - val_loss: 0.0309 - val_mae: 0.0959\n",
            "Epoch 207/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0303 - mae: 0.0948 - val_loss: 0.0309 - val_mae: 0.0952\n",
            "Epoch 208/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0301 - mae: 0.0945 - val_loss: 0.0305 - val_mae: 0.0944\n",
            "Epoch 209/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0300 - mae: 0.0943 - val_loss: 0.0306 - val_mae: 0.0949\n",
            "Epoch 210/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0302 - mae: 0.0946 - val_loss: 0.0310 - val_mae: 0.0952\n",
            "Epoch 211/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0301 - mae: 0.0943 - val_loss: 0.0307 - val_mae: 0.0947\n",
            "Epoch 212/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0301 - mae: 0.0944 - val_loss: 0.0308 - val_mae: 0.0945\n",
            "Epoch 213/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0300 - mae: 0.0943 - val_loss: 0.0306 - val_mae: 0.0950\n",
            "Epoch 214/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0304 - mae: 0.0948 - val_loss: 0.0307 - val_mae: 0.0954\n",
            "Epoch 215/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0299 - mae: 0.0941 - val_loss: 0.0310 - val_mae: 0.0952\n",
            "Epoch 216/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0299 - mae: 0.0942 - val_loss: 0.0309 - val_mae: 0.0959\n",
            "Epoch 217/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0299 - mae: 0.0941 - val_loss: 0.0310 - val_mae: 0.0969\n",
            "Epoch 218/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0300 - mae: 0.0942 - val_loss: 0.0304 - val_mae: 0.0941\n",
            "Epoch 219/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0300 - mae: 0.0941 - val_loss: 0.0305 - val_mae: 0.0946\n",
            "Epoch 220/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0298 - mae: 0.0940 - val_loss: 0.0305 - val_mae: 0.0942\n",
            "Epoch 221/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0299 - mae: 0.0940 - val_loss: 0.0304 - val_mae: 0.0942\n",
            "Epoch 222/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0298 - mae: 0.0938 - val_loss: 0.0306 - val_mae: 0.0944\n",
            "Epoch 223/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0298 - mae: 0.0938 - val_loss: 0.0303 - val_mae: 0.0942\n",
            "Epoch 224/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0298 - mae: 0.0938 - val_loss: 0.0305 - val_mae: 0.0948\n",
            "Epoch 225/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0299 - mae: 0.0940 - val_loss: 0.0304 - val_mae: 0.0943\n",
            "Epoch 226/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0299 - mae: 0.0941 - val_loss: 0.0303 - val_mae: 0.0941\n",
            "Epoch 227/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0298 - mae: 0.0937 - val_loss: 0.0303 - val_mae: 0.0937\n",
            "Epoch 228/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0297 - mae: 0.0936 - val_loss: 0.0308 - val_mae: 0.0953\n",
            "Epoch 229/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0298 - mae: 0.0938 - val_loss: 0.0306 - val_mae: 0.0947\n",
            "Epoch 230/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0297 - mae: 0.0936 - val_loss: 0.0304 - val_mae: 0.0944\n",
            "Epoch 231/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0296 - mae: 0.0937 - val_loss: 0.0307 - val_mae: 0.0952\n",
            "Epoch 232/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0297 - mae: 0.0936 - val_loss: 0.0301 - val_mae: 0.0937\n",
            "Epoch 233/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0296 - mae: 0.0935 - val_loss: 0.0309 - val_mae: 0.0950\n",
            "Epoch 234/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0299 - mae: 0.0939 - val_loss: 0.0303 - val_mae: 0.0939\n",
            "Epoch 235/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0297 - mae: 0.0936 - val_loss: 0.0312 - val_mae: 0.0954\n",
            "Epoch 236/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0297 - mae: 0.0936 - val_loss: 0.0303 - val_mae: 0.0941\n",
            "Epoch 237/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0297 - mae: 0.0936 - val_loss: 0.0302 - val_mae: 0.0940\n",
            "Epoch 238/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0294 - mae: 0.0931 - val_loss: 0.0305 - val_mae: 0.0947\n",
            "Epoch 239/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0298 - mae: 0.0936 - val_loss: 0.0327 - val_mae: 0.1001\n",
            "Epoch 240/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0297 - mae: 0.0937 - val_loss: 0.0301 - val_mae: 0.0941\n",
            "Epoch 241/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0295 - mae: 0.0932 - val_loss: 0.0306 - val_mae: 0.0942\n",
            "Epoch 242/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0295 - mae: 0.0933 - val_loss: 0.0301 - val_mae: 0.0935\n",
            "Epoch 243/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0299 - mae: 0.0938 - val_loss: 0.0302 - val_mae: 0.0934\n",
            "Epoch 244/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0295 - mae: 0.0932 - val_loss: 0.0303 - val_mae: 0.0935\n",
            "Epoch 245/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0295 - mae: 0.0932 - val_loss: 0.0300 - val_mae: 0.0934\n",
            "Epoch 246/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0295 - mae: 0.0932 - val_loss: 0.0302 - val_mae: 0.0938\n",
            "Epoch 247/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0294 - mae: 0.0931 - val_loss: 0.0303 - val_mae: 0.0943\n",
            "Epoch 248/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0293 - mae: 0.0929 - val_loss: 0.0303 - val_mae: 0.0944\n",
            "Epoch 249/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0294 - mae: 0.0931 - val_loss: 0.0302 - val_mae: 0.0937\n",
            "Epoch 250/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0294 - mae: 0.0931 - val_loss: 0.0301 - val_mae: 0.0941\n",
            "Epoch 251/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0293 - mae: 0.0928 - val_loss: 0.0306 - val_mae: 0.0954\n",
            "Epoch 252/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0293 - mae: 0.0929 - val_loss: 0.0299 - val_mae: 0.0933\n",
            "Epoch 253/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0294 - mae: 0.0929 - val_loss: 0.0301 - val_mae: 0.0935\n",
            "Epoch 254/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0293 - mae: 0.0930 - val_loss: 0.0300 - val_mae: 0.0938\n",
            "Epoch 255/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0293 - mae: 0.0928 - val_loss: 0.0301 - val_mae: 0.0941\n",
            "Epoch 256/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0293 - mae: 0.0928 - val_loss: 0.0299 - val_mae: 0.0932\n",
            "Epoch 257/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0294 - mae: 0.0929 - val_loss: 0.0302 - val_mae: 0.0936\n",
            "Epoch 258/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0293 - mae: 0.0928 - val_loss: 0.0299 - val_mae: 0.0928\n",
            "Epoch 259/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0292 - mae: 0.0927 - val_loss: 0.0300 - val_mae: 0.0940\n",
            "Epoch 260/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0292 - mae: 0.0926 - val_loss: 0.0298 - val_mae: 0.0927\n",
            "Epoch 261/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0292 - mae: 0.0925 - val_loss: 0.0304 - val_mae: 0.0940\n",
            "Epoch 262/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0291 - mae: 0.0924 - val_loss: 0.0297 - val_mae: 0.0930\n",
            "Epoch 263/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0294 - mae: 0.0931 - val_loss: 0.0297 - val_mae: 0.0930\n",
            "Epoch 264/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0291 - mae: 0.0925 - val_loss: 0.0295 - val_mae: 0.0928\n",
            "Epoch 265/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0291 - mae: 0.0925 - val_loss: 0.0304 - val_mae: 0.0946\n",
            "Epoch 266/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0292 - mae: 0.0925 - val_loss: 0.0301 - val_mae: 0.0938\n",
            "Epoch 267/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0291 - mae: 0.0925 - val_loss: 0.0298 - val_mae: 0.0926\n",
            "Epoch 268/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0290 - mae: 0.0923 - val_loss: 0.0302 - val_mae: 0.0941\n",
            "Epoch 269/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0291 - mae: 0.0925 - val_loss: 0.0296 - val_mae: 0.0925\n",
            "Epoch 270/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0290 - mae: 0.0923 - val_loss: 0.0297 - val_mae: 0.0934\n",
            "Epoch 271/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0290 - mae: 0.0922 - val_loss: 0.0297 - val_mae: 0.0932\n",
            "Epoch 272/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0292 - mae: 0.0927 - val_loss: 0.0297 - val_mae: 0.0927\n",
            "Epoch 273/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0290 - mae: 0.0922 - val_loss: 0.0300 - val_mae: 0.0931\n",
            "Epoch 274/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0289 - mae: 0.0921 - val_loss: 0.0300 - val_mae: 0.0935\n",
            "Epoch 275/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0290 - mae: 0.0923 - val_loss: 0.0296 - val_mae: 0.0924\n",
            "Epoch 276/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0290 - mae: 0.0922 - val_loss: 0.0298 - val_mae: 0.0931\n",
            "Epoch 277/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0289 - mae: 0.0922 - val_loss: 0.0295 - val_mae: 0.0924\n",
            "Epoch 278/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0289 - mae: 0.0922 - val_loss: 0.0298 - val_mae: 0.0935\n",
            "Epoch 279/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0289 - mae: 0.0921 - val_loss: 0.0296 - val_mae: 0.0928\n",
            "Epoch 280/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0289 - mae: 0.0922 - val_loss: 0.0299 - val_mae: 0.0929\n",
            "Epoch 281/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0291 - mae: 0.0926 - val_loss: 0.0299 - val_mae: 0.0933\n",
            "Epoch 282/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0290 - mae: 0.0922 - val_loss: 0.0296 - val_mae: 0.0920\n",
            "Epoch 283/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0288 - mae: 0.0919 - val_loss: 0.0296 - val_mae: 0.0930\n",
            "Epoch 284/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0288 - mae: 0.0920 - val_loss: 0.0296 - val_mae: 0.0926\n",
            "Epoch 285/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0290 - mae: 0.0922 - val_loss: 0.0294 - val_mae: 0.0928\n",
            "Epoch 286/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0289 - mae: 0.0920 - val_loss: 0.0296 - val_mae: 0.0926\n",
            "Epoch 287/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0289 - mae: 0.0920 - val_loss: 0.0293 - val_mae: 0.0924\n",
            "Epoch 288/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0288 - mae: 0.0920 - val_loss: 0.0292 - val_mae: 0.0919\n",
            "Epoch 289/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0287 - mae: 0.0917 - val_loss: 0.0293 - val_mae: 0.0923\n",
            "Epoch 290/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0286 - mae: 0.0917 - val_loss: 0.0293 - val_mae: 0.0921\n",
            "Epoch 291/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0287 - mae: 0.0918 - val_loss: 0.0295 - val_mae: 0.0933\n",
            "Epoch 292/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0287 - mae: 0.0918 - val_loss: 0.0296 - val_mae: 0.0923\n",
            "Epoch 293/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0287 - mae: 0.0919 - val_loss: 0.0292 - val_mae: 0.0920\n",
            "Epoch 294/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0288 - mae: 0.0918 - val_loss: 0.0305 - val_mae: 0.0948\n",
            "Epoch 295/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0287 - mae: 0.0919 - val_loss: 0.0295 - val_mae: 0.0934\n",
            "Epoch 296/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0287 - mae: 0.0917 - val_loss: 0.0295 - val_mae: 0.0928\n",
            "Epoch 297/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0287 - mae: 0.0919 - val_loss: 0.0292 - val_mae: 0.0922\n",
            "Epoch 298/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0286 - mae: 0.0917 - val_loss: 0.0295 - val_mae: 0.0933\n",
            "Epoch 299/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0286 - mae: 0.0917 - val_loss: 0.0293 - val_mae: 0.0921\n",
            "Epoch 300/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0286 - mae: 0.0915 - val_loss: 0.0296 - val_mae: 0.0929\n",
            "Epoch 301/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0285 - mae: 0.0915 - val_loss: 0.0290 - val_mae: 0.0915\n",
            "Epoch 302/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0286 - mae: 0.0916 - val_loss: 0.0296 - val_mae: 0.0927\n",
            "Epoch 303/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0286 - mae: 0.0915 - val_loss: 0.0294 - val_mae: 0.0929\n",
            "Epoch 304/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0286 - mae: 0.0916 - val_loss: 0.0300 - val_mae: 0.0935\n",
            "Epoch 305/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0290 - mae: 0.0923 - val_loss: 0.0291 - val_mae: 0.0923\n",
            "Epoch 306/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0286 - mae: 0.0916 - val_loss: 0.0297 - val_mae: 0.0935\n",
            "Epoch 307/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0285 - mae: 0.0915 - val_loss: 0.0291 - val_mae: 0.0915\n",
            "Epoch 308/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0285 - mae: 0.0915 - val_loss: 0.0291 - val_mae: 0.0916\n",
            "Epoch 309/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0286 - mae: 0.0916 - val_loss: 0.0290 - val_mae: 0.0921\n",
            "Epoch 310/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0284 - mae: 0.0914 - val_loss: 0.0291 - val_mae: 0.0916\n",
            "Epoch 311/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0284 - mae: 0.0912 - val_loss: 0.0291 - val_mae: 0.0917\n",
            "Epoch 312/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0285 - mae: 0.0916 - val_loss: 0.0291 - val_mae: 0.0923\n",
            "Epoch 313/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0284 - mae: 0.0913 - val_loss: 0.0292 - val_mae: 0.0925\n",
            "Epoch 314/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0285 - mae: 0.0915 - val_loss: 0.0295 - val_mae: 0.0923\n",
            "Epoch 315/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0284 - mae: 0.0912 - val_loss: 0.0294 - val_mae: 0.0922\n",
            "Epoch 316/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0284 - mae: 0.0913 - val_loss: 0.0294 - val_mae: 0.0931\n",
            "Epoch 317/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0284 - mae: 0.0913 - val_loss: 0.0291 - val_mae: 0.0916\n",
            "Epoch 318/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0284 - mae: 0.0914 - val_loss: 0.0293 - val_mae: 0.0924\n",
            "Epoch 319/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0284 - mae: 0.0913 - val_loss: 0.0291 - val_mae: 0.0918\n",
            "Epoch 320/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0284 - mae: 0.0913 - val_loss: 0.0293 - val_mae: 0.0929\n",
            "Epoch 321/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0285 - mae: 0.0914 - val_loss: 0.0296 - val_mae: 0.0932\n",
            "Epoch 322/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0284 - mae: 0.0912 - val_loss: 0.0288 - val_mae: 0.0911\n",
            "Epoch 323/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0283 - mae: 0.0912 - val_loss: 0.0290 - val_mae: 0.0915\n",
            "Epoch 324/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0283 - mae: 0.0912 - val_loss: 0.0289 - val_mae: 0.0914\n",
            "Epoch 325/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0282 - mae: 0.0910 - val_loss: 0.0293 - val_mae: 0.0924\n",
            "Epoch 326/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0283 - mae: 0.0911 - val_loss: 0.0290 - val_mae: 0.0919\n",
            "Epoch 327/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0283 - mae: 0.0911 - val_loss: 0.0288 - val_mae: 0.0915\n",
            "Epoch 328/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0282 - mae: 0.0910 - val_loss: 0.0293 - val_mae: 0.0924\n",
            "Epoch 329/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0284 - mae: 0.0912 - val_loss: 0.0288 - val_mae: 0.0918\n",
            "Epoch 330/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0283 - mae: 0.0909 - val_loss: 0.0289 - val_mae: 0.0916\n",
            "Epoch 331/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0283 - mae: 0.0912 - val_loss: 0.0288 - val_mae: 0.0911\n",
            "Epoch 332/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0281 - mae: 0.0908 - val_loss: 0.0296 - val_mae: 0.0929\n",
            "Epoch 333/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0283 - mae: 0.0911 - val_loss: 0.0291 - val_mae: 0.0921\n",
            "Epoch 334/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0283 - mae: 0.0910 - val_loss: 0.0289 - val_mae: 0.0919\n",
            "Epoch 335/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0285 - mae: 0.0913 - val_loss: 0.0290 - val_mae: 0.0915\n",
            "Epoch 336/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0282 - mae: 0.0909 - val_loss: 0.0290 - val_mae: 0.0923\n",
            "Epoch 337/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0282 - mae: 0.0911 - val_loss: 0.0292 - val_mae: 0.0928\n",
            "Epoch 338/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0282 - mae: 0.0910 - val_loss: 0.0289 - val_mae: 0.0914\n",
            "Epoch 339/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0281 - mae: 0.0909 - val_loss: 0.0289 - val_mae: 0.0914\n",
            "Epoch 340/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0281 - mae: 0.0907 - val_loss: 0.0289 - val_mae: 0.0917\n",
            "Epoch 341/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0282 - mae: 0.0910 - val_loss: 0.0288 - val_mae: 0.0909\n",
            "Epoch 342/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0281 - mae: 0.0909 - val_loss: 0.0287 - val_mae: 0.0913\n",
            "Epoch 343/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0281 - mae: 0.0907 - val_loss: 0.0286 - val_mae: 0.0909\n",
            "Epoch 344/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0281 - mae: 0.0907 - val_loss: 0.0286 - val_mae: 0.0909\n",
            "Epoch 345/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0282 - mae: 0.0910 - val_loss: 0.0290 - val_mae: 0.0924\n",
            "Epoch 346/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0281 - mae: 0.0909 - val_loss: 0.0288 - val_mae: 0.0919\n",
            "Epoch 347/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0281 - mae: 0.0908 - val_loss: 0.0288 - val_mae: 0.0915\n",
            "Epoch 348/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0280 - mae: 0.0906 - val_loss: 0.0286 - val_mae: 0.0910\n",
            "Epoch 349/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0282 - mae: 0.0909 - val_loss: 0.0287 - val_mae: 0.0913\n",
            "Epoch 350/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0280 - mae: 0.0906 - val_loss: 0.0290 - val_mae: 0.0925\n",
            "Epoch 351/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0281 - mae: 0.0907 - val_loss: 0.0289 - val_mae: 0.0918\n",
            "Epoch 352/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0281 - mae: 0.0908 - val_loss: 0.0285 - val_mae: 0.0908\n",
            "Epoch 353/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0280 - mae: 0.0906 - val_loss: 0.0289 - val_mae: 0.0913\n",
            "Epoch 354/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0280 - mae: 0.0905 - val_loss: 0.0288 - val_mae: 0.0914\n",
            "Epoch 355/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0280 - mae: 0.0906 - val_loss: 0.0295 - val_mae: 0.0924\n",
            "Epoch 356/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0281 - mae: 0.0907 - val_loss: 0.0287 - val_mae: 0.0914\n",
            "Epoch 357/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0280 - mae: 0.0905 - val_loss: 0.0286 - val_mae: 0.0906\n",
            "Epoch 358/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0281 - mae: 0.0907 - val_loss: 0.0288 - val_mae: 0.0921\n",
            "Epoch 359/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0282 - mae: 0.0909 - val_loss: 0.0286 - val_mae: 0.0909\n",
            "Epoch 360/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0278 - mae: 0.0903 - val_loss: 0.0291 - val_mae: 0.0916\n",
            "Epoch 361/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0281 - mae: 0.0907 - val_loss: 0.0285 - val_mae: 0.0909\n",
            "Epoch 362/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0279 - mae: 0.0903 - val_loss: 0.0288 - val_mae: 0.0911\n",
            "Epoch 363/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0279 - mae: 0.0904 - val_loss: 0.0288 - val_mae: 0.0915\n",
            "Epoch 364/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0279 - mae: 0.0904 - val_loss: 0.0285 - val_mae: 0.0908\n",
            "Epoch 365/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0278 - mae: 0.0901 - val_loss: 0.0287 - val_mae: 0.0917\n",
            "Epoch 366/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0281 - mae: 0.0907 - val_loss: 0.0291 - val_mae: 0.0930\n",
            "Epoch 367/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0278 - mae: 0.0904 - val_loss: 0.0293 - val_mae: 0.0924\n",
            "Epoch 368/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0285 - mae: 0.0911 - val_loss: 0.0285 - val_mae: 0.0905\n",
            "Epoch 369/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0281 - mae: 0.0904 - val_loss: 0.0286 - val_mae: 0.0909\n",
            "Epoch 370/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0279 - mae: 0.0902 - val_loss: 0.0284 - val_mae: 0.0905\n",
            "Epoch 371/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0279 - mae: 0.0903 - val_loss: 0.0286 - val_mae: 0.0910\n",
            "Epoch 372/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0278 - mae: 0.0902 - val_loss: 0.0285 - val_mae: 0.0911\n",
            "Epoch 373/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0278 - mae: 0.0902 - val_loss: 0.0287 - val_mae: 0.0910\n",
            "Epoch 374/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0279 - mae: 0.0903 - val_loss: 0.0285 - val_mae: 0.0905\n",
            "Epoch 375/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0278 - mae: 0.0902 - val_loss: 0.0285 - val_mae: 0.0907\n",
            "Epoch 376/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0279 - mae: 0.0902 - val_loss: 0.0285 - val_mae: 0.0907\n",
            "Epoch 377/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0278 - mae: 0.0902 - val_loss: 0.0285 - val_mae: 0.0913\n",
            "Epoch 378/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0278 - mae: 0.0902 - val_loss: 0.0285 - val_mae: 0.0909\n",
            "Epoch 379/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0277 - mae: 0.0900 - val_loss: 0.0284 - val_mae: 0.0905\n",
            "Epoch 380/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0278 - mae: 0.0902 - val_loss: 0.0287 - val_mae: 0.0915\n",
            "Epoch 381/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0278 - mae: 0.0902 - val_loss: 0.0285 - val_mae: 0.0902\n",
            "Epoch 382/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0278 - mae: 0.0902 - val_loss: 0.0288 - val_mae: 0.0912\n",
            "Epoch 383/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0278 - mae: 0.0901 - val_loss: 0.0286 - val_mae: 0.0916\n",
            "Epoch 384/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0277 - mae: 0.0900 - val_loss: 0.0288 - val_mae: 0.0906\n",
            "Epoch 385/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0279 - mae: 0.0903 - val_loss: 0.0284 - val_mae: 0.0906\n",
            "Epoch 386/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0276 - mae: 0.0898 - val_loss: 0.0291 - val_mae: 0.0918\n",
            "Epoch 387/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0278 - mae: 0.0901 - val_loss: 0.0290 - val_mae: 0.0918\n",
            "Epoch 388/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0278 - mae: 0.0901 - val_loss: 0.0284 - val_mae: 0.0906\n",
            "Epoch 389/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0277 - mae: 0.0900 - val_loss: 0.0287 - val_mae: 0.0909\n",
            "Epoch 390/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0278 - mae: 0.0902 - val_loss: 0.0283 - val_mae: 0.0903\n",
            "Epoch 391/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0277 - mae: 0.0900 - val_loss: 0.0283 - val_mae: 0.0900\n",
            "Epoch 392/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0278 - mae: 0.0900 - val_loss: 0.0284 - val_mae: 0.0910\n",
            "Epoch 393/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0278 - mae: 0.0901 - val_loss: 0.0282 - val_mae: 0.0900\n",
            "Epoch 394/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0276 - mae: 0.0896 - val_loss: 0.0286 - val_mae: 0.0913\n",
            "Epoch 395/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0276 - mae: 0.0897 - val_loss: 0.0286 - val_mae: 0.0912\n",
            "Epoch 396/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0277 - mae: 0.0899 - val_loss: 0.0285 - val_mae: 0.0910\n",
            "Epoch 397/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0278 - mae: 0.0900 - val_loss: 0.0284 - val_mae: 0.0907\n",
            "Epoch 398/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0277 - mae: 0.0899 - val_loss: 0.0283 - val_mae: 0.0901\n",
            "Epoch 399/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0277 - mae: 0.0898 - val_loss: 0.0283 - val_mae: 0.0898\n",
            "Epoch 400/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0276 - mae: 0.0897 - val_loss: 0.0284 - val_mae: 0.0904\n",
            "Epoch 401/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0277 - mae: 0.0898 - val_loss: 0.0285 - val_mae: 0.0903\n",
            "Epoch 402/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0276 - mae: 0.0898 - val_loss: 0.0286 - val_mae: 0.0902\n",
            "Epoch 403/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0276 - mae: 0.0897 - val_loss: 0.0283 - val_mae: 0.0906\n",
            "Epoch 404/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0276 - mae: 0.0898 - val_loss: 0.0289 - val_mae: 0.0919\n",
            "Epoch 405/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0277 - mae: 0.0898 - val_loss: 0.0283 - val_mae: 0.0903\n",
            "Epoch 406/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0276 - mae: 0.0897 - val_loss: 0.0284 - val_mae: 0.0904\n",
            "Epoch 407/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0275 - mae: 0.0895 - val_loss: 0.0286 - val_mae: 0.0912\n",
            "Epoch 408/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0276 - mae: 0.0897 - val_loss: 0.0281 - val_mae: 0.0899\n",
            "Epoch 409/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0276 - mae: 0.0898 - val_loss: 0.0282 - val_mae: 0.0897\n",
            "Epoch 410/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0276 - mae: 0.0895 - val_loss: 0.0282 - val_mae: 0.0897\n",
            "Epoch 411/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0276 - mae: 0.0896 - val_loss: 0.0283 - val_mae: 0.0908\n",
            "Epoch 412/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0275 - mae: 0.0896 - val_loss: 0.0282 - val_mae: 0.0896\n",
            "Epoch 413/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0277 - mae: 0.0898 - val_loss: 0.0282 - val_mae: 0.0903\n",
            "Epoch 414/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0275 - mae: 0.0895 - val_loss: 0.0281 - val_mae: 0.0896\n",
            "Epoch 415/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0275 - mae: 0.0895 - val_loss: 0.0282 - val_mae: 0.0899\n",
            "Epoch 416/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0275 - mae: 0.0895 - val_loss: 0.0285 - val_mae: 0.0910\n",
            "Epoch 417/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0276 - mae: 0.0896 - val_loss: 0.0284 - val_mae: 0.0908\n",
            "Epoch 418/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0276 - mae: 0.0898 - val_loss: 0.0285 - val_mae: 0.0911\n",
            "Epoch 419/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0274 - mae: 0.0894 - val_loss: 0.0282 - val_mae: 0.0897\n",
            "Epoch 420/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0275 - mae: 0.0894 - val_loss: 0.0283 - val_mae: 0.0902\n",
            "Epoch 421/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0275 - mae: 0.0894 - val_loss: 0.0283 - val_mae: 0.0912\n",
            "Epoch 422/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0276 - mae: 0.0897 - val_loss: 0.0280 - val_mae: 0.0895\n",
            "Epoch 423/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0275 - mae: 0.0895 - val_loss: 0.0281 - val_mae: 0.0896\n",
            "Epoch 424/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0275 - mae: 0.0895 - val_loss: 0.0282 - val_mae: 0.0907\n",
            "Epoch 425/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0276 - mae: 0.0895 - val_loss: 0.0282 - val_mae: 0.0894\n",
            "Epoch 426/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0274 - mae: 0.0894 - val_loss: 0.0285 - val_mae: 0.0910\n",
            "Epoch 427/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0275 - mae: 0.0895 - val_loss: 0.0282 - val_mae: 0.0901\n",
            "Epoch 428/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0275 - mae: 0.0895 - val_loss: 0.0281 - val_mae: 0.0897\n",
            "Epoch 429/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0274 - mae: 0.0892 - val_loss: 0.0282 - val_mae: 0.0902\n",
            "Epoch 430/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0275 - mae: 0.0894 - val_loss: 0.0281 - val_mae: 0.0904\n",
            "Epoch 431/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0274 - mae: 0.0891 - val_loss: 0.0288 - val_mae: 0.0908\n",
            "Epoch 432/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0277 - mae: 0.0895 - val_loss: 0.0283 - val_mae: 0.0903\n",
            "Epoch 433/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0274 - mae: 0.0891 - val_loss: 0.0283 - val_mae: 0.0901\n",
            "Epoch 434/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0275 - mae: 0.0895 - val_loss: 0.0282 - val_mae: 0.0896\n",
            "Epoch 435/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0273 - mae: 0.0891 - val_loss: 0.0281 - val_mae: 0.0904\n",
            "Epoch 436/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0273 - mae: 0.0891 - val_loss: 0.0284 - val_mae: 0.0904\n",
            "Epoch 437/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0274 - mae: 0.0893 - val_loss: 0.0280 - val_mae: 0.0898\n",
            "Epoch 438/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0273 - mae: 0.0891 - val_loss: 0.0284 - val_mae: 0.0910\n",
            "Epoch 439/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0275 - mae: 0.0892 - val_loss: 0.0287 - val_mae: 0.0908\n",
            "Epoch 440/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0274 - mae: 0.0892 - val_loss: 0.0286 - val_mae: 0.0908\n",
            "Epoch 441/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0282 - mae: 0.0902 - val_loss: 0.0282 - val_mae: 0.0895\n",
            "Epoch 442/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0275 - mae: 0.0893 - val_loss: 0.0281 - val_mae: 0.0900\n",
            "Epoch 443/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0273 - mae: 0.0891 - val_loss: 0.0280 - val_mae: 0.0894\n",
            "Epoch 444/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0273 - mae: 0.0890 - val_loss: 0.0281 - val_mae: 0.0895\n",
            "Epoch 445/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0273 - mae: 0.0891 - val_loss: 0.0279 - val_mae: 0.0894\n",
            "Epoch 446/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0273 - mae: 0.0890 - val_loss: 0.0282 - val_mae: 0.0903\n",
            "Epoch 447/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0274 - mae: 0.0890 - val_loss: 0.0280 - val_mae: 0.0896\n",
            "Epoch 448/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0274 - mae: 0.0892 - val_loss: 0.0282 - val_mae: 0.0904\n",
            "Epoch 449/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0273 - mae: 0.0890 - val_loss: 0.0279 - val_mae: 0.0898\n",
            "Epoch 450/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0273 - mae: 0.0890 - val_loss: 0.0279 - val_mae: 0.0892\n",
            "Epoch 451/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0273 - mae: 0.0891 - val_loss: 0.0283 - val_mae: 0.0899\n",
            "Epoch 452/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0273 - mae: 0.0890 - val_loss: 0.0283 - val_mae: 0.0905\n",
            "Epoch 453/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0274 - mae: 0.0892 - val_loss: 0.0280 - val_mae: 0.0898\n",
            "Epoch 454/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0273 - mae: 0.0890 - val_loss: 0.0280 - val_mae: 0.0893\n",
            "Epoch 455/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0273 - mae: 0.0890 - val_loss: 0.0277 - val_mae: 0.0886\n",
            "Epoch 456/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0273 - mae: 0.0889 - val_loss: 0.0279 - val_mae: 0.0892\n",
            "Epoch 457/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0273 - mae: 0.0890 - val_loss: 0.0282 - val_mae: 0.0899\n",
            "Epoch 458/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0273 - mae: 0.0890 - val_loss: 0.0280 - val_mae: 0.0893\n",
            "Epoch 459/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0273 - mae: 0.0889 - val_loss: 0.0281 - val_mae: 0.0900\n",
            "Epoch 460/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0272 - mae: 0.0889 - val_loss: 0.0280 - val_mae: 0.0900\n",
            "Epoch 461/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0272 - mae: 0.0889 - val_loss: 0.0279 - val_mae: 0.0895\n",
            "Epoch 462/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0273 - mae: 0.0890 - val_loss: 0.0279 - val_mae: 0.0888\n",
            "Epoch 463/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0272 - mae: 0.0889 - val_loss: 0.0281 - val_mae: 0.0900\n",
            "Epoch 464/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0272 - mae: 0.0887 - val_loss: 0.0281 - val_mae: 0.0895\n",
            "Epoch 465/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0274 - mae: 0.0892 - val_loss: 0.0279 - val_mae: 0.0892\n",
            "Epoch 466/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0272 - mae: 0.0888 - val_loss: 0.0277 - val_mae: 0.0890\n",
            "Epoch 467/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0272 - mae: 0.0888 - val_loss: 0.0280 - val_mae: 0.0897\n",
            "Epoch 468/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0272 - mae: 0.0888 - val_loss: 0.0282 - val_mae: 0.0907\n",
            "Epoch 469/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0273 - mae: 0.0888 - val_loss: 0.0278 - val_mae: 0.0886\n",
            "Epoch 470/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0272 - mae: 0.0887 - val_loss: 0.0280 - val_mae: 0.0895\n",
            "Epoch 471/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0272 - mae: 0.0888 - val_loss: 0.0280 - val_mae: 0.0893\n",
            "Epoch 472/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0272 - mae: 0.0888 - val_loss: 0.0278 - val_mae: 0.0893\n",
            "Epoch 473/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0273 - mae: 0.0890 - val_loss: 0.0278 - val_mae: 0.0890\n",
            "Epoch 474/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0271 - mae: 0.0886 - val_loss: 0.0280 - val_mae: 0.0897\n",
            "Epoch 475/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0271 - mae: 0.0888 - val_loss: 0.0279 - val_mae: 0.0891\n",
            "Epoch 476/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0271 - mae: 0.0885 - val_loss: 0.0279 - val_mae: 0.0898\n",
            "Epoch 477/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0271 - mae: 0.0887 - val_loss: 0.0282 - val_mae: 0.0896\n",
            "Epoch 478/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0272 - mae: 0.0887 - val_loss: 0.0277 - val_mae: 0.0888\n",
            "Epoch 479/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0272 - mae: 0.0887 - val_loss: 0.0280 - val_mae: 0.0899\n",
            "Epoch 480/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0271 - mae: 0.0886 - val_loss: 0.0279 - val_mae: 0.0893\n",
            "Epoch 481/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0271 - mae: 0.0885 - val_loss: 0.0278 - val_mae: 0.0891\n",
            "Epoch 482/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0271 - mae: 0.0886 - val_loss: 0.0278 - val_mae: 0.0887\n",
            "Epoch 483/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0272 - mae: 0.0886 - val_loss: 0.0279 - val_mae: 0.0895\n",
            "Epoch 484/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0271 - mae: 0.0887 - val_loss: 0.0278 - val_mae: 0.0887\n",
            "Epoch 485/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0271 - mae: 0.0885 - val_loss: 0.0278 - val_mae: 0.0891\n",
            "Epoch 486/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0272 - mae: 0.0887 - val_loss: 0.0279 - val_mae: 0.0894\n",
            "Epoch 487/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0885 - val_loss: 0.0277 - val_mae: 0.0889\n",
            "Epoch 488/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0272 - mae: 0.0887 - val_loss: 0.0277 - val_mae: 0.0894\n",
            "Epoch 489/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0272 - mae: 0.0889 - val_loss: 0.0279 - val_mae: 0.0893\n",
            "Epoch 490/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0884 - val_loss: 0.0276 - val_mae: 0.0889\n",
            "Epoch 491/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0884 - val_loss: 0.0279 - val_mae: 0.0897\n",
            "Epoch 492/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0271 - mae: 0.0885 - val_loss: 0.0278 - val_mae: 0.0884\n",
            "Epoch 493/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0271 - mae: 0.0886 - val_loss: 0.0277 - val_mae: 0.0892\n",
            "Epoch 494/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0884 - val_loss: 0.0276 - val_mae: 0.0891\n",
            "Epoch 495/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0885 - val_loss: 0.0279 - val_mae: 0.0893\n",
            "Epoch 496/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0884 - val_loss: 0.0278 - val_mae: 0.0894\n",
            "Epoch 497/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0271 - mae: 0.0886 - val_loss: 0.0277 - val_mae: 0.0886\n",
            "Epoch 498/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0273 - mae: 0.0888 - val_loss: 0.0277 - val_mae: 0.0893\n",
            "Epoch 499/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0271 - mae: 0.0886 - val_loss: 0.0279 - val_mae: 0.0897\n",
            "Epoch 500/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0884 - val_loss: 0.0277 - val_mae: 0.0893\n",
            "Epoch 501/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0883 - val_loss: 0.0277 - val_mae: 0.0888\n",
            "Epoch 502/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0271 - mae: 0.0885 - val_loss: 0.0277 - val_mae: 0.0887\n",
            "Epoch 503/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0884 - val_loss: 0.0278 - val_mae: 0.0897\n",
            "Epoch 504/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0884 - val_loss: 0.0278 - val_mae: 0.0895\n",
            "Epoch 505/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0272 - mae: 0.0887 - val_loss: 0.0276 - val_mae: 0.0885\n",
            "Epoch 506/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0270 - mae: 0.0884 - val_loss: 0.0278 - val_mae: 0.0891\n",
            "Epoch 507/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0884 - val_loss: 0.0277 - val_mae: 0.0889\n",
            "Epoch 508/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0884 - val_loss: 0.0278 - val_mae: 0.0894\n",
            "Epoch 509/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0271 - mae: 0.0884 - val_loss: 0.0277 - val_mae: 0.0886\n",
            "Epoch 510/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0883 - val_loss: 0.0277 - val_mae: 0.0886\n",
            "Epoch 511/1000\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0270 - mae: 0.0885 - val_loss: 0.0275 - val_mae: 0.0885\n",
            "Epoch 512/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0881 - val_loss: 0.0278 - val_mae: 0.0895\n",
            "Epoch 513/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0882 - val_loss: 0.0278 - val_mae: 0.0892\n",
            "Epoch 514/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0271 - mae: 0.0885 - val_loss: 0.0282 - val_mae: 0.0907\n",
            "Epoch 515/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0883 - val_loss: 0.0278 - val_mae: 0.0897\n",
            "Epoch 516/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0881 - val_loss: 0.0276 - val_mae: 0.0885\n",
            "Epoch 517/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0881 - val_loss: 0.0278 - val_mae: 0.0893\n",
            "Epoch 518/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0885 - val_loss: 0.0279 - val_mae: 0.0892\n",
            "Epoch 519/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0884 - val_loss: 0.0275 - val_mae: 0.0885\n",
            "Epoch 520/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0882 - val_loss: 0.0277 - val_mae: 0.0895\n",
            "Epoch 521/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0879 - val_loss: 0.0277 - val_mae: 0.0889\n",
            "Epoch 522/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0881 - val_loss: 0.0276 - val_mae: 0.0882\n",
            "Epoch 523/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0881 - val_loss: 0.0275 - val_mae: 0.0883\n",
            "Epoch 524/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0882 - val_loss: 0.0276 - val_mae: 0.0888\n",
            "Epoch 525/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0883 - val_loss: 0.0283 - val_mae: 0.0910\n",
            "Epoch 526/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0882 - val_loss: 0.0288 - val_mae: 0.0916\n",
            "Epoch 527/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0270 - mae: 0.0883 - val_loss: 0.0276 - val_mae: 0.0891\n",
            "Epoch 528/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0880 - val_loss: 0.0275 - val_mae: 0.0885\n",
            "Epoch 529/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0881 - val_loss: 0.0277 - val_mae: 0.0887\n",
            "Epoch 530/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0882 - val_loss: 0.0277 - val_mae: 0.0889\n",
            "Epoch 531/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0269 - mae: 0.0881 - val_loss: 0.0276 - val_mae: 0.0889\n",
            "Epoch 532/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0882 - val_loss: 0.0276 - val_mae: 0.0888\n",
            "Epoch 533/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0882 - val_loss: 0.0276 - val_mae: 0.0888\n",
            "Epoch 534/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0880 - val_loss: 0.0274 - val_mae: 0.0886\n",
            "Epoch 535/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0269 - mae: 0.0880 - val_loss: 0.0280 - val_mae: 0.0894\n",
            "Epoch 536/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0270 - mae: 0.0881 - val_loss: 0.0274 - val_mae: 0.0883\n",
            "Epoch 537/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0878 - val_loss: 0.0276 - val_mae: 0.0888\n",
            "Epoch 538/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0878 - val_loss: 0.0279 - val_mae: 0.0895\n",
            "Epoch 539/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.0882 - val_loss: 0.0281 - val_mae: 0.0895\n",
            "Epoch 540/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0880 - val_loss: 0.0275 - val_mae: 0.0884\n",
            "Epoch 541/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0880 - val_loss: 0.0276 - val_mae: 0.0883\n",
            "Epoch 542/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0880 - val_loss: 0.0275 - val_mae: 0.0884\n",
            "Epoch 543/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0268 - mae: 0.0879 - val_loss: 0.0274 - val_mae: 0.0879\n",
            "Epoch 544/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0878 - val_loss: 0.0276 - val_mae: 0.0892\n",
            "Epoch 545/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0879 - val_loss: 0.0276 - val_mae: 0.0889\n",
            "Epoch 546/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0880 - val_loss: 0.0276 - val_mae: 0.0881\n",
            "Epoch 547/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0269 - mae: 0.0881 - val_loss: 0.0274 - val_mae: 0.0884\n",
            "Epoch 548/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0268 - mae: 0.0878 - val_loss: 0.0274 - val_mae: 0.0887\n",
            "Epoch 549/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0269 - mae: 0.0882 - val_loss: 0.0277 - val_mae: 0.0891\n",
            "Epoch 550/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0880 - val_loss: 0.0275 - val_mae: 0.0878\n",
            "Epoch 551/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0267 - mae: 0.0876 - val_loss: 0.0274 - val_mae: 0.0885\n",
            "Epoch 552/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0878 - val_loss: 0.0279 - val_mae: 0.0895\n",
            "Epoch 553/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0268 - mae: 0.0878 - val_loss: 0.0275 - val_mae: 0.0896\n",
            "Epoch 554/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0268 - mae: 0.0879 - val_loss: 0.0276 - val_mae: 0.0885\n",
            "Epoch 555/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0269 - mae: 0.0881 - val_loss: 0.0275 - val_mae: 0.0885\n",
            "Epoch 556/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0878 - val_loss: 0.0277 - val_mae: 0.0885\n",
            "Epoch 557/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0879 - val_loss: 0.0276 - val_mae: 0.0882\n",
            "Epoch 558/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0879 - val_loss: 0.0274 - val_mae: 0.0887\n",
            "Epoch 559/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0879 - val_loss: 0.0278 - val_mae: 0.0897\n",
            "Epoch 560/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0267 - mae: 0.0878 - val_loss: 0.0274 - val_mae: 0.0884\n",
            "Epoch 561/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0266 - mae: 0.0877 - val_loss: 0.0273 - val_mae: 0.0879\n",
            "Epoch 562/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0267 - mae: 0.0876 - val_loss: 0.0274 - val_mae: 0.0883\n",
            "Epoch 563/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0879 - val_loss: 0.0278 - val_mae: 0.0890\n",
            "Epoch 564/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0878 - val_loss: 0.0279 - val_mae: 0.0881\n",
            "Epoch 565/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0267 - mae: 0.0876 - val_loss: 0.0273 - val_mae: 0.0877\n",
            "Epoch 566/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0267 - mae: 0.0875 - val_loss: 0.0273 - val_mae: 0.0879\n",
            "Epoch 567/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0267 - mae: 0.0877 - val_loss: 0.0276 - val_mae: 0.0891\n",
            "Epoch 568/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0879 - val_loss: 0.0272 - val_mae: 0.0876\n",
            "Epoch 569/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0267 - mae: 0.0878 - val_loss: 0.0275 - val_mae: 0.0879\n",
            "Epoch 570/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0267 - mae: 0.0876 - val_loss: 0.0275 - val_mae: 0.0883\n",
            "Epoch 571/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0267 - mae: 0.0876 - val_loss: 0.0274 - val_mae: 0.0885\n",
            "Epoch 572/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0878 - val_loss: 0.0273 - val_mae: 0.0880\n",
            "Epoch 573/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0267 - mae: 0.0877 - val_loss: 0.0275 - val_mae: 0.0884\n",
            "Epoch 574/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0266 - mae: 0.0876 - val_loss: 0.0283 - val_mae: 0.0912\n",
            "Epoch 575/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0879 - val_loss: 0.0275 - val_mae: 0.0883\n",
            "Epoch 576/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0266 - mae: 0.0874 - val_loss: 0.0273 - val_mae: 0.0883\n",
            "Epoch 577/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0267 - mae: 0.0876 - val_loss: 0.0274 - val_mae: 0.0883\n",
            "Epoch 578/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0266 - mae: 0.0875 - val_loss: 0.0274 - val_mae: 0.0875\n",
            "Epoch 579/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0267 - mae: 0.0877 - val_loss: 0.0275 - val_mae: 0.0884\n",
            "Epoch 580/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0267 - mae: 0.0876 - val_loss: 0.0274 - val_mae: 0.0889\n",
            "Epoch 581/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0267 - mae: 0.0879 - val_loss: 0.0275 - val_mae: 0.0882\n",
            "Epoch 582/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0267 - mae: 0.0876 - val_loss: 0.0272 - val_mae: 0.0881\n",
            "Epoch 583/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0266 - mae: 0.0875 - val_loss: 0.0274 - val_mae: 0.0879\n",
            "Epoch 584/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0266 - mae: 0.0875 - val_loss: 0.0274 - val_mae: 0.0880\n",
            "Epoch 585/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0266 - mae: 0.0876 - val_loss: 0.0276 - val_mae: 0.0884\n",
            "Epoch 586/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0266 - mae: 0.0875 - val_loss: 0.0272 - val_mae: 0.0876\n",
            "Epoch 587/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0266 - mae: 0.0875 - val_loss: 0.0274 - val_mae: 0.0886\n",
            "Epoch 588/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0267 - mae: 0.0876 - val_loss: 0.0273 - val_mae: 0.0879\n",
            "Epoch 589/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0266 - mae: 0.0875 - val_loss: 0.0272 - val_mae: 0.0875\n",
            "Epoch 590/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0266 - mae: 0.0874 - val_loss: 0.0275 - val_mae: 0.0885\n",
            "Epoch 591/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.0878 - val_loss: 0.0274 - val_mae: 0.0875\n",
            "Epoch 592/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0266 - mae: 0.0876 - val_loss: 0.0277 - val_mae: 0.0887\n",
            "Epoch 593/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0273 - val_mae: 0.0877\n",
            "Epoch 594/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0266 - mae: 0.0874 - val_loss: 0.0273 - val_mae: 0.0884\n",
            "Epoch 595/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0275 - val_mae: 0.0879\n",
            "Epoch 596/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0266 - mae: 0.0875 - val_loss: 0.0274 - val_mae: 0.0885\n",
            "Epoch 597/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0266 - mae: 0.0875 - val_loss: 0.0278 - val_mae: 0.0887\n",
            "Epoch 598/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0267 - mae: 0.0876 - val_loss: 0.0275 - val_mae: 0.0883\n",
            "Epoch 599/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0266 - mae: 0.0874 - val_loss: 0.0273 - val_mae: 0.0883\n",
            "Epoch 600/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0266 - mae: 0.0874 - val_loss: 0.0271 - val_mae: 0.0875\n",
            "Epoch 601/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0872 - val_loss: 0.0274 - val_mae: 0.0891\n",
            "Epoch 602/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0266 - mae: 0.0874 - val_loss: 0.0274 - val_mae: 0.0885\n",
            "Epoch 603/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0265 - mae: 0.0872 - val_loss: 0.0273 - val_mae: 0.0878\n",
            "Epoch 604/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0266 - mae: 0.0874 - val_loss: 0.0272 - val_mae: 0.0879\n",
            "Epoch 605/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0265 - mae: 0.0872 - val_loss: 0.0273 - val_mae: 0.0881\n",
            "Epoch 606/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0275 - val_mae: 0.0889\n",
            "Epoch 607/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0265 - mae: 0.0874 - val_loss: 0.0271 - val_mae: 0.0876\n",
            "Epoch 608/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0272 - val_mae: 0.0880\n",
            "Epoch 609/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0274 - val_mae: 0.0875\n",
            "Epoch 610/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0276 - val_mae: 0.0887\n",
            "Epoch 611/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0266 - mae: 0.0874 - val_loss: 0.0274 - val_mae: 0.0882\n",
            "Epoch 612/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0272 - val_mae: 0.0876\n",
            "Epoch 613/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0872 - val_loss: 0.0274 - val_mae: 0.0874\n",
            "Epoch 614/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0874 - val_loss: 0.0271 - val_mae: 0.0869\n",
            "Epoch 615/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0871 - val_loss: 0.0274 - val_mae: 0.0894\n",
            "Epoch 616/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0271 - val_mae: 0.0874\n",
            "Epoch 617/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0266 - mae: 0.0874 - val_loss: 0.0271 - val_mae: 0.0878\n",
            "Epoch 618/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0872 - val_loss: 0.0273 - val_mae: 0.0887\n",
            "Epoch 619/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0273 - val_mae: 0.0886\n",
            "Epoch 620/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0274 - val_mae: 0.0873\n",
            "Epoch 621/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0872 - val_loss: 0.0274 - val_mae: 0.0882\n",
            "Epoch 622/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0872 - val_loss: 0.0274 - val_mae: 0.0890\n",
            "Epoch 623/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0266 - mae: 0.0874 - val_loss: 0.0273 - val_mae: 0.0876\n",
            "Epoch 624/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0264 - mae: 0.0870 - val_loss: 0.0275 - val_mae: 0.0882\n",
            "Epoch 625/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0264 - mae: 0.0870 - val_loss: 0.0273 - val_mae: 0.0880\n",
            "Epoch 626/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0272 - val_mae: 0.0876\n",
            "Epoch 627/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0273 - val_mae: 0.0882\n",
            "Epoch 628/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0271 - val_mae: 0.0872\n",
            "Epoch 629/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0264 - mae: 0.0869 - val_loss: 0.0270 - val_mae: 0.0880\n",
            "Epoch 630/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0273 - val_mae: 0.0889\n",
            "Epoch 631/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0264 - mae: 0.0871 - val_loss: 0.0273 - val_mae: 0.0881\n",
            "Epoch 632/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0264 - mae: 0.0871 - val_loss: 0.0273 - val_mae: 0.0882\n",
            "Epoch 633/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0264 - mae: 0.0870 - val_loss: 0.0273 - val_mae: 0.0877\n",
            "Epoch 634/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0264 - mae: 0.0872 - val_loss: 0.0272 - val_mae: 0.0878\n",
            "Epoch 635/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0264 - mae: 0.0872 - val_loss: 0.0273 - val_mae: 0.0870\n",
            "Epoch 636/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0872 - val_loss: 0.0273 - val_mae: 0.0878\n",
            "Epoch 637/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0264 - mae: 0.0872 - val_loss: 0.0271 - val_mae: 0.0880\n",
            "Epoch 638/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0264 - mae: 0.0871 - val_loss: 0.0271 - val_mae: 0.0868\n",
            "Epoch 639/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0263 - mae: 0.0869 - val_loss: 0.0272 - val_mae: 0.0882\n",
            "Epoch 640/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0264 - mae: 0.0871 - val_loss: 0.0272 - val_mae: 0.0874\n",
            "Epoch 641/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0264 - mae: 0.0869 - val_loss: 0.0273 - val_mae: 0.0886\n",
            "Epoch 642/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0264 - mae: 0.0871 - val_loss: 0.0276 - val_mae: 0.0891\n",
            "Epoch 643/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0264 - mae: 0.0871 - val_loss: 0.0271 - val_mae: 0.0880\n",
            "Epoch 644/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0271 - val_mae: 0.0873\n",
            "Epoch 645/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0264 - mae: 0.0871 - val_loss: 0.0271 - val_mae: 0.0873\n",
            "Epoch 646/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0264 - mae: 0.0871 - val_loss: 0.0273 - val_mae: 0.0877\n",
            "Epoch 647/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0264 - mae: 0.0869 - val_loss: 0.0270 - val_mae: 0.0868\n",
            "Epoch 648/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0263 - mae: 0.0868 - val_loss: 0.0272 - val_mae: 0.0878\n",
            "Epoch 649/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0265 - mae: 0.0872 - val_loss: 0.0270 - val_mae: 0.0874\n",
            "Epoch 650/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0263 - mae: 0.0869 - val_loss: 0.0273 - val_mae: 0.0878\n",
            "Epoch 651/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0264 - mae: 0.0872 - val_loss: 0.0271 - val_mae: 0.0878\n",
            "Epoch 652/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0264 - mae: 0.0871 - val_loss: 0.0273 - val_mae: 0.0878\n",
            "Epoch 653/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0264 - mae: 0.0870 - val_loss: 0.0273 - val_mae: 0.0887\n",
            "Epoch 654/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0869 - val_loss: 0.0272 - val_mae: 0.0873\n",
            "Epoch 655/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0264 - mae: 0.0870 - val_loss: 0.0271 - val_mae: 0.0875\n",
            "Epoch 656/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0263 - mae: 0.0870 - val_loss: 0.0273 - val_mae: 0.0882\n",
            "Epoch 657/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0264 - mae: 0.0871 - val_loss: 0.0272 - val_mae: 0.0876\n",
            "Epoch 658/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0263 - mae: 0.0868 - val_loss: 0.0275 - val_mae: 0.0881\n",
            "Epoch 659/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0263 - mae: 0.0869 - val_loss: 0.0274 - val_mae: 0.0879\n",
            "Epoch 660/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0270 - val_mae: 0.0875\n",
            "Epoch 661/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0263 - mae: 0.0868 - val_loss: 0.0274 - val_mae: 0.0882\n",
            "Epoch 662/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0266 - mae: 0.0875 - val_loss: 0.0270 - val_mae: 0.0873\n",
            "Epoch 663/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0264 - mae: 0.0870 - val_loss: 0.0270 - val_mae: 0.0873\n",
            "Epoch 664/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0263 - mae: 0.0868 - val_loss: 0.0272 - val_mae: 0.0872\n",
            "Epoch 665/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0263 - mae: 0.0870 - val_loss: 0.0271 - val_mae: 0.0872\n",
            "Epoch 666/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0867 - val_loss: 0.0272 - val_mae: 0.0883\n",
            "Epoch 667/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0867 - val_loss: 0.0273 - val_mae: 0.0884\n",
            "Epoch 668/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0869 - val_loss: 0.0272 - val_mae: 0.0884\n",
            "Epoch 669/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0870 - val_loss: 0.0270 - val_mae: 0.0863\n",
            "Epoch 670/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0869 - val_loss: 0.0271 - val_mae: 0.0875\n",
            "Epoch 671/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0870 - val_loss: 0.0273 - val_mae: 0.0882\n",
            "Epoch 672/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0868 - val_loss: 0.0272 - val_mae: 0.0873\n",
            "Epoch 673/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0263 - mae: 0.0869 - val_loss: 0.0269 - val_mae: 0.0869\n",
            "Epoch 674/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0870 - val_loss: 0.0273 - val_mae: 0.0887\n",
            "Epoch 675/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0263 - mae: 0.0871 - val_loss: 0.0270 - val_mae: 0.0873\n",
            "Epoch 676/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0867 - val_loss: 0.0271 - val_mae: 0.0878\n",
            "Epoch 677/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0263 - mae: 0.0868 - val_loss: 0.0270 - val_mae: 0.0875\n",
            "Epoch 678/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0868 - val_loss: 0.0270 - val_mae: 0.0871\n",
            "Epoch 679/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0868 - val_loss: 0.0272 - val_mae: 0.0877\n",
            "Epoch 680/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0870 - val_loss: 0.0269 - val_mae: 0.0868\n",
            "Epoch 681/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0262 - mae: 0.0866 - val_loss: 0.0269 - val_mae: 0.0870\n",
            "Epoch 682/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0866 - val_loss: 0.0272 - val_mae: 0.0880\n",
            "Epoch 683/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0869 - val_loss: 0.0271 - val_mae: 0.0877\n",
            "Epoch 684/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0869 - val_loss: 0.0271 - val_mae: 0.0886\n",
            "Epoch 685/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0868 - val_loss: 0.0270 - val_mae: 0.0871\n",
            "Epoch 686/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0867 - val_loss: 0.0272 - val_mae: 0.0880\n",
            "Epoch 687/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0867 - val_loss: 0.0269 - val_mae: 0.0871\n",
            "Epoch 688/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0865 - val_loss: 0.0273 - val_mae: 0.0881\n",
            "Epoch 689/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0265 - mae: 0.0873 - val_loss: 0.0270 - val_mae: 0.0873\n",
            "Epoch 690/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0264 - mae: 0.0872 - val_loss: 0.0274 - val_mae: 0.0879\n",
            "Epoch 691/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0264 - mae: 0.0871 - val_loss: 0.0276 - val_mae: 0.0895\n",
            "Epoch 692/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0263 - mae: 0.0869 - val_loss: 0.0269 - val_mae: 0.0870\n",
            "Epoch 693/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0867 - val_loss: 0.0269 - val_mae: 0.0873\n",
            "Epoch 694/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0866 - val_loss: 0.0269 - val_mae: 0.0872\n",
            "Epoch 695/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0867 - val_loss: 0.0269 - val_mae: 0.0872\n",
            "Epoch 696/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0868 - val_loss: 0.0270 - val_mae: 0.0874\n",
            "Epoch 697/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0869 - val_loss: 0.0269 - val_mae: 0.0873\n",
            "Epoch 698/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0264 - mae: 0.0870 - val_loss: 0.0270 - val_mae: 0.0878\n",
            "Epoch 699/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0262 - mae: 0.0870 - val_loss: 0.0269 - val_mae: 0.0871\n",
            "Epoch 700/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0865 - val_loss: 0.0268 - val_mae: 0.0876\n",
            "Epoch 701/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0262 - mae: 0.0868 - val_loss: 0.0273 - val_mae: 0.0878\n",
            "Epoch 702/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0262 - mae: 0.0868 - val_loss: 0.0269 - val_mae: 0.0873\n",
            "Epoch 703/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0865 - val_loss: 0.0273 - val_mae: 0.0885\n",
            "Epoch 704/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0869 - val_loss: 0.0273 - val_mae: 0.0883\n",
            "Epoch 705/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0262 - mae: 0.0866 - val_loss: 0.0272 - val_mae: 0.0879\n",
            "Epoch 706/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0869 - val_loss: 0.0269 - val_mae: 0.0869\n",
            "Epoch 707/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0869 - val_loss: 0.0271 - val_mae: 0.0878\n",
            "Epoch 708/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0263 - mae: 0.0869 - val_loss: 0.0277 - val_mae: 0.0881\n",
            "Epoch 709/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0265 - mae: 0.0871 - val_loss: 0.0270 - val_mae: 0.0872\n",
            "Epoch 710/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0866 - val_loss: 0.0273 - val_mae: 0.0880\n",
            "Epoch 711/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0261 - mae: 0.0865 - val_loss: 0.0271 - val_mae: 0.0874\n",
            "Epoch 712/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0866 - val_loss: 0.0269 - val_mae: 0.0869\n",
            "Epoch 713/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0261 - mae: 0.0867 - val_loss: 0.0270 - val_mae: 0.0874\n",
            "Epoch 714/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0866 - val_loss: 0.0269 - val_mae: 0.0869\n",
            "Epoch 715/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0864 - val_loss: 0.0278 - val_mae: 0.0898\n",
            "Epoch 716/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0264 - mae: 0.0870 - val_loss: 0.0269 - val_mae: 0.0866\n",
            "Epoch 717/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0865 - val_loss: 0.0268 - val_mae: 0.0875\n",
            "Epoch 718/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0260 - mae: 0.0864 - val_loss: 0.0268 - val_mae: 0.0873\n",
            "Epoch 719/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0864 - val_loss: 0.0267 - val_mae: 0.0869\n",
            "Epoch 720/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0865 - val_loss: 0.0269 - val_mae: 0.0873\n",
            "Epoch 721/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0868 - val_loss: 0.0269 - val_mae: 0.0871\n",
            "Epoch 722/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0866 - val_loss: 0.0268 - val_mae: 0.0868\n",
            "Epoch 723/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0261 - mae: 0.0866 - val_loss: 0.0269 - val_mae: 0.0878\n",
            "Epoch 724/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0867 - val_loss: 0.0270 - val_mae: 0.0879\n",
            "Epoch 725/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0866 - val_loss: 0.0268 - val_mae: 0.0869\n",
            "Epoch 726/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0261 - mae: 0.0867 - val_loss: 0.0267 - val_mae: 0.0864\n",
            "Epoch 727/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0864 - val_loss: 0.0267 - val_mae: 0.0875\n",
            "Epoch 728/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0261 - mae: 0.0866 - val_loss: 0.0267 - val_mae: 0.0868\n",
            "Epoch 729/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0261 - mae: 0.0864 - val_loss: 0.0268 - val_mae: 0.0871\n",
            "Epoch 730/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0866 - val_loss: 0.0269 - val_mae: 0.0873\n",
            "Epoch 731/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0866 - val_loss: 0.0267 - val_mae: 0.0874\n",
            "Epoch 732/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0261 - mae: 0.0865 - val_loss: 0.0271 - val_mae: 0.0875\n",
            "Epoch 733/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0865 - val_loss: 0.0269 - val_mae: 0.0871\n",
            "Epoch 734/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0868 - val_loss: 0.0268 - val_mae: 0.0869\n",
            "Epoch 735/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0260 - mae: 0.0863 - val_loss: 0.0269 - val_mae: 0.0880\n",
            "Epoch 736/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0867 - val_loss: 0.0267 - val_mae: 0.0867\n",
            "Epoch 737/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0260 - mae: 0.0865 - val_loss: 0.0268 - val_mae: 0.0862\n",
            "Epoch 738/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0261 - mae: 0.0865 - val_loss: 0.0268 - val_mae: 0.0876\n",
            "Epoch 739/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0261 - mae: 0.0866 - val_loss: 0.0269 - val_mae: 0.0873\n",
            "Epoch 740/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0868 - val_loss: 0.0272 - val_mae: 0.0876\n",
            "Epoch 741/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0867 - val_loss: 0.0268 - val_mae: 0.0877\n",
            "Epoch 742/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0863 - val_loss: 0.0268 - val_mae: 0.0872\n",
            "Epoch 743/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0866 - val_loss: 0.0267 - val_mae: 0.0865\n",
            "Epoch 744/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0863 - val_loss: 0.0267 - val_mae: 0.0865\n",
            "Epoch 745/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0863 - val_loss: 0.0266 - val_mae: 0.0864\n",
            "Epoch 746/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0263 - mae: 0.0868 - val_loss: 0.0267 - val_mae: 0.0864\n",
            "Epoch 747/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0260 - mae: 0.0863 - val_loss: 0.0270 - val_mae: 0.0883\n",
            "Epoch 748/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0260 - mae: 0.0864 - val_loss: 0.0268 - val_mae: 0.0876\n",
            "Epoch 749/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0864 - val_loss: 0.0268 - val_mae: 0.0872\n",
            "Epoch 750/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0259 - mae: 0.0862 - val_loss: 0.0267 - val_mae: 0.0865\n",
            "Epoch 751/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0862 - val_loss: 0.0270 - val_mae: 0.0880\n",
            "Epoch 752/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0261 - mae: 0.0865 - val_loss: 0.0269 - val_mae: 0.0873\n",
            "Epoch 753/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0260 - mae: 0.0865 - val_loss: 0.0271 - val_mae: 0.0883\n",
            "Epoch 754/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0865 - val_loss: 0.0272 - val_mae: 0.0874\n",
            "Epoch 755/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0266 - mae: 0.0872 - val_loss: 0.0268 - val_mae: 0.0868\n",
            "Epoch 756/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0260 - mae: 0.0862 - val_loss: 0.0267 - val_mae: 0.0872\n",
            "Epoch 757/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0260 - mae: 0.0864 - val_loss: 0.0271 - val_mae: 0.0875\n",
            "Epoch 758/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0260 - mae: 0.0864 - val_loss: 0.0266 - val_mae: 0.0867\n",
            "Epoch 759/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0259 - mae: 0.0863 - val_loss: 0.0269 - val_mae: 0.0875\n",
            "Epoch 760/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0260 - mae: 0.0865 - val_loss: 0.0268 - val_mae: 0.0870\n",
            "Epoch 761/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0260 - mae: 0.0863 - val_loss: 0.0283 - val_mae: 0.0894\n",
            "Epoch 762/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0260 - mae: 0.0864 - val_loss: 0.0265 - val_mae: 0.0863\n",
            "Epoch 763/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0864 - val_loss: 0.0267 - val_mae: 0.0872\n",
            "Epoch 764/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0864 - val_loss: 0.0266 - val_mae: 0.0861\n",
            "Epoch 765/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0260 - mae: 0.0864 - val_loss: 0.0265 - val_mae: 0.0861\n",
            "Epoch 766/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0259 - mae: 0.0862 - val_loss: 0.0266 - val_mae: 0.0865\n",
            "Epoch 767/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0259 - mae: 0.0863 - val_loss: 0.0268 - val_mae: 0.0875\n",
            "Epoch 768/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0259 - mae: 0.0862 - val_loss: 0.0269 - val_mae: 0.0874\n",
            "Epoch 769/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0863 - val_loss: 0.0269 - val_mae: 0.0874\n",
            "Epoch 770/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0865 - val_loss: 0.0268 - val_mae: 0.0870\n",
            "Epoch 771/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0261 - mae: 0.0868 - val_loss: 0.0266 - val_mae: 0.0865\n",
            "Epoch 772/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0262 - mae: 0.0868 - val_loss: 0.0267 - val_mae: 0.0871\n",
            "Epoch 773/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0260 - mae: 0.0863 - val_loss: 0.0268 - val_mae: 0.0874\n",
            "Epoch 774/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0259 - mae: 0.0861 - val_loss: 0.0267 - val_mae: 0.0873\n",
            "Epoch 775/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0864 - val_loss: 0.0276 - val_mae: 0.0895\n",
            "Epoch 776/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0260 - mae: 0.0864 - val_loss: 0.0266 - val_mae: 0.0867\n",
            "Epoch 777/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0259 - mae: 0.0862 - val_loss: 0.0266 - val_mae: 0.0860\n",
            "Epoch 778/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0864 - val_loss: 0.0266 - val_mae: 0.0867\n",
            "Epoch 779/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0260 - mae: 0.0865 - val_loss: 0.0267 - val_mae: 0.0864\n",
            "Epoch 780/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0259 - mae: 0.0861 - val_loss: 0.0266 - val_mae: 0.0867\n",
            "Epoch 781/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0861 - val_loss: 0.0268 - val_mae: 0.0875\n",
            "Epoch 782/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0865 - val_loss: 0.0266 - val_mae: 0.0865\n",
            "Epoch 783/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0862 - val_loss: 0.0269 - val_mae: 0.0869\n",
            "Epoch 784/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0863 - val_loss: 0.0269 - val_mae: 0.0876\n",
            "Epoch 785/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0861 - val_loss: 0.0268 - val_mae: 0.0874\n",
            "Epoch 786/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0863 - val_loss: 0.0267 - val_mae: 0.0868\n",
            "Epoch 787/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0259 - mae: 0.0861 - val_loss: 0.0267 - val_mae: 0.0870\n",
            "Epoch 788/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0259 - mae: 0.0861 - val_loss: 0.0267 - val_mae: 0.0863\n",
            "Epoch 789/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0864 - val_loss: 0.0266 - val_mae: 0.0865\n",
            "Epoch 790/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0864 - val_loss: 0.0267 - val_mae: 0.0876\n",
            "Epoch 791/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0862 - val_loss: 0.0266 - val_mae: 0.0864\n",
            "Epoch 792/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0862 - val_loss: 0.0268 - val_mae: 0.0867\n",
            "Epoch 793/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0862 - val_loss: 0.0271 - val_mae: 0.0879\n",
            "Epoch 794/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0863 - val_loss: 0.0264 - val_mae: 0.0864\n",
            "Epoch 795/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0862 - val_loss: 0.0266 - val_mae: 0.0865\n",
            "Epoch 796/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0862 - val_loss: 0.0276 - val_mae: 0.0887\n",
            "Epoch 797/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0863 - val_loss: 0.0267 - val_mae: 0.0875\n",
            "Epoch 798/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0259 - mae: 0.0861 - val_loss: 0.0265 - val_mae: 0.0860\n",
            "Epoch 799/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0258 - mae: 0.0860 - val_loss: 0.0267 - val_mae: 0.0867\n",
            "Epoch 800/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0259 - mae: 0.0862 - val_loss: 0.0267 - val_mae: 0.0866\n",
            "Epoch 801/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0258 - mae: 0.0860 - val_loss: 0.0266 - val_mae: 0.0869\n",
            "Epoch 802/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0259 - mae: 0.0863 - val_loss: 0.0266 - val_mae: 0.0867\n",
            "Epoch 803/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0860 - val_loss: 0.0264 - val_mae: 0.0861\n",
            "Epoch 804/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0265 - val_mae: 0.0863\n",
            "Epoch 805/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0863 - val_loss: 0.0267 - val_mae: 0.0871\n",
            "Epoch 806/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0861 - val_loss: 0.0265 - val_mae: 0.0866\n",
            "Epoch 807/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0259 - mae: 0.0862 - val_loss: 0.0269 - val_mae: 0.0874\n",
            "Epoch 808/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0863 - val_loss: 0.0267 - val_mae: 0.0879\n",
            "Epoch 809/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0863 - val_loss: 0.0268 - val_mae: 0.0875\n",
            "Epoch 810/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0265 - val_mae: 0.0862\n",
            "Epoch 811/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0860 - val_loss: 0.0266 - val_mae: 0.0867\n",
            "Epoch 812/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0258 - mae: 0.0860 - val_loss: 0.0272 - val_mae: 0.0874\n",
            "Epoch 813/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0864 - val_loss: 0.0270 - val_mae: 0.0883\n",
            "Epoch 814/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0862 - val_loss: 0.0269 - val_mae: 0.0867\n",
            "Epoch 815/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0258 - mae: 0.0860 - val_loss: 0.0265 - val_mae: 0.0863\n",
            "Epoch 816/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0265 - val_mae: 0.0861\n",
            "Epoch 817/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0861 - val_loss: 0.0267 - val_mae: 0.0871\n",
            "Epoch 818/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0269 - val_mae: 0.0880\n",
            "Epoch 819/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0260 - mae: 0.0865 - val_loss: 0.0265 - val_mae: 0.0868\n",
            "Epoch 820/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0266 - val_mae: 0.0871\n",
            "Epoch 821/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0263 - val_mae: 0.0860\n",
            "Epoch 822/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0861 - val_loss: 0.0266 - val_mae: 0.0866\n",
            "Epoch 823/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0860 - val_loss: 0.0269 - val_mae: 0.0890\n",
            "Epoch 824/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0864 - val_loss: 0.0276 - val_mae: 0.0895\n",
            "Epoch 825/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0862 - val_loss: 0.0266 - val_mae: 0.0872\n",
            "Epoch 826/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0867 - val_loss: 0.0265 - val_mae: 0.0860\n",
            "Epoch 827/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0862 - val_loss: 0.0264 - val_mae: 0.0864\n",
            "Epoch 828/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0265 - val_mae: 0.0865\n",
            "Epoch 829/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0859 - val_loss: 0.0264 - val_mae: 0.0863\n",
            "Epoch 830/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0257 - mae: 0.0859 - val_loss: 0.0266 - val_mae: 0.0875\n",
            "Epoch 831/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0258 - mae: 0.0859 - val_loss: 0.0268 - val_mae: 0.0877\n",
            "Epoch 832/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0860 - val_loss: 0.0265 - val_mae: 0.0865\n",
            "Epoch 833/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0861 - val_loss: 0.0263 - val_mae: 0.0855\n",
            "Epoch 834/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0863 - val_loss: 0.0266 - val_mae: 0.0870\n",
            "Epoch 835/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0859 - val_loss: 0.0265 - val_mae: 0.0863\n",
            "Epoch 836/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0258 - mae: 0.0859 - val_loss: 0.0263 - val_mae: 0.0860\n",
            "Epoch 837/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0257 - mae: 0.0859 - val_loss: 0.0267 - val_mae: 0.0880\n",
            "Epoch 838/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0862 - val_loss: 0.0266 - val_mae: 0.0864\n",
            "Epoch 839/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0862 - val_loss: 0.0272 - val_mae: 0.0885\n",
            "Epoch 840/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0260 - mae: 0.0865 - val_loss: 0.0266 - val_mae: 0.0868\n",
            "Epoch 841/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0864 - val_loss: 0.0266 - val_mae: 0.0861\n",
            "Epoch 842/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0860 - val_loss: 0.0268 - val_mae: 0.0876\n",
            "Epoch 843/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0265 - val_mae: 0.0867\n",
            "Epoch 844/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0860 - val_loss: 0.0265 - val_mae: 0.0866\n",
            "Epoch 845/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0257 - mae: 0.0858 - val_loss: 0.0275 - val_mae: 0.0892\n",
            "Epoch 846/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0261 - mae: 0.0867 - val_loss: 0.0266 - val_mae: 0.0867\n",
            "Epoch 847/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0860 - val_loss: 0.0265 - val_mae: 0.0872\n",
            "Epoch 848/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0856 - val_loss: 0.0267 - val_mae: 0.0869\n",
            "Epoch 849/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0257 - mae: 0.0858 - val_loss: 0.0263 - val_mae: 0.0857\n",
            "Epoch 850/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0257 - mae: 0.0858 - val_loss: 0.0278 - val_mae: 0.0883\n",
            "Epoch 851/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0860 - val_loss: 0.0265 - val_mae: 0.0861\n",
            "Epoch 852/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0257 - mae: 0.0859 - val_loss: 0.0272 - val_mae: 0.0876\n",
            "Epoch 853/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0267 - val_mae: 0.0875\n",
            "Epoch 854/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0265 - val_mae: 0.0872\n",
            "Epoch 855/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0859 - val_loss: 0.0268 - val_mae: 0.0871\n",
            "Epoch 856/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0265 - val_mae: 0.0864\n",
            "Epoch 857/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0258 - mae: 0.0860 - val_loss: 0.0266 - val_mae: 0.0867\n",
            "Epoch 858/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0862 - val_loss: 0.0267 - val_mae: 0.0877\n",
            "Epoch 859/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0859 - val_loss: 0.0267 - val_mae: 0.0868\n",
            "Epoch 860/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0860 - val_loss: 0.0265 - val_mae: 0.0864\n",
            "Epoch 861/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0259 - mae: 0.0862 - val_loss: 0.0264 - val_mae: 0.0859\n",
            "Epoch 862/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0858 - val_loss: 0.0265 - val_mae: 0.0864\n",
            "Epoch 863/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0858 - val_loss: 0.0266 - val_mae: 0.0873\n",
            "Epoch 864/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0860 - val_loss: 0.0265 - val_mae: 0.0860\n",
            "Epoch 865/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0858 - val_loss: 0.0267 - val_mae: 0.0863\n",
            "Epoch 866/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0860 - val_loss: 0.0264 - val_mae: 0.0858\n",
            "Epoch 867/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0860 - val_loss: 0.0268 - val_mae: 0.0869\n",
            "Epoch 868/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0858 - val_loss: 0.0266 - val_mae: 0.0874\n",
            "Epoch 869/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0862 - val_loss: 0.0265 - val_mae: 0.0863\n",
            "Epoch 870/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0858 - val_loss: 0.0263 - val_mae: 0.0858\n",
            "Epoch 871/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0257 - mae: 0.0858 - val_loss: 0.0264 - val_mae: 0.0862\n",
            "Epoch 872/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0257 - mae: 0.0859 - val_loss: 0.0264 - val_mae: 0.0864\n",
            "Epoch 873/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0256 - mae: 0.0857 - val_loss: 0.0271 - val_mae: 0.0877\n",
            "Epoch 874/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0265 - val_mae: 0.0868\n",
            "Epoch 875/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0862 - val_loss: 0.0264 - val_mae: 0.0861\n",
            "Epoch 876/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0857 - val_loss: 0.0265 - val_mae: 0.0872\n",
            "Epoch 877/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0257 - mae: 0.0858 - val_loss: 0.0265 - val_mae: 0.0870\n",
            "Epoch 878/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0268 - val_mae: 0.0868\n",
            "Epoch 879/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0859 - val_loss: 0.0265 - val_mae: 0.0871\n",
            "Epoch 880/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0266 - val_mae: 0.0870\n",
            "Epoch 881/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0265 - val_mae: 0.0869\n",
            "Epoch 882/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0256 - mae: 0.0856 - val_loss: 0.0268 - val_mae: 0.0880\n",
            "Epoch 883/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0256 - mae: 0.0857 - val_loss: 0.0264 - val_mae: 0.0865\n",
            "Epoch 884/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0859 - val_loss: 0.0263 - val_mae: 0.0859\n",
            "Epoch 885/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0860 - val_loss: 0.0263 - val_mae: 0.0869\n",
            "Epoch 886/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0858 - val_loss: 0.0263 - val_mae: 0.0859\n",
            "Epoch 887/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0858 - val_loss: 0.0266 - val_mae: 0.0872\n",
            "Epoch 888/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0256 - mae: 0.0857 - val_loss: 0.0263 - val_mae: 0.0866\n",
            "Epoch 889/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0858 - val_loss: 0.0270 - val_mae: 0.0879\n",
            "Epoch 890/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0861 - val_loss: 0.0263 - val_mae: 0.0860\n",
            "Epoch 891/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0258 - mae: 0.0862 - val_loss: 0.0264 - val_mae: 0.0860\n",
            "Epoch 892/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0257 - mae: 0.0859 - val_loss: 0.0264 - val_mae: 0.0859\n",
            "Epoch 893/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0257 - mae: 0.0858 - val_loss: 0.0263 - val_mae: 0.0856\n",
            "Epoch 894/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0256 - mae: 0.0856 - val_loss: 0.0266 - val_mae: 0.0874\n",
            "Epoch 895/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0256 - mae: 0.0857 - val_loss: 0.0264 - val_mae: 0.0866\n",
            "Epoch 896/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0858 - val_loss: 0.0268 - val_mae: 0.0873\n",
            "Epoch 897/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0257 - mae: 0.0859 - val_loss: 0.0262 - val_mae: 0.0862\n",
            "Epoch 898/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0256 - mae: 0.0856 - val_loss: 0.0264 - val_mae: 0.0859\n",
            "Epoch 899/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0857 - val_loss: 0.0266 - val_mae: 0.0860\n",
            "Epoch 900/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0857 - val_loss: 0.0264 - val_mae: 0.0862\n",
            "Epoch 901/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0857 - val_loss: 0.0271 - val_mae: 0.0876\n",
            "Epoch 902/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0859 - val_loss: 0.0267 - val_mae: 0.0867\n",
            "Epoch 903/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0858 - val_loss: 0.0265 - val_mae: 0.0870\n",
            "Epoch 904/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0266 - val_mae: 0.0868\n",
            "Epoch 905/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0857 - val_loss: 0.0265 - val_mae: 0.0859\n",
            "Epoch 906/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0855 - val_loss: 0.0264 - val_mae: 0.0857\n",
            "Epoch 907/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0857 - val_loss: 0.0264 - val_mae: 0.0877\n",
            "Epoch 908/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0856 - val_loss: 0.0262 - val_mae: 0.0859\n",
            "Epoch 909/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0856 - val_loss: 0.0264 - val_mae: 0.0868\n",
            "Epoch 910/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0856 - val_loss: 0.0262 - val_mae: 0.0867\n",
            "Epoch 911/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0856 - val_loss: 0.0267 - val_mae: 0.0868\n",
            "Epoch 912/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0856 - val_loss: 0.0262 - val_mae: 0.0857\n",
            "Epoch 913/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0257 - mae: 0.0858 - val_loss: 0.0265 - val_mae: 0.0870\n",
            "Epoch 914/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0857 - val_loss: 0.0263 - val_mae: 0.0861\n",
            "Epoch 915/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0855 - val_loss: 0.0265 - val_mae: 0.0869\n",
            "Epoch 916/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0255 - mae: 0.0855 - val_loss: 0.0263 - val_mae: 0.0861\n",
            "Epoch 917/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0856 - val_loss: 0.0263 - val_mae: 0.0858\n",
            "Epoch 918/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0855 - val_loss: 0.0263 - val_mae: 0.0859\n",
            "Epoch 919/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0857 - val_loss: 0.0269 - val_mae: 0.0865\n",
            "Epoch 920/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0856 - val_loss: 0.0264 - val_mae: 0.0863\n",
            "Epoch 921/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0256 - mae: 0.0856 - val_loss: 0.0262 - val_mae: 0.0860\n",
            "Epoch 922/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0856 - val_loss: 0.0264 - val_mae: 0.0870\n",
            "Epoch 923/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0856 - val_loss: 0.0265 - val_mae: 0.0860\n",
            "Epoch 924/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0854 - val_loss: 0.0269 - val_mae: 0.0875\n",
            "Epoch 925/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0257 - mae: 0.0857 - val_loss: 0.0262 - val_mae: 0.0856\n",
            "Epoch 926/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0858 - val_loss: 0.0262 - val_mae: 0.0859\n",
            "Epoch 927/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0855 - val_loss: 0.0262 - val_mae: 0.0856\n",
            "Epoch 928/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0853 - val_loss: 0.0262 - val_mae: 0.0859\n",
            "Epoch 929/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0854 - val_loss: 0.0261 - val_mae: 0.0851\n",
            "Epoch 930/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0855 - val_loss: 0.0264 - val_mae: 0.0861\n",
            "Epoch 931/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0856 - val_loss: 0.0262 - val_mae: 0.0862\n",
            "Epoch 932/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0255 - mae: 0.0856 - val_loss: 0.0264 - val_mae: 0.0869\n",
            "Epoch 933/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0256 - mae: 0.0854 - val_loss: 0.0262 - val_mae: 0.0861\n",
            "Epoch 934/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0255 - mae: 0.0855 - val_loss: 0.0262 - val_mae: 0.0860\n",
            "Epoch 935/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0856 - val_loss: 0.0264 - val_mae: 0.0862\n",
            "Epoch 936/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0859 - val_loss: 0.0263 - val_mae: 0.0858\n",
            "Epoch 937/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0854 - val_loss: 0.0264 - val_mae: 0.0865\n",
            "Epoch 938/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0855 - val_loss: 0.0268 - val_mae: 0.0868\n",
            "Epoch 939/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0852 - val_loss: 0.0279 - val_mae: 0.0895\n",
            "Epoch 940/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0258 - mae: 0.0861 - val_loss: 0.0263 - val_mae: 0.0864\n",
            "Epoch 941/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0856 - val_loss: 0.0263 - val_mae: 0.0863\n",
            "Epoch 942/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0857 - val_loss: 0.0264 - val_mae: 0.0861\n",
            "Epoch 943/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0852 - val_loss: 0.0261 - val_mae: 0.0854\n",
            "Epoch 944/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0853 - val_loss: 0.0264 - val_mae: 0.0858\n",
            "Epoch 945/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0853 - val_loss: 0.0263 - val_mae: 0.0866\n",
            "Epoch 946/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0854 - val_loss: 0.0263 - val_mae: 0.0861\n",
            "Epoch 947/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0853 - val_loss: 0.0267 - val_mae: 0.0888\n",
            "Epoch 948/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0855 - val_loss: 0.0268 - val_mae: 0.0866\n",
            "Epoch 949/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0855 - val_loss: 0.0262 - val_mae: 0.0852\n",
            "Epoch 950/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0853 - val_loss: 0.0263 - val_mae: 0.0862\n",
            "Epoch 951/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0854 - val_loss: 0.0262 - val_mae: 0.0855\n",
            "Epoch 952/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0857 - val_loss: 0.0260 - val_mae: 0.0857\n",
            "Epoch 953/1000\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.0256 - mae: 0.0855 - val_loss: 0.0261 - val_mae: 0.0849\n",
            "Epoch 954/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0855 - val_loss: 0.0261 - val_mae: 0.0852\n",
            "Epoch 955/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0854 - val_loss: 0.0262 - val_mae: 0.0867\n",
            "Epoch 956/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0853 - val_loss: 0.0263 - val_mae: 0.0865\n",
            "Epoch 957/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0854 - val_loss: 0.0263 - val_mae: 0.0858\n",
            "Epoch 958/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0853 - val_loss: 0.0261 - val_mae: 0.0851\n",
            "Epoch 959/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0853 - val_loss: 0.0261 - val_mae: 0.0866\n",
            "Epoch 960/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0856 - val_loss: 0.0262 - val_mae: 0.0854\n",
            "Epoch 961/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0852 - val_loss: 0.0262 - val_mae: 0.0857\n",
            "Epoch 962/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0854 - val_loss: 0.0265 - val_mae: 0.0857\n",
            "Epoch 963/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0257 - mae: 0.0859 - val_loss: 0.0261 - val_mae: 0.0858\n",
            "Epoch 964/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0852 - val_loss: 0.0265 - val_mae: 0.0862\n",
            "Epoch 965/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0854 - val_loss: 0.0260 - val_mae: 0.0851\n",
            "Epoch 966/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0852 - val_loss: 0.0261 - val_mae: 0.0856\n",
            "Epoch 967/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0854 - val_loss: 0.0259 - val_mae: 0.0854\n",
            "Epoch 968/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0852 - val_loss: 0.0261 - val_mae: 0.0851\n",
            "Epoch 969/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0255 - mae: 0.0854 - val_loss: 0.0263 - val_mae: 0.0865\n",
            "Epoch 970/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0855 - val_loss: 0.0262 - val_mae: 0.0859\n",
            "Epoch 971/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0255 - mae: 0.0854 - val_loss: 0.0267 - val_mae: 0.0875\n",
            "Epoch 972/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0855 - val_loss: 0.0261 - val_mae: 0.0854\n",
            "Epoch 973/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0852 - val_loss: 0.0262 - val_mae: 0.0862\n",
            "Epoch 974/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0254 - mae: 0.0852 - val_loss: 0.0261 - val_mae: 0.0856\n",
            "Epoch 975/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0854 - val_loss: 0.0261 - val_mae: 0.0855\n",
            "Epoch 976/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0254 - mae: 0.0852 - val_loss: 0.0262 - val_mae: 0.0863\n",
            "Epoch 977/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0254 - mae: 0.0852 - val_loss: 0.0260 - val_mae: 0.0854\n",
            "Epoch 978/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0852 - val_loss: 0.0260 - val_mae: 0.0853\n",
            "Epoch 979/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0854 - val_loss: 0.0263 - val_mae: 0.0860\n",
            "Epoch 980/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0854 - val_loss: 0.0262 - val_mae: 0.0867\n",
            "Epoch 981/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0851 - val_loss: 0.0261 - val_mae: 0.0858\n",
            "Epoch 982/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0852 - val_loss: 0.0265 - val_mae: 0.0866\n",
            "Epoch 983/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0854 - val_loss: 0.0271 - val_mae: 0.0877\n",
            "Epoch 984/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0855 - val_loss: 0.0261 - val_mae: 0.0852\n",
            "Epoch 985/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0852 - val_loss: 0.0263 - val_mae: 0.0861\n",
            "Epoch 986/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0850 - val_loss: 0.0262 - val_mae: 0.0860\n",
            "Epoch 987/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0253 - mae: 0.0852 - val_loss: 0.0262 - val_mae: 0.0862\n",
            "Epoch 988/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0852 - val_loss: 0.0260 - val_mae: 0.0854\n",
            "Epoch 989/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0253 - mae: 0.0849 - val_loss: 0.0264 - val_mae: 0.0873\n",
            "Epoch 990/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0255 - mae: 0.0854 - val_loss: 0.0261 - val_mae: 0.0859\n",
            "Epoch 991/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0255 - mae: 0.0854 - val_loss: 0.0262 - val_mae: 0.0859\n",
            "Epoch 992/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0255 - mae: 0.0853 - val_loss: 0.0262 - val_mae: 0.0857\n",
            "Epoch 993/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0254 - mae: 0.0852 - val_loss: 0.0265 - val_mae: 0.0860\n",
            "Epoch 994/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0254 - mae: 0.0852 - val_loss: 0.0261 - val_mae: 0.0853\n",
            "Epoch 995/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0253 - mae: 0.0852 - val_loss: 0.0261 - val_mae: 0.0852\n",
            "Epoch 996/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0254 - mae: 0.0852 - val_loss: 0.0261 - val_mae: 0.0855\n",
            "Epoch 997/1000\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0253 - mae: 0.0850 - val_loss: 0.0261 - val_mae: 0.0865\n",
            "Epoch 998/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0253 - mae: 0.0851 - val_loss: 0.0261 - val_mae: 0.0857\n",
            "Epoch 999/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0253 - mae: 0.0849 - val_loss: 0.0262 - val_mae: 0.0853\n",
            "Epoch 1000/1000\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0256 - mae: 0.0856 - val_loss: 0.0264 - val_mae: 0.0861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRFSAFd3e98l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "fce4274e-5fd1-4601-8a52-a4ed36f96d24"
      },
      "source": [
        "# Выводим график точности на обучающей выборке\n",
        "# label - имя графика в легенде\n",
        "plt.plot(history.history['loss'], \n",
        "         label='Погрешность на обучающем наборе')\n",
        "\n",
        "# Выводим график точности на проверочной выборке\n",
        "plt.plot(history.history['val_loss'], \n",
        "         label='Погрешность на проверочном наборе')\n",
        "\n",
        "# Выводим подписи осей\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('Доля верных ответов')\n",
        "\n",
        "# Выводим легенду\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A98XdpWS-y4R"
      },
      "source": [
        "###Делаем предсказания моделью"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScIDqnrDI51e"
      },
      "source": [
        "####Создадим функцию для проверки транзакции:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxbEcTc2Xj-Y"
      },
      "source": [
        "def detectFraud(ae, x, std, threshold=2):\n",
        "    \"\"\"\n",
        "    :param ae: автоэнкодер (модель keras)\n",
        "    :param x: данные для проверки (размерности (1, 29))\n",
        "    :param std: среднеквадратичная ошибка автоэнкодера на нормальных данных\n",
        "    :param threshold: порог - параметр критерия. Операция считается мошеннической, если ошибка восстановления превышает среднюю более чем threshold раз.\n",
        "    :return: True for fraud, False for normal. \n",
        "    \"\"\"\n",
        "    pred = ae.predict(x)\n",
        "    e = (pred - x)**2\n",
        "    mse = e.mean()\n",
        "    return mse > threshold * std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPYL-41RI4Cm"
      },
      "source": [
        "####Применим нашу функцию ко всем тестовым операциям для разделения на нормальные и мошеннические"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU2sanwpXkLs",
        "outputId": "ae7ae87f-cf95-471d-f810-3c64f20387bc"
      },
      "source": [
        "%%time\n",
        "threshold = 3\n",
        "std = 0.32\n",
        "count = 0\n",
        "detect_list = []\n",
        "for x in x_test:\n",
        "    x = x.reshape(1, 29)\n",
        "    if detectFraud(ae, x, std, threshold=threshold):\n",
        "        detect_list.append(1)\n",
        "        count += 1\n",
        "    else:\n",
        "        detect_list.append(0)\n",
        "print(\"Выявлено мошеннических операций: %d, всего: %d (%.1f%% всех тестовых данных)\" % (count, len(x_test), 100 * count / len(x_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Выявлено мошеннических операций: 17, всего: 984 (1.7% всех тестовых данных)\n",
            "CPU times: user 50.6 s, sys: 2.34 s, total: 53 s\n",
            "Wall time: 1min 46s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dOvXk0YJIVC"
      },
      "source": [
        "и к нормальным операциям:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fv-aiaPGI0O",
        "outputId": "27112330-beed-42bf-a529-9dcee2abe6cb"
      },
      "source": [
        "%%time\n",
        "count = 0\n",
        "x_train_short = x_train[:len(x_test)] # укоротили массив для увеличения скорости обработки\n",
        "for x in x_train_short:\n",
        "    x = x.reshape(1, 29)\n",
        "    if detectFraud(ae, x, std, threshold=threshold):\n",
        "        count += 1\n",
        "print(\"Выявлено мошеннических операций: %d, всего: %d (%.1f%% всех нормальных данных)\" % (count, len(x_train_short), 100 * count / len(x_train_short)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Выявлено мошеннических операций: 0, всего: 984 (0.0% всех нормальных данных)\n",
            "CPU times: user 50.4 s, sys: 2.24 s, total: 52.7 s\n",
            "Wall time: 51.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRk3EaaZIXO9"
      },
      "source": [
        "С уменьшением порога threshold увеличивается процент выявленных мошеннических транзакций, однако одновременно с этим увеличивается число ложных срабатываний на нормальных операциях."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCBqQF1k-47m"
      },
      "source": [
        "###Переводим ответ в правильный формат, отсылаем для подсчёта рейтинга"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgviiwL6fqUk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "04923c4d-70e4-4537-d8ba-505f01f759a2"
      },
      "source": [
        "submission = pd.DataFrame({\"Id\":range(1,len(x_test)+1),\"Label\":detect_list})\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  Label\n",
              "0   1      0\n",
              "1   2      0\n",
              "2   3      0\n",
              "3   4      0\n",
              "4   5      0"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUZBHVjZK8et"
      },
      "source": [
        "Посмотрим распределение точек в скрытом пространстве"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrNMeCzRXjsF"
      },
      "source": [
        "z_clean = encoder.predict(x_test[submission[\"Label\"]==0])\n",
        "z_fraud = encoder.predict(x_test[submission[\"Label\"]==1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "Yh7zPTghROZy",
        "outputId": "8103d057-6260-47df-f733-41cdf0f6d708"
      },
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "plt.scatter(z_clean[:, 0], z_clean[:, 1], label='normal')\n",
        "plt.scatter(z_fraud[:, 0], z_fraud[:, 1], label='fraud')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.title('Распределение в скрытом пространстве')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUdWbDZax-C7"
      },
      "source": [
        "submission = submission.to_csv('./submission.csv', sep=',', index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgB5YhGDtCPW",
        "outputId": "ffb59c22-a7e3-4525-f5b3-969d00e69895"
      },
      "source": [
        "!kaggle competitions submit -c udt-3-autoencod -f submission.csv -m \"Message\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 5.67k/5.67k [00:01<00:00, 2.91kB/s]\n",
            "Successfully submitted to Университет Цифровых Технологий платформа 3"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGSUYQ147JnJ"
      },
      "source": [
        "#Литература\n",
        "\n",
        "1. https://www.tensorflow.org/tutorials/generative/autoencoder\n",
        "2. https://medium.com/analytics-vidhya/autoencoders-with-tensorflow-2f0a7315d161\n",
        "3. https://www.pyimagesearch.com/2020/02/17/autoencoders-with-keras-tensorflow-and-deep-learning/\n",
        "4. https://blog.keras.io/building-autoencoders-in-keras.html\n",
        "5. https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN_Wfcx8uC6f"
      },
      "source": [
        "##End"
      ]
    }
  ]
}